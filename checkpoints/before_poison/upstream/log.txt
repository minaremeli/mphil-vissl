INFO 2022-05-20 12:52:26,372 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2022-05-20 12:52:26,373 env.py:  50: ARCH:	x86_64
INFO 2022-05-20 12:52:26,374 env.py:  50: BASH_ENV:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/init/bash
INFO 2022-05-20 12:52:26,375 env.py:  50: BASH_FUNC_ml%%:	() {  eval $($LMOD_DIR/ml_cmd "$@")
}
INFO 2022-05-20 12:52:26,375 env.py:  50: BASH_FUNC_module%%:	() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
INFO 2022-05-20 12:52:26,376 env.py:  50: CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64
INFO 2022-05-20 12:52:26,377 env.py:  50: CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0
INFO 2022-05-20 12:52:26,377 env.py:  50: COLUMNS:	202
INFO 2022-05-20 12:52:26,378 env.py:  50: CONDA_ACTIVATE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/etc/profile.d/conda.sh
INFO 2022-05-20 12:52:26,379 env.py:  50: CONDA_DEFAULT_ENV:	vissl_env
INFO 2022-05-20 12:52:26,379 env.py:  50: CONDA_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/conda
INFO 2022-05-20 12:52:26,380 env.py:  50: CONDA_PREFIX:	/home/mila/r/rajkuman/.conda/envs/vissl_env
INFO 2022-05-20 12:52:26,381 env.py:  50: CONDA_PROMPT_MODIFIER:	(vissl_env) 
INFO 2022-05-20 12:52:26,381 env.py:  50: CONDA_PYTHON_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/python
INFO 2022-05-20 12:52:26,382 env.py:  50: CONDA_SHLVL:	1
INFO 2022-05-20 12:52:26,382 env.py:  50: CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include
INFO 2022-05-20 12:52:26,383 env.py:  50: CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3
INFO 2022-05-20 12:52:26,384 env.py:  50: CUDA_VISIBLE_DEVICES:	0
INFO 2022-05-20 12:52:26,385 env.py:  50: ENVIRONMENT:	BATCH
INFO 2022-05-20 12:52:26,385 env.py:  50: GPU_DEVICE_ORDINAL:	0
INFO 2022-05-20 12:52:26,386 env.py:  50: HOME:	/home/mila/r/rajkuman
INFO 2022-05-20 12:52:26,387 env.py:  50: HOSTNAME:	kepler5
INFO 2022-05-20 12:52:26,387 env.py:  50: ID:	debian
INFO 2022-05-20 12:52:26,388 env.py:  50: JPY_API_TOKEN:	4de0cf5d90674b4781f11f58d29559e2
INFO 2022-05-20 12:52:26,388 env.py:  50: JUPYTERHUB_ACTIVITY_URL:	http://172.16.2.123:8081/hub/api/users/rajkuman/activity
INFO 2022-05-20 12:52:26,389 env.py:  50: JUPYTERHUB_API_TOKEN:	4de0cf5d90674b4781f11f58d29559e2
INFO 2022-05-20 12:52:26,390 env.py:  50: JUPYTERHUB_API_URL:	http://172.16.2.123:8081/hub/api
INFO 2022-05-20 12:52:26,390 env.py:  50: JUPYTERHUB_BASE_URL:	/
INFO 2022-05-20 12:52:26,391 env.py:  50: JUPYTERHUB_CLIENT_ID:	jupyterhub-user-rajkuman
INFO 2022-05-20 12:52:26,391 env.py:  50: JUPYTERHUB_HOST:	
INFO 2022-05-20 12:52:26,392 env.py:  50: JUPYTERHUB_OAUTH_CALLBACK_URL:	/user/rajkuman/oauth_callback
INFO 2022-05-20 12:52:26,392 env.py:  50: JUPYTERHUB_SERVER_NAME:	
INFO 2022-05-20 12:52:26,393 env.py:  50: JUPYTERHUB_SERVICE_PREFIX:	/user/rajkuman/
INFO 2022-05-20 12:52:26,394 env.py:  50: JUPYTERHUB_USER:	rajkuman
INFO 2022-05-20 12:52:26,394 env.py:  50: JUPYTER_SERVER_ROOT:	/home/mila/r/rajkuman
INFO 2022-05-20 12:52:26,395 env.py:  50: JUPYTER_SERVER_URL:	http://0.0.0.0:40655/user/rajkuman/
INFO 2022-05-20 12:52:26,395 env.py:  50: KERNEL_LAUNCH_TIMEOUT:	40
INFO 2022-05-20 12:52:26,396 env.py:  50: LANG:	en_US.UTF-8
INFO 2022-05-20 12:52:26,397 env.py:  50: LESSCLOSE:	/bin/lesspipe %s %s
INFO 2022-05-20 12:52:26,397 env.py:  50: LESSOPEN:	| /bin/lesspipe %s
INFO 2022-05-20 12:52:26,398 env.py:  50: LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib
INFO 2022-05-20 12:52:26,398 env.py:  50: LINES:	50
INFO 2022-05-20 12:52:26,399 env.py:  50: LMOD_CMD:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec/lmod
INFO 2022-05-20 12:52:26,400 env.py:  50: LMOD_DIR:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec
INFO 2022-05-20 12:52:26,401 env.py:  50: LMOD_PACKAGE_PATH:	/cvmfs/config.mila.quebec/etc/lmod/
INFO 2022-05-20 12:52:26,401 env.py:  50: LMOD_PKG:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-20 12:52:26,402 env.py:  50: LMOD_ROOT:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod
INFO 2022-05-20 12:52:26,403 env.py:  50: LMOD_SETTARG_FULL_SUPPORT:	no
INFO 2022-05-20 12:52:26,404 env.py:  50: LMOD_SYSTEM_DEFAULT_MODULES:	Mila:gcc/7.4.0
INFO 2022-05-20 12:52:26,405 env.py:  50: LMOD_VERSION:	8.3.17
INFO 2022-05-20 12:52:26,405 env.py:  50: LMOD_sys:	Linux
INFO 2022-05-20 12:52:26,406 env.py:  50: LOADEDMODULES:	Mila:gcc/7.4.0:anaconda/3
INFO 2022-05-20 12:52:26,406 env.py:  50: LOCAL_RANK:	0
INFO 2022-05-20 12:52:26,407 env.py:  50: LOGNAME:	rajkuman
INFO 2022-05-20 12:52:26,408 env.py:  50: LS_COLORS:	rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
INFO 2022-05-20 12:52:26,409 env.py:  50: MAIL:	/var/mail/rajkuman
INFO 2022-05-20 12:52:26,409 env.py:  50: MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man::
INFO 2022-05-20 12:52:26,410 env.py:  50: MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:/cvmfs/config.mila.quebec/modules/Compiler:/cvmfs/config.mila.quebec/modules/Environments:/cvmfs/config.mila.quebec/modules/Cuda:/cvmfs/config.mila.quebec/modules/Pytorch:/cvmfs/config.mila.quebec/modules/Tensorflow
INFO 2022-05-20 12:52:26,411 env.py:  50: MODULEPATH_ROOT:	/cvmfs/config.mila.quebec/modules
INFO 2022-05-20 12:52:26,412 env.py:  50: MODULERCFILE:	/cvmfs/config.mila.quebec/etc/lmod/modulerc.lua
INFO 2022-05-20 12:52:26,412 env.py:  50: MODULESHOME:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-20 12:52:26,413 env.py:  50: OLDPWD:	/home/mila/r/rajkuman/mina/mphil-vissl/configs
INFO 2022-05-20 12:52:26,414 env.py:  50: PATH:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin:/home/mila/r/rajkuman/.local/bin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/condabin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:/opt/slurm/bin:/sbin:/bin:/usr/sbin:/usr/bin
INFO 2022-05-20 12:52:26,414 env.py:  50: PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig
INFO 2022-05-20 12:52:26,415 env.py:  50: PROCESSOR_ARCHITECTURE:	amd64
INFO 2022-05-20 12:52:26,415 env.py:  50: PWD:	/home/mila/r/rajkuman/mina/mphil-vissl
INFO 2022-05-20 12:52:26,416 env.py:  50: PYTHONNOUSERSITE:	True
INFO 2022-05-20 12:52:26,417 env.py:  50: PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7
INFO 2022-05-20 12:52:26,417 env.py:  50: PYXTERM_DIMENSIONS:	80x25
INFO 2022-05-20 12:52:26,418 env.py:  50: RANK:	0
INFO 2022-05-20 12:52:26,419 env.py:  50: ROCR_VISIBLE_DEVICES:	0
INFO 2022-05-20 12:52:26,419 env.py:  50: SACCT_FORMAT:	User,JobID,Jobname,partition,state,time,start,end,elapsed,nnodes,ncpus,reqmem,alloctres,nodelist,workdir
INFO 2022-05-20 12:52:26,420 env.py:  50: SCRATCH:	/network/scratch/r/rajkuman
INFO 2022-05-20 12:52:26,420 env.py:  50: SHELL:	/bin/bash
INFO 2022-05-20 12:52:26,421 env.py:  50: SHLVL:	3
INFO 2022-05-20 12:52:26,421 env.py:  50: SINFO_FORMAT:	%18N %.6D %.11T %.4c %.8z %.6m %.8d %.6w %.22f %80E
INFO 2022-05-20 12:52:26,422 env.py:  50: SLURMD_NODENAME:	kepler5
INFO 2022-05-20 12:52:26,422 env.py:  50: SLURM_CLUSTER_NAME:	mila
INFO 2022-05-20 12:52:26,423 env.py:  50: SLURM_CONF:	/etc/slurm/slurm.conf
INFO 2022-05-20 12:52:26,423 env.py:  50: SLURM_CPUS_ON_NODE:	4
INFO 2022-05-20 12:52:26,424 env.py:  50: SLURM_CPUS_PER_TASK:	4
INFO 2022-05-20 12:52:26,424 env.py:  50: SLURM_EXPORT_ENV:	PATH,LANG,USER,HOME,SHELL,JUPYTERHUB_API_TOKEN,JPY_API_TOKEN,JUPYTERHUB_CLIENT_ID,JUPYTERHUB_HOST,JUPYTERHUB_OAUTH_CALLBACK_URL,JUPYTERHUB_USER,JUPYTERHUB_SERVER_NAME,JUPYTERHUB_API_URL,JUPYTERHUB_ACTIVITY_URL,JUPYTERHUB_BASE_URL,JUPYTERHUB_SERVICE_PREFIX
INFO 2022-05-20 12:52:26,425 env.py:  50: SLURM_GET_USER_ENV:	1
INFO 2022-05-20 12:52:26,426 env.py:  50: SLURM_GTIDS:	0
INFO 2022-05-20 12:52:26,426 env.py:  50: SLURM_JOBID:	1843477
INFO 2022-05-20 12:52:26,427 env.py:  50: SLURM_JOB_ACCOUNT:	mila
INFO 2022-05-20 12:52:26,427 env.py:  50: SLURM_JOB_CPUS_PER_NODE:	4
INFO 2022-05-20 12:52:26,428 env.py:  50: SLURM_JOB_GID:	1471600619
INFO 2022-05-20 12:52:26,428 env.py:  50: SLURM_JOB_GPUS:	1
INFO 2022-05-20 12:52:26,429 env.py:  50: SLURM_JOB_ID:	1843477
INFO 2022-05-20 12:52:26,429 env.py:  50: SLURM_JOB_NAME:	jupyterhub-rajkuman
INFO 2022-05-20 12:52:26,430 env.py:  50: SLURM_JOB_NODELIST:	kepler5
INFO 2022-05-20 12:52:26,431 env.py:  50: SLURM_JOB_NUM_NODES:	1
INFO 2022-05-20 12:52:26,431 env.py:  50: SLURM_JOB_PARTITION:	unkillable
INFO 2022-05-20 12:52:26,432 env.py:  50: SLURM_JOB_QOS:	normal
INFO 2022-05-20 12:52:26,433 env.py:  50: SLURM_JOB_UID:	1471600619
INFO 2022-05-20 12:52:26,433 env.py:  50: SLURM_JOB_USER:	rajkuman
INFO 2022-05-20 12:52:26,434 env.py:  50: SLURM_LOCALID:	0
INFO 2022-05-20 12:52:26,434 env.py:  50: SLURM_MEM_PER_NODE:	24000
INFO 2022-05-20 12:52:26,435 env.py:  50: SLURM_NNODES:	1
INFO 2022-05-20 12:52:26,436 env.py:  50: SLURM_NODEID:	0
INFO 2022-05-20 12:52:26,436 env.py:  50: SLURM_NODELIST:	kepler5
INFO 2022-05-20 12:52:26,437 env.py:  50: SLURM_NODE_ALIASES:	(null)
INFO 2022-05-20 12:52:26,437 env.py:  50: SLURM_NPROCS:	1
INFO 2022-05-20 12:52:26,438 env.py:  50: SLURM_NTASKS:	1
INFO 2022-05-20 12:52:26,439 env.py:  50: SLURM_PRIO_PROCESS:	0
INFO 2022-05-20 12:52:26,439 env.py:  50: SLURM_PROCID:	0
INFO 2022-05-20 12:52:26,440 env.py:  50: SLURM_SUBMIT_DIR:	/var/lib/jupyterhub
INFO 2022-05-20 12:52:26,440 env.py:  50: SLURM_SUBMIT_HOST:	jupyter
INFO 2022-05-20 12:52:26,441 env.py:  50: SLURM_TASKS_PER_NODE:	1
INFO 2022-05-20 12:52:26,442 env.py:  50: SLURM_TASK_PID:	5314
INFO 2022-05-20 12:52:26,443 env.py:  50: SLURM_TMPDIR:	/Tmp/slurm.1843477.0
INFO 2022-05-20 12:52:26,444 env.py:  50: SLURM_TOPOLOGY_ADDR:	kepler5
INFO 2022-05-20 12:52:26,444 env.py:  50: SLURM_TOPOLOGY_ADDR_PATTERN:	node
INFO 2022-05-20 12:52:26,445 env.py:  50: SLURM_WORKING_CLUSTER:	mila:slurm:6817:9216:109
INFO 2022-05-20 12:52:26,446 env.py:  50: SQUEUE_FORMAT:	%.8i %.8u %.12P %.14j %.3t %16S %.10M %.5D %.4C %.10b %.7m %N (%r) %k
INFO 2022-05-20 12:52:26,447 env.py:  50: S_COLORS:	auto
INFO 2022-05-20 12:52:26,447 env.py:  50: TERM:	xterm
INFO 2022-05-20 12:52:26,448 env.py:  50: TMPDIR:	/tmp
INFO 2022-05-20 12:52:26,449 env.py:  50: USER:	rajkuman
INFO 2022-05-20 12:52:26,449 env.py:  50: WORLD_SIZE:	1
INFO 2022-05-20 12:52:26,450 env.py:  50: XDG_SESSION_ID:	c415
INFO 2022-05-20 12:52:26,451 env.py:  50: _:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin/python
INFO 2022-05-20 12:52:26,451 env.py:  50: _CE_CONDA:	
INFO 2022-05-20 12:52:26,452 env.py:  50: _CE_M:	
INFO 2022-05-20 12:52:26,453 env.py:  50: _LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua
INFO 2022-05-20 12:52:26,454 env.py:  50: _ModuleTable001_:	X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtNaWxhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL01pbGEubHVhIixbImZ1bGxOYW1lIl09Ik1pbGEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17bG1vZD17WyJzdGlja3kiXT0xLH0sfSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJNaWxhIix9LGFuYWNvbmRhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL2FuYWNvbmRhLzMubHVhIixbImZ1bGxOYW1lIl09ImFuYWNvbmRh
INFO 2022-05-20 12:52:26,454 env.py:  50: _ModuleTable002_:	LzMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJhbmFjb25kYS8zIix9LGdjYz17WyJmbiJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZS9nY2MvNy40LjAubHVhIixbImZ1bGxOYW1lIl09ImdjYy83LjQuMCIsWyJsb2FkT3JkZXIiXT0yLHByb3BUPXtsbW9kPXtbInN0aWNreSJdPTEsfSx9LFsic3RhY2tEZXB0aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09ImdjYy83LjQuMCIsfSx9LG1wYXRoQT17Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Nv
INFO 2022-05-20 12:52:26,455 env.py:  50: _ModuleTable003_:	bXBpbGVyIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50cyIsIi9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9DdWRhIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL1B5dG9yY2giLCIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZTovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29tcGlsZXI6L2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50czovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ3VkYTovY3Zt
INFO 2022-05-20 12:52:26,455 env.py:  50: _ModuleTable004_:	ZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvUHl0b3JjaDovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfQ==
INFO 2022-05-20 12:52:26,456 env.py:  50: _ModuleTable_Sz_:	4
INFO 2022-05-20 12:52:26,456 env.py:  50: __Init_Default_Modules:	1
INFO 2022-05-20 12:52:26,457 env.py:  50: __LMOD_REF_COUNT_CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1
INFO 2022-05-20 12:52:26,458 env.py:  50: __LMOD_REF_COUNT_CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0:1
INFO 2022-05-20 12:52:26,459 env.py:  50: __LMOD_REF_COUNT_CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include:1
INFO 2022-05-20 12:52:26,459 env.py:  50: __LMOD_REF_COUNT_CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3:1
INFO 2022-05-20 12:52:26,460 env.py:  50: __LMOD_REF_COUNT_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib:1
INFO 2022-05-20 12:52:26,460 env.py:  50: __LMOD_REF_COUNT_LOADEDMODULES:	Mila:1;gcc/7.4.0:1;anaconda/3:1
INFO 2022-05-20 12:52:26,461 env.py:  50: __LMOD_REF_COUNT_MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man:1
INFO 2022-05-20 12:52:26,462 env.py:  50: __LMOD_REF_COUNT_MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:1;/cvmfs/config.mila.quebec/modules/Compiler:1;/cvmfs/config.mila.quebec/modules/Environments:1;/cvmfs/config.mila.quebec/modules/Cuda:1;/cvmfs/config.mila.quebec/modules/Pytorch:1;/cvmfs/config.mila.quebec/modules/Tensorflow:1
INFO 2022-05-20 12:52:26,463 env.py:  50: __LMOD_REF_COUNT_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:1;/opt/slurm/bin:1;/sbin:1;/bin:1;/usr/sbin:1;/usr/bin:1
INFO 2022-05-20 12:52:26,463 env.py:  50: __LMOD_REF_COUNT_PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig:1
INFO 2022-05-20 12:52:26,464 env.py:  50: __LMOD_REF_COUNT_PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7:1
INFO 2022-05-20 12:52:26,465 env.py:  50: __LMOD_REF_COUNT__LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:1;/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:1;/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua:1
INFO 2022-05-20 12:52:26,466 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 12:52:26,466 train.py: 105: Setting seed....
INFO 2022-05-20 12:52:26,467 misc.py: 173: MACHINE SEED: 28
INFO 2022-05-20 12:52:26,511 hydra_config.py: 132: Training with config:
INFO 2022-05-20 12:52:26,527 hydra_config.py: 141: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints/before_poison/upstream',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 4,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/cifar100/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['CIFAR100-upstream'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 256,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/cifar100/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['CIFAR100-upstream'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'Resize', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'CHECK_NAN': True,
           'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 200,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': ['res5'],
                                    'num_meters': 1,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'model_output_mask': False,
            'name': 'accuracy_list_meter',
            'names': ['accuracy_list_meter'],
            'precision_at_k_list_meter': {'meter_names': [],
                                          'num_meters': 1,
                                          'topk_values': [1]},
            'recall_at_k_list_meter': {'meter_names': [],
                                       'num_meters': 1,
                                       'topk_values': [1]}},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'BASE_MODEL_NAME': 'multi_input_output_model',
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['res5',
                                                                        ['AdaptiveAvgPool2d',
                                                                         [[1,
                                                                           1]]]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['eval_mlp',
                                {'dims': [2048, 100], 'in_channels': 2048}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': 8,
                              'SYNC_BN_TYPE': 'apex'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'BLOCK': 'Bottleneck',
                                 'CONV1_KERNEL': 7,
                                 'CONV1_PADDING': 3,
                                 'CONV1_STRIDE': 2,
                                 'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'MAXPOOL': True,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': './checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0005},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 28,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.01,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [8, 16, 24],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.01,
                                                      0.001,
                                                      0.0001,
                                                      1e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.01,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [8, 16, 24],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.01,
                                                           0.001,
                                                           0.0001,
                                                           1e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0005},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2022-05-20 12:52:35,043 train.py: 117: System config:
-------------------  ---------------------------------------------------------------------------------------------------------------
sys.platform         linux
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                1.19.5
Pillow               9.0.1
vissl                0.1.6 @/home/mila/r/rajkuman/mina/mphil-vissl/vissl
GPU available        True
GPU 0                Tesla V100-PCIE-16GB
CUDA_HOME            /usr/local/cuda
torchvision          0.9.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torchvision
hydra                1.0.7 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/hydra_core-1.0.7-py3.8.egg/hydra
classy_vision        0.7.0.dev @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/classy_vision
tensorboard          2.9.0
apex                 0.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/apex
PyTorch              1.8.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  -----------------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               16
On-line CPU(s) list  0-15
Thread(s) per core   2
Core(s) per socket   4
Socket(s)            2
NUMA node(s)         2
Vendor ID            GenuineIntel
CPU family           6
Model                63
Model name           Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz
Stepping             2
CPU MHz              1639.570
CPU max MHz          3500.0000
CPU min MHz          1200.0000
BogoMIPS             5999.93
Virtualization       VT-x
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             10240K
NUMA node0 CPU(s)    0-3,8-11
NUMA node1 CPU(s)    4-7,12-15
-------------------  -----------------------------------------
INFO 2022-05-20 12:52:35,050 trainer_main.py: 112: Using Distributed init method: tcp://localhost:58447, world_size: 1, rank: 0
INFO 2022-05-20 12:52:35,072 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2022-05-20 12:52:35,073 trainer_main.py: 130: | initialized host kepler5 as rank 0 (0)
INFO 2022-05-20 12:52:51,925 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2022-05-20 12:52:51,927 train_task.py: 455: Building model....
INFO 2022-05-20 12:52:51,927 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2022-05-20 12:52:51,928 resnext.py:  66: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2022-05-20 12:52:51,929 resnext.py:  93: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2022-05-20 12:52:52,699 feature_extractor.py:  50: Freezing model trunk...
INFO 2022-05-20 12:52:52,720 model_helpers.py: 178: Using SyncBN group size: 1
INFO 2022-05-20 12:52:52,721 model_helpers.py: 182: Converting BN layers to Apex SyncBN
INFO 2022-05-20 12:52:52,722 distributed_c10d.py: 187: Added key: store_based_barrier_key:2 to store for rank: 0
INFO 2022-05-20 12:52:52,732 train_task.py: 472: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2022-05-20 12:52:52,732 base_ssl_model.py: 195: Freezing model trunk...
INFO 2022-05-20 12:52:52,739 train_task.py: 429: Initializing model from: ./checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch
INFO 2022-05-20 12:52:52,742 util.py: 276: Attempting to load checkpoint from ./checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch
INFO 2022-05-20 12:52:56,257 util.py: 281: Loaded checkpoint from ./checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch
INFO 2022-05-20 12:52:56,258 util.py: 240: Broadcasting checkpoint loaded from ./checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch
INFO 2022-05-20 12:53:04,805 train_task.py: 435: Checkpoint loaded: ./checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch...
INFO 2022-05-20 12:53:04,818 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2022-05-20 12:53:04,819 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,820 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,821 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,821 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,822 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,823 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,823 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,824 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,825 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,826 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,826 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,828 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,829 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,829 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,830 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,831 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,832 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,833 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,833 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,834 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,835 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,836 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,836 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,837 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,838 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,839 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,839 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,840 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,841 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2022-05-20 12:53:04,843 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,843 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,844 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,845 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,846 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,846 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,847 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,848 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,849 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,850 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,850 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,851 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,852 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,853 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,854 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,855 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,856 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,856 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,857 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,858 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,859 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,860 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,860 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,861 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,862 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,863 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,863 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,864 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,865 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 12:53:04,866 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,866 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,867 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,868 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,869 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,870 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,870 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,871 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,872 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,873 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,873 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,874 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,875 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,876 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,877 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,877 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,878 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,879 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,880 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,881 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,881 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,882 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,883 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,884 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,884 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,885 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,886 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,887 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,888 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,888 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,889 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2022-05-20 12:53:04,890 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,891 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,891 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,892 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,893 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,894 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,895 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,895 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,896 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,897 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,898 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,899 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,900 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,901 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,901 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,902 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,903 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,904 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,905 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,905 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,906 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,907 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,907 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,908 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,910 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,910 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,911 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,912 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,912 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,913 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,914 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,915 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,916 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,917 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,917 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,918 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,919 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,920 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,922 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,922 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,923 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,924 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,925 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,925 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,927 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,929 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,930 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 12:53:04,931 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,932 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,932 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,933 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,934 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,935 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:04,936 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,936 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,937 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,938 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,939 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,940 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,940 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,942 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,943 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,944 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,945 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,945 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,946 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,947 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,948 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,950 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,950 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,951 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,952 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,953 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,954 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,955 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,956 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,957 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,958 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2022-05-20 12:53:04,959 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,960 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,962 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,962 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,963 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,964 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,967 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,968 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,969 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,970 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,970 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,971 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,972 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,973 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,973 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,974 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,975 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,976 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,977 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,978 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,979 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,979 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,980 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,981 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,982 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,984 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,985 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,985 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,986 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,986 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2022-05-20 12:53:04,987 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,988 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,989 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,989 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,990 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:04,991 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2022-05-20 12:53:04,992 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:04,993 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,994 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,995 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,995 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:04,996 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2022-05-20 12:53:04,998 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:04,999 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,000 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,000 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,001 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,002 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,003 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,003 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,005 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,006 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,007 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,008 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,009 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,010 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,011 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,012 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,013 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,014 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2022-05-20 12:53:05,017 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:05,017 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,018 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,019 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,020 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,020 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,021 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,022 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,023 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,024 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,024 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,025 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,026 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,026 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,027 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,028 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,029 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,029 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2022-05-20 12:53:05,030 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:05,031 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,032 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,033 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,033 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 12:53:05,035 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,036 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,036 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,037 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,038 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,039 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 12:53:05,039 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,040 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,041 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,042 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,042 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,043 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,044 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2022-05-20 12:53:05,046 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:05,047 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,048 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,049 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,049 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,050 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,051 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,052 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,053 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,054 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,054 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,055 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,057 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,058 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,059 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,060 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,060 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,061 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2022-05-20 12:53:05,063 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,063 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,064 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,065 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,066 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,067 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2022-05-20 12:53:05,069 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:05,071 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,072 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,073 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,074 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,075 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,076 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,077 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,078 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,079 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,080 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,081 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,082 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,083 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,084 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,085 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,085 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,086 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2022-05-20 12:53:05,088 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 12:53:05,089 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,090 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,090 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,091 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 12:53:05,092 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2022-05-20 12:53:05,093 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 12:53:05,094 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,095 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,096 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,096 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 12:53:05,097 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2022-05-20 12:53:05,098 checkpoint.py: 894: Not found:		heads.0.channel_bn.weight, not initialized
INFO 2022-05-20 12:53:05,098 checkpoint.py: 894: Not found:		heads.0.channel_bn.bias, not initialized
INFO 2022-05-20 12:53:05,099 checkpoint.py: 894: Not found:		heads.0.channel_bn.running_mean, not initialized
INFO 2022-05-20 12:53:05,100 checkpoint.py: 894: Not found:		heads.0.channel_bn.running_var, not initialized
INFO 2022-05-20 12:53:05,101 checkpoint.py: 851: Ignored layer:	heads.0.channel_bn.num_batches_tracked
INFO 2022-05-20 12:53:05,101 checkpoint.py: 894: Not found:		heads.0.clf.clf.0.weight, not initialized
INFO 2022-05-20 12:53:05,102 checkpoint.py: 894: Not found:		heads.0.clf.clf.0.bias, not initialized
INFO 2022-05-20 12:53:05,103 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['heads.0.projection_head.0.weight', 'heads.0.projection_head.0.bias', 'heads.0.projection_head.1.weight', 'heads.0.projection_head.1.bias', 'heads.0.projection_head.1.running_mean', 'heads.0.projection_head.1.running_var', 'heads.0.projection_head.1.num_batches_tracked', 'heads.0.projection_head.3.weight', 'heads.0.projection_head.3.bias', 'heads.0.prototypes0.weight']
INFO 2022-05-20 12:53:05,111 train_task.py: 656: Broadcast model BN buffers from primary on every forward pass
INFO 2022-05-20 12:53:05,112 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2022-05-20 12:53:05,195 optimizer_helper.py: 293: 
Trainable params: 4, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 0, 
Trunk Unregularized Parameters 0, 
Head Regularized Parameters: 2, 
Head Unregularized Parameters: 2 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2022-05-20 12:53:05,199 ssl_dataset.py: 156: Rank: 0 split: TEST Data files:
['data/CIFAR-100-upstream/test']
INFO 2022-05-20 12:53:05,200 ssl_dataset.py: 159: Rank: 0 split: TEST Label files:
['data/CIFAR-100-upstream/test']
INFO 2022-05-20 12:53:05,548 disk_dataset.py:  86: Loaded 9000 samples from folder data/CIFAR-100-upstream/test
INFO 2022-05-20 12:53:05,550 ssl_dataset.py: 156: Rank: 0 split: TRAIN Data files:
['data/CIFAR-100-upstream/train']
INFO 2022-05-20 12:53:05,551 ssl_dataset.py: 159: Rank: 0 split: TRAIN Label files:
['data/CIFAR-100-upstream/train']
INFO 2022-05-20 12:53:06,793 disk_dataset.py:  86: Loaded 45000 samples from folder data/CIFAR-100-upstream/train
INFO 2022-05-20 12:53:06,794 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 12:53:06,795 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-20 12:53:06,796 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 12:53:06,797 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-20 12:53:06,799 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 12:53:06,800 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-20 12:53:06,801 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 12:53:06,802 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-20 12:53:06,803 train_task.py: 384: Building loss...
INFO 2022-05-20 12:53:06,804 trainer_main.py: 268: Training 28 epochs
INFO 2022-05-20 12:53:06,805 trainer_main.py: 269: One epoch = 176 iterations.
INFO 2022-05-20 12:53:06,806 trainer_main.py: 270: Total 45000 samples in one epoch
INFO 2022-05-20 12:53:06,807 trainer_main.py: 276: Total 4928 iterations for training
INFO 2022-05-20 12:53:06,954 logger.py:  84: Fri May 20 12:53:06 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:82:00.0 Off |                    0 |
| N/A   40C    P0    37W / 250W |   8104MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      7034      C   python                           6833MiB |
|    0   N/A  N/A     20264      C   python                           1265MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-20 12:53:06,960 trainer_main.py: 173: Model is:
 Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)
              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AdaptiveAvgPool2d(output_size=[1, 1])
    )
  )
  (heads): ModuleList(
    (0): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=2048, out_features=100, bias=True)
        )
      )
    )
  )
)
INFO 2022-05-20 12:53:06,961 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2022-05-20 12:53:06,962 trainer_main.py: 175: Starting training....
INFO 2022-05-20 12:53:06,963 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 12:54:42,580 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 12:54:42,584 log_hooks.py:  76: ========= Memory Summary at on_phase_start =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  244460 KB |  244460 KB |  244461 KB |     512 B  |
|       from large pool |  225792 KB |  225792 KB |  225792 KB |       0 B  |
|       from small pool |   18668 KB |   18668 KB |   18669 KB |     512 B  |
|---------------------------------------------------------------------------|
| Active memory         |  244460 KB |  244460 KB |  244461 KB |     512 B  |
|       from large pool |  225792 KB |  225792 KB |  225792 KB |       0 B  |
|       from small pool |   18668 KB |   18668 KB |   18669 KB |     512 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  276480 KB |  276480 KB |  276480 KB |       0 B  |
|       from large pool |  253952 KB |  253952 KB |  253952 KB |       0 B  |
|       from small pool |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   32019 KB |   32023 KB |   91512 KB |   59493 KB |
|       from large pool |   28160 KB |   28160 KB |   74496 KB |   46336 KB |
|       from small pool |    3859 KB |    3863 KB |   17016 KB |   13157 KB |
|---------------------------------------------------------------------------|
| Allocations           |     329    |     329    |     330    |       1    |
|       from large pool |      18    |      18    |      18    |       0    |
|       from small pool |     311    |     311    |     312    |       1    |
|---------------------------------------------------------------------------|
| Active allocs         |     329    |     329    |     330    |       1    |
|       from large pool |      18    |      18    |      18    |       0    |
|       from small pool |     311    |     311    |     312    |       1    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      17    |      17    |      17    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |      11    |      11    |      11    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |       9    |      17    |       8    |
|       from large pool |       5    |       5    |       5    |       0    |
|       from small pool |       4    |       5    |      12    |       8    |
|===========================================================================|


INFO 2022-05-20 12:54:42,586 state_update_hooks.py: 115: Starting phase 0 [train]
INFO 2022-05-20 12:54:45,742 log_hooks.py:  76: ========= Memory Summary at on_forward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  401767 KB |    4202 MB |   59478 MB |   59086 MB |
|       from large pool |  382976 KB |    4184 MB |   59459 MB |   59085 MB |
|       from small pool |   18791 KB |      18 MB |      18 MB |       0 MB |
|---------------------------------------------------------------------------|
| Active memory         |  401767 KB |    4202 MB |   59478 MB |   59086 MB |
|       from large pool |  382976 KB |    4184 MB |   59459 MB |   59085 MB |
|       from small pool |   18791 KB |      18 MB |      18 MB |       0 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    5512 MB |    7760 MB |   23082 MB |   17570 MB |
|       from large pool |    5490 MB |    7738 MB |   23060 MB |   17570 MB |
|       from small pool |      22 MB |      22 MB |      22 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   26265 KB |    3598 MB |   42064 MB |   42038 MB |
|       from large pool |   22528 KB |    3594 MB |   42047 MB |   42025 MB |
|       from small pool |    3737 KB |       3 MB |      17 MB |      13 MB |
|---------------------------------------------------------------------------|
| Allocations           |     339    |     344    |     539    |     200    |
|       from large pool |      21    |      24    |     165    |     144    |
|       from small pool |     318    |     324    |     374    |      56    |
|---------------------------------------------------------------------------|
| Active allocs         |     339    |     344    |     539    |     200    |
|       from large pool |      21    |      24    |     165    |     144    |
|       from small pool |     318    |     324    |     374    |      56    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      20    |      22    |      30    |      10    |
|       from large pool |       9    |      11    |      19    |      10    |
|       from small pool |      11    |      11    |      11    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      13    |      91    |      81    |
|       from large pool |       3    |       9    |      70    |      67    |
|       from small pool |       7    |       7    |      21    |      14    |
|===========================================================================|


INFO 2022-05-20 12:54:45,837 log_hooks.py:  76: ========= Memory Summary at on_backward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  396936 KB |    4202 MB |   59483 MB |   59095 MB |
|       from large pool |  377344 KB |    4184 MB |   59462 MB |   59094 MB |
|       from small pool |   19592 KB |      19 MB |      20 MB |       1 MB |
|---------------------------------------------------------------------------|
| Active memory         |  396936 KB |    4202 MB |   59483 MB |   59095 MB |
|       from large pool |  377344 KB |    4184 MB |   59462 MB |   59094 MB |
|       from small pool |   19592 KB |      19 MB |      20 MB |       1 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    5512 MB |    7760 MB |   23082 MB |   17570 MB |
|       from large pool |    5490 MB |    7738 MB |   23060 MB |   17570 MB |
|       from small pool |      22 MB |      22 MB |      22 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   31096 KB |    3598 MB |   42073 MB |   42043 MB |
|       from large pool |   28160 KB |    3594 MB |   42055 MB |   42028 MB |
|       from small pool |    2936 KB |       3 MB |      17 MB |      15 MB |
|---------------------------------------------------------------------------|
| Allocations           |     340    |     348    |     567    |     227    |
|       from large pool |      19    |      24    |     166    |     147    |
|       from small pool |     321    |     327    |     401    |      80    |
|---------------------------------------------------------------------------|
| Active allocs         |     340    |     348    |     567    |     227    |
|       from large pool |      19    |      24    |     166    |     147    |
|       from small pool |     321    |     327    |     401    |      80    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      20    |      22    |      30    |      10    |
|       from large pool |       9    |      11    |      19    |      10    |
|       from small pool |      11    |      11    |      11    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      12    |      13    |     100    |      88    |
|       from large pool |       5    |       9    |      73    |      68    |
|       from small pool |       7    |       9    |      27    |      20    |
|===========================================================================|


INFO 2022-05-20 12:54:45,841 log_hooks.py:  76: ========= Memory Summary at on_update =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  397752 KB |    4202 MB |   59485 MB |   59096 MB |
|       from large pool |  377344 KB |    4184 MB |   59462 MB |   59094 MB |
|       from small pool |   20408 KB |      21 MB |      22 MB |       2 MB |
|---------------------------------------------------------------------------|
| Active memory         |  397752 KB |    4202 MB |   59485 MB |   59096 MB |
|       from large pool |  377344 KB |    4184 MB |   59462 MB |   59094 MB |
|       from small pool |   20408 KB |      21 MB |      22 MB |       2 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    5516 MB |    7760 MB |   23086 MB |   17570 MB |
|       from large pool |    5490 MB |    7738 MB |   23060 MB |   17570 MB |
|       from small pool |      26 MB |      26 MB |      26 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   32327 KB |    3598 MB |   42077 MB |   42045 MB |
|       from large pool |   28160 KB |    3594 MB |   42055 MB |   42028 MB |
|       from small pool |    4167 KB |       5 MB |      21 MB |      17 MB |
|---------------------------------------------------------------------------|
| Allocations           |     344    |     348    |     577    |     233    |
|       from large pool |      19    |      24    |     166    |     147    |
|       from small pool |     325    |     327    |     411    |      86    |
|---------------------------------------------------------------------------|
| Active allocs         |     344    |     348    |     577    |     233    |
|       from large pool |      19    |      24    |     166    |     147    |
|       from small pool |     325    |     327    |     411    |      86    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      22    |      22    |      32    |      10    |
|       from large pool |       9    |      11    |      19    |      10    |
|       from small pool |      13    |      13    |      13    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      14    |      15    |     104    |      90    |
|       from large pool |       5    |       9    |      73    |      68    |
|       from small pool |       9    |      10    |      31    |      22    |
|===========================================================================|


INFO 2022-05-20 12:54:45,842 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 0; lr: 0.01; loss: 4.76747; btime(ms): 0; eta: 0:00:00; peak_mem(M): 4202;
INFO 2022-05-20 12:54:46,072 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 4.66611; btime(ms): 99041; eta: 5 days, 15:32:56; peak_mem(M): 4202; max_iterations: 4928;
INFO 2022-05-20 12:54:47,000 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 5; lr: 0.01; loss: 4.04476; btime(ms): 19993; eta: 1 day, 3:20:27; peak_mem(M): 4202;
INFO 2022-05-20 12:54:48,839 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 10; lr: 0.01; loss: 3.25896; btime(ms): 10169; eta: 13:53:33; peak_mem(M): 4202;
INFO 2022-05-20 12:54:51,595 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 15; lr: 0.01; loss: 2.4549; btime(ms): 6958; eta: 9:29:45; peak_mem(M): 4202;
INFO 2022-05-20 12:54:54,211 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 20; lr: 0.01; loss: 2.1372; btime(ms): 5359; eta: 7:18:22; peak_mem(M): 4202;
INFO 2022-05-20 12:54:57,880 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 25; lr: 0.01; loss: 1.84411; btime(ms): 4390; eta: 5:58:46; peak_mem(M): 4202;
INFO 2022-05-20 12:55:00,496 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 30; lr: 0.01; loss: 1.68034; btime(ms): 3779; eta: 5:08:30; peak_mem(M): 4202;
INFO 2022-05-20 12:55:03,530 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 35; lr: 0.01; loss: 1.61043; btime(ms): 3313; eta: 4:30:15; peak_mem(M): 4202;
INFO 2022-05-20 12:55:05,796 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 40; lr: 0.01; loss: 1.43769; btime(ms): 2969; eta: 4:01:53; peak_mem(M): 4202;
INFO 2022-05-20 12:55:09,396 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 45; lr: 0.01; loss: 1.45421; btime(ms): 2694; eta: 3:39:15; peak_mem(M): 4202;
INFO 2022-05-20 12:55:11,952 logger.py:  84: Fri May 20 12:55:11 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:82:00.0 Off |                    0 |
| N/A   48C    P0    44W / 250W |  13586MiB / 16160MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      7034      C   python                           6833MiB |
|    0   N/A  N/A     20264      C   python                           6745MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-20 12:55:12,216 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 50; lr: 0.01; loss: 1.29024; btime(ms): 2498; eta: 3:23:07; peak_mem(M): 4202;
INFO 2022-05-20 12:55:14,862 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 55; lr: 0.01; loss: 1.33852; btime(ms): 2319; eta: 3:08:21; peak_mem(M): 4202;
INFO 2022-05-20 12:55:17,355 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 60; lr: 0.01; loss: 1.268; btime(ms): 2172; eta: 2:56:13; peak_mem(M): 4202;
INFO 2022-05-20 12:55:21,115 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 65; lr: 0.01; loss: 1.21393; btime(ms): 2044; eta: 2:45:40; peak_mem(M): 4202;
INFO 2022-05-20 12:55:23,742 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 70; lr: 0.01; loss: 1.30683; btime(ms): 1952; eta: 2:38:03; peak_mem(M): 4202;
INFO 2022-05-20 12:55:27,064 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 75; lr: 0.01; loss: 1.45369; btime(ms): 1861; eta: 2:30:31; peak_mem(M): 4202;
INFO 2022-05-20 12:55:30,150 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 80; lr: 0.01; loss: 1.2402; btime(ms): 1788; eta: 2:24:31; peak_mem(M): 4202;
INFO 2022-05-20 12:55:33,493 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 85; lr: 0.01; loss: 1.34239; btime(ms): 1710; eta: 2:18:04; peak_mem(M): 4202;
INFO 2022-05-20 12:55:36,107 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 90; lr: 0.01; loss: 0.99295; btime(ms): 1655; eta: 2:13:30; peak_mem(M): 4202;
INFO 2022-05-20 12:55:38,997 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 95; lr: 0.01; loss: 1.08876; btime(ms): 1595; eta: 2:08:31; peak_mem(M): 4202;
INFO 2022-05-20 12:55:41,536 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 100; lr: 0.01; loss: 1.25315; btime(ms): 1545; eta: 2:04:19; peak_mem(M): 4202;
INFO 2022-05-20 12:56:26,883 trainer_main.py: 214: Meters synced
INFO 2022-05-20 12:56:26,885 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 592
INFO 2022-05-20 12:56:26,886 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  336.57 ms  336.76 ms
             forward:   41.61 ms  237.97 ms
        loss_compute:    1.60 ms    1.55 ms
     loss_all_reduce:    0.22 ms    0.22 ms
       meters_update:    5.92 ms    6.01 ms
            backward:    3.00 ms    3.05 ms
      optimizer_step:    0.91 ms    0.95 ms
    train_step_total:  590.94 ms  590.95 ms
INFO 2022-05-20 12:56:26,887 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 61.9089}, 'top_5': {'res5': 85.8733}}
INFO 2022-05-20 12:56:26,888 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 12:56:26,896 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 12:56:26,897 log_hooks.py: 425: [phase: 0] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 12:56:28,024 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase0.torch
INFO 2022-05-20 12:56:28,025 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 12:56:28,032 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 12:56:28,033 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 12:57:59,222 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 12:57:59,224 state_update_hooks.py: 115: Starting phase 1 [test]
INFO 2022-05-20 12:58:18,785 trainer_main.py: 214: Meters synced
INFO 2022-05-20 12:58:18,794 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 543
INFO 2022-05-20 12:58:18,795 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 71.8}, 'top_5': {'res5': 93.4}}
INFO 2022-05-20 12:58:18,795 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 12:58:18,802 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 12:58:18,803 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 12:59:57,640 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 12:59:57,642 state_update_hooks.py: 115: Starting phase 2 [train]
INFO 2022-05-20 13:00:13,061 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 200; lr: 0.01; loss: 0.97911; btime(ms): 1805; eta: 2:22:15; peak_mem(M): 4202;
INFO 2022-05-20 13:01:50,575 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:01:50,577 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 641
INFO 2022-05-20 13:01:50,578 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  405.75 ms  405.83 ms
             forward:   18.40 ms  219.89 ms
        loss_compute:    1.83 ms    1.78 ms
     loss_all_reduce:    0.24 ms    0.24 ms
       meters_update:    5.83 ms    5.91 ms
            backward:    2.93 ms    2.99 ms
      optimizer_step:    0.86 ms    0.90 ms
    train_step_total:  641.35 ms  641.37 ms
INFO 2022-05-20 13:01:50,580 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 77.0578}, 'top_5': {'res5': 95.3467}}
INFO 2022-05-20 13:01:50,581 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:01:50,588 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:01:50,589 log_hooks.py: 425: [phase: 1] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:01:51,733 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase1.torch
INFO 2022-05-20 13:01:51,734 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:01:51,742 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:01:51,743 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:03:26,140 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:03:26,141 state_update_hooks.py: 115: Starting phase 3 [test]
INFO 2022-05-20 13:03:45,097 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:03:45,108 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 526
INFO 2022-05-20 13:03:45,109 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 74.32220000000001}, 'top_5': {'res5': 94.65559999999999}}
INFO 2022-05-20 13:03:45,109 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:03:45,115 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:03:45,116 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 4, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:05:10,483 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:05:10,486 state_update_hooks.py: 115: Starting phase 4 [train]
INFO 2022-05-20 13:05:44,224 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 400; lr: 0.01; loss: 0.65172; btime(ms): 1603; eta: 2:01:00; peak_mem(M): 4202;
INFO 2022-05-20 13:06:54,039 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:06:54,040 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 588
INFO 2022-05-20 13:06:54,041 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  334.92 ms  335.05 ms
             forward:   20.03 ms  231.24 ms
        loss_compute:    1.73 ms    1.75 ms
     loss_all_reduce:    0.24 ms    0.24 ms
       meters_update:    7.76 ms    7.84 ms
            backward:    3.45 ms    3.54 ms
      optimizer_step:    1.12 ms    1.13 ms
    train_step_total:  588.00 ms  588.02 ms
INFO 2022-05-20 13:06:54,042 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 81.1289}, 'top_5': {'res5': 96.6889}}
INFO 2022-05-20 13:06:54,043 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:06:54,049 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:06:54,050 log_hooks.py: 425: [phase: 2] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:06:55,167 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase2.torch
INFO 2022-05-20 13:06:55,167 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:06:55,174 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:06:55,175 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 5, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:08:14,784 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:08:14,787 state_update_hooks.py: 115: Starting phase 5 [test]
INFO 2022-05-20 13:08:32,837 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:08:32,845 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 501
INFO 2022-05-20 13:08:32,846 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 75.1333}, 'top_5': {'res5': 95.19999999999999}}
INFO 2022-05-20 13:08:32,847 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:08:32,852 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:08:32,853 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 6, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:09:54,595 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:09:54,601 state_update_hooks.py: 115: Starting phase 6 [train]
INFO 2022-05-20 13:10:34,546 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 600; lr: 0.01; loss: 0.58896; btime(ms): 1479; eta: 1:46:43; peak_mem(M): 4202;
INFO 2022-05-20 13:11:30,540 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:11:30,542 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 545
INFO 2022-05-20 13:11:30,543 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  309.75 ms  310.00 ms
             forward:   19.93 ms  216.84 ms
        loss_compute:    1.53 ms    1.50 ms
     loss_all_reduce:    0.19 ms    0.19 ms
       meters_update:    5.99 ms    6.07 ms
            backward:    2.76 ms    2.80 ms
      optimizer_step:    0.88 ms    0.90 ms
    train_step_total:  544.79 ms  544.80 ms
INFO 2022-05-20 13:11:30,544 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 83.7111}, 'top_5': {'res5': 97.37559999999999}}
INFO 2022-05-20 13:11:30,545 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:11:30,553 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:11:30,554 log_hooks.py: 425: [phase: 3] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:11:31,668 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase3.torch
INFO 2022-05-20 13:11:31,669 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:11:31,678 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:11:31,679 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 7, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:12:56,735 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:12:56,738 state_update_hooks.py: 115: Starting phase 7 [test]
INFO 2022-05-20 13:13:15,373 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:13:15,384 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 517
INFO 2022-05-20 13:13:15,385 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 76.2556}, 'top_5': {'res5': 95.38889999999999}}
INFO 2022-05-20 13:13:15,386 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:13:15,393 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:13:15,394 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 8, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:14:39,479 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:14:39,482 state_update_hooks.py: 115: Starting phase 8 [train]
INFO 2022-05-20 13:15:31,532 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 800; lr: 0.01; loss: 0.49659; btime(ms): 1424; eta: 1:37:59; peak_mem(M): 4202;
INFO 2022-05-20 13:16:12,689 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:16:12,691 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 529
INFO 2022-05-20 13:16:12,692 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  295.43 ms  295.69 ms
             forward:   19.82 ms  217.07 ms
        loss_compute:    1.44 ms    1.43 ms
     loss_all_reduce:    0.17 ms    0.17 ms
       meters_update:    6.14 ms    6.22 ms
            backward:    3.07 ms    3.14 ms
      optimizer_step:    0.87 ms    0.90 ms
    train_step_total:  529.27 ms  529.28 ms
INFO 2022-05-20 13:16:12,693 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 85.7978}, 'top_5': {'res5': 97.87780000000001}}
INFO 2022-05-20 13:16:12,693 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:16:12,699 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:16:12,700 log_hooks.py: 425: [phase: 4] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:16:13,814 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase4.torch
INFO 2022-05-20 13:16:13,814 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:16:13,822 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:16:13,823 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 9, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:17:32,272 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:17:32,274 state_update_hooks.py: 115: Starting phase 9 [test]
INFO 2022-05-20 13:17:49,005 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:17:49,013 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 464
INFO 2022-05-20 13:17:49,014 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 76.4444}, 'top_5': {'res5': 95.39999999999999}}
INFO 2022-05-20 13:17:49,014 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:17:49,020 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:17:49,021 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 10, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:19:01,117 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:19:01,118 state_update_hooks.py: 115: Starting phase 10 [train]
INFO 2022-05-20 13:20:08,922 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 1000; lr: 0.01; loss: 0.4751; btime(ms): 1373; eta: 1:29:56; peak_mem(M): 4202;
INFO 2022-05-20 13:20:36,194 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:20:36,195 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 540
INFO 2022-05-20 13:20:36,197 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  304.18 ms  304.25 ms
             forward:   18.19 ms  218.58 ms
        loss_compute:    1.57 ms    1.53 ms
     loss_all_reduce:    0.22 ms    0.22 ms
       meters_update:    7.19 ms    7.32 ms
            backward:    3.11 ms    3.21 ms
      optimizer_step:    0.95 ms    0.98 ms
    train_step_total:  539.86 ms  539.87 ms
INFO 2022-05-20 13:20:36,198 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 87.2956}, 'top_5': {'res5': 98.28}}
INFO 2022-05-20 13:20:36,199 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:20:36,205 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:20:36,206 log_hooks.py: 425: [phase: 5] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:20:37,331 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase5.torch
INFO 2022-05-20 13:20:37,331 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:20:37,338 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:20:37,339 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 11, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:21:50,241 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:21:50,241 state_update_hooks.py: 115: Starting phase 11 [test]
INFO 2022-05-20 13:22:07,197 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:22:07,205 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 471
INFO 2022-05-20 13:22:07,206 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 76.5444}, 'top_5': {'res5': 95.4222}}
INFO 2022-05-20 13:22:07,207 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:22:07,212 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:22:07,213 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 12, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:23:23,086 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:23:23,087 state_update_hooks.py: 115: Starting phase 12 [train]
INFO 2022-05-20 13:24:37,776 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 1200; lr: 0.01; loss: 0.42323; btime(ms): 1335; eta: 1:22:57; peak_mem(M): 4202;
INFO 2022-05-20 13:24:52,702 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:24:52,720 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 509
INFO 2022-05-20 13:24:52,722 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  271.37 ms  271.68 ms
             forward:   19.86 ms  218.78 ms
        loss_compute:    2.06 ms    1.97 ms
     loss_all_reduce:    0.28 ms    0.29 ms
       meters_update:    6.73 ms    6.81 ms
            backward:    3.24 ms    3.28 ms
      optimizer_step:    0.89 ms    0.93 ms
    train_step_total:  508.84 ms  508.85 ms
INFO 2022-05-20 13:24:52,725 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 88.7778}, 'top_5': {'res5': 98.53110000000001}}
INFO 2022-05-20 13:24:52,725 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:24:52,731 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:24:52,732 log_hooks.py: 425: [phase: 6] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:24:53,892 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase6.torch
INFO 2022-05-20 13:24:53,893 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:24:53,897 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:24:53,898 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 13, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:26:09,116 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:26:09,117 state_update_hooks.py: 115: Starting phase 13 [test]
INFO 2022-05-20 13:26:31,791 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:26:31,799 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 630
INFO 2022-05-20 13:26:31,800 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 76.7556}, 'top_5': {'res5': 95.5778}}
INFO 2022-05-20 13:26:31,801 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:26:31,807 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:26:31,808 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 14, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:27:47,740 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:27:47,741 state_update_hooks.py: 115: Starting phase 14 [train]
INFO 2022-05-20 13:29:17,685 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 1400; lr: 0.01; loss: 0.55084; btime(ms): 1313; eta: 1:17:15; peak_mem(M): 4202;
INFO 2022-05-20 13:29:20,258 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:29:20,260 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 525
INFO 2022-05-20 13:29:20,261 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  292.62 ms  292.93 ms
             forward:   17.62 ms  218.45 ms
        loss_compute:    1.86 ms    1.79 ms
     loss_all_reduce:    0.21 ms    0.21 ms
       meters_update:    5.20 ms    5.27 ms
            backward:    2.92 ms    2.98 ms
      optimizer_step:    0.79 ms    0.82 ms
    train_step_total:  525.37 ms  525.38 ms
INFO 2022-05-20 13:29:20,262 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 89.5933}, 'top_5': {'res5': 98.7689}}
INFO 2022-05-20 13:29:20,263 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:29:20,268 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:29:20,269 log_hooks.py: 425: [phase: 7] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:29:21,385 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase7.torch
INFO 2022-05-20 13:29:21,387 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:29:21,393 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:29:21,394 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 15, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:30:37,837 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:30:37,839 state_update_hooks.py: 115: Starting phase 15 [test]
INFO 2022-05-20 13:30:55,153 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:30:55,162 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 481
INFO 2022-05-20 13:30:55,163 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 76.8222}, 'top_5': {'res5': 95.7111}}
INFO 2022-05-20 13:30:55,164 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:30:55,170 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:30:55,170 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 16, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:32:13,728 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:32:13,729 state_update_hooks.py: 115: Starting phase 16 [train]
INFO 2022-05-20 13:33:43,427 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:33:43,429 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 509
INFO 2022-05-20 13:33:43,430 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  282.66 ms  282.94 ms
             forward:   14.52 ms  215.68 ms
        loss_compute:    0.79 ms    0.78 ms
     loss_all_reduce:    0.14 ms    0.15 ms
       meters_update:    3.92 ms    4.00 ms
            backward:    1.57 ms    1.61 ms
      optimizer_step:    0.92 ms    0.95 ms
    train_step_total:  509.38 ms  509.39 ms
INFO 2022-05-20 13:33:43,431 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 91.5667}, 'top_5': {'res5': 99.0556}}
INFO 2022-05-20 13:33:43,432 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:33:43,438 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:33:43,438 log_hooks.py: 425: [phase: 8] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:33:44,554 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase8.torch
INFO 2022-05-20 13:33:44,555 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:33:44,560 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:33:44,561 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 17, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:35:00,451 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:35:00,452 state_update_hooks.py: 115: Starting phase 17 [test]
INFO 2022-05-20 13:35:18,645 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:35:18,656 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 505
INFO 2022-05-20 13:35:18,658 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.0667}, 'top_5': {'res5': 95.6222}}
INFO 2022-05-20 13:35:18,658 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:35:18,665 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:35:18,666 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 18, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:36:39,249 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:36:39,250 state_update_hooks.py: 115: Starting phase 18 [train]
INFO 2022-05-20 13:36:48,792 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 1600; lr: 0.001; loss: 0.39984; btime(ms): 1362; eta: 1:15:34; peak_mem(M): 4202;
INFO 2022-05-20 13:38:05,128 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:38:05,130 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 487
INFO 2022-05-20 13:38:05,131 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  262.16 ms  262.45 ms
             forward:   13.86 ms  215.48 ms
        loss_compute:    0.76 ms    0.76 ms
     loss_all_reduce:    0.13 ms    0.14 ms
       meters_update:    4.21 ms    4.29 ms
            backward:    1.52 ms    1.56 ms
      optimizer_step:    0.75 ms    0.79 ms
    train_step_total:  487.69 ms  487.70 ms
INFO 2022-05-20 13:38:05,132 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 91.8244}, 'top_5': {'res5': 99.08}}
INFO 2022-05-20 13:38:05,133 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:38:05,137 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:38:05,137 log_hooks.py: 425: [phase: 9] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:38:06,245 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase9.torch
INFO 2022-05-20 13:38:06,246 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:38:06,249 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:38:06,250 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:45:58,741 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2022-05-20 13:45:58,742 env.py:  50: ARCH:	x86_64
INFO 2022-05-20 13:45:58,743 env.py:  50: BASH_ENV:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/init/bash
INFO 2022-05-20 13:45:58,743 env.py:  50: BASH_FUNC_ml%%:	() {  eval $($LMOD_DIR/ml_cmd "$@")
}
INFO 2022-05-20 13:45:58,744 env.py:  50: BASH_FUNC_module%%:	() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
INFO 2022-05-20 13:45:58,745 env.py:  50: CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64
INFO 2022-05-20 13:45:58,745 env.py:  50: CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0
INFO 2022-05-20 13:45:58,746 env.py:  50: COLUMNS:	202
INFO 2022-05-20 13:45:58,746 env.py:  50: CONDA_ACTIVATE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/etc/profile.d/conda.sh
INFO 2022-05-20 13:45:58,747 env.py:  50: CONDA_DEFAULT_ENV:	vissl_env
INFO 2022-05-20 13:45:58,747 env.py:  50: CONDA_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/conda
INFO 2022-05-20 13:45:58,748 env.py:  50: CONDA_PREFIX:	/home/mila/r/rajkuman/.conda/envs/vissl_env
INFO 2022-05-20 13:45:58,748 env.py:  50: CONDA_PROMPT_MODIFIER:	(vissl_env) 
INFO 2022-05-20 13:45:58,749 env.py:  50: CONDA_PYTHON_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/python
INFO 2022-05-20 13:45:58,749 env.py:  50: CONDA_SHLVL:	1
INFO 2022-05-20 13:45:58,750 env.py:  50: CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include
INFO 2022-05-20 13:45:58,750 env.py:  50: CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3
INFO 2022-05-20 13:45:58,751 env.py:  50: CUDA_VISIBLE_DEVICES:	0
INFO 2022-05-20 13:45:58,751 env.py:  50: ENVIRONMENT:	BATCH
INFO 2022-05-20 13:45:58,752 env.py:  50: GPU_DEVICE_ORDINAL:	0
INFO 2022-05-20 13:45:58,752 env.py:  50: HOME:	/home/mila/r/rajkuman
INFO 2022-05-20 13:45:58,753 env.py:  50: HOSTNAME:	kepler5
INFO 2022-05-20 13:45:58,753 env.py:  50: ID:	debian
INFO 2022-05-20 13:45:58,753 env.py:  50: JPY_API_TOKEN:	4de0cf5d90674b4781f11f58d29559e2
INFO 2022-05-20 13:45:58,754 env.py:  50: JUPYTERHUB_ACTIVITY_URL:	http://172.16.2.123:8081/hub/api/users/rajkuman/activity
INFO 2022-05-20 13:45:58,754 env.py:  50: JUPYTERHUB_API_TOKEN:	4de0cf5d90674b4781f11f58d29559e2
INFO 2022-05-20 13:45:58,755 env.py:  50: JUPYTERHUB_API_URL:	http://172.16.2.123:8081/hub/api
INFO 2022-05-20 13:45:58,755 env.py:  50: JUPYTERHUB_BASE_URL:	/
INFO 2022-05-20 13:45:58,755 env.py:  50: JUPYTERHUB_CLIENT_ID:	jupyterhub-user-rajkuman
INFO 2022-05-20 13:45:58,756 env.py:  50: JUPYTERHUB_HOST:	
INFO 2022-05-20 13:45:58,756 env.py:  50: JUPYTERHUB_OAUTH_CALLBACK_URL:	/user/rajkuman/oauth_callback
INFO 2022-05-20 13:45:58,756 env.py:  50: JUPYTERHUB_SERVER_NAME:	
INFO 2022-05-20 13:45:58,757 env.py:  50: JUPYTERHUB_SERVICE_PREFIX:	/user/rajkuman/
INFO 2022-05-20 13:45:58,757 env.py:  50: JUPYTERHUB_USER:	rajkuman
INFO 2022-05-20 13:45:58,758 env.py:  50: JUPYTER_SERVER_ROOT:	/home/mila/r/rajkuman
INFO 2022-05-20 13:45:58,758 env.py:  50: JUPYTER_SERVER_URL:	http://0.0.0.0:40655/user/rajkuman/
INFO 2022-05-20 13:45:58,758 env.py:  50: KERNEL_LAUNCH_TIMEOUT:	40
INFO 2022-05-20 13:45:58,759 env.py:  50: LANG:	en_US.UTF-8
INFO 2022-05-20 13:45:58,759 env.py:  50: LESSCLOSE:	/bin/lesspipe %s %s
INFO 2022-05-20 13:45:58,759 env.py:  50: LESSOPEN:	| /bin/lesspipe %s
INFO 2022-05-20 13:45:58,760 env.py:  50: LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib
INFO 2022-05-20 13:45:58,760 env.py:  50: LINES:	50
INFO 2022-05-20 13:45:58,761 env.py:  50: LMOD_CMD:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec/lmod
INFO 2022-05-20 13:45:58,761 env.py:  50: LMOD_DIR:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec
INFO 2022-05-20 13:45:58,761 env.py:  50: LMOD_PACKAGE_PATH:	/cvmfs/config.mila.quebec/etc/lmod/
INFO 2022-05-20 13:45:58,762 env.py:  50: LMOD_PKG:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-20 13:45:58,762 env.py:  50: LMOD_ROOT:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod
INFO 2022-05-20 13:45:58,763 env.py:  50: LMOD_SETTARG_FULL_SUPPORT:	no
INFO 2022-05-20 13:45:58,763 env.py:  50: LMOD_SYSTEM_DEFAULT_MODULES:	Mila:gcc/7.4.0
INFO 2022-05-20 13:45:58,763 env.py:  50: LMOD_VERSION:	8.3.17
INFO 2022-05-20 13:45:58,764 env.py:  50: LMOD_sys:	Linux
INFO 2022-05-20 13:45:58,764 env.py:  50: LOADEDMODULES:	Mila:gcc/7.4.0:anaconda/3
INFO 2022-05-20 13:45:58,765 env.py:  50: LOCAL_RANK:	0
INFO 2022-05-20 13:45:58,765 env.py:  50: LOGNAME:	rajkuman
INFO 2022-05-20 13:45:58,765 env.py:  50: LS_COLORS:	rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
INFO 2022-05-20 13:45:58,766 env.py:  50: MAIL:	/var/mail/rajkuman
INFO 2022-05-20 13:45:58,766 env.py:  50: MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man::
INFO 2022-05-20 13:45:58,767 env.py:  50: MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:/cvmfs/config.mila.quebec/modules/Compiler:/cvmfs/config.mila.quebec/modules/Environments:/cvmfs/config.mila.quebec/modules/Cuda:/cvmfs/config.mila.quebec/modules/Pytorch:/cvmfs/config.mila.quebec/modules/Tensorflow
INFO 2022-05-20 13:45:58,767 env.py:  50: MODULEPATH_ROOT:	/cvmfs/config.mila.quebec/modules
INFO 2022-05-20 13:45:58,767 env.py:  50: MODULERCFILE:	/cvmfs/config.mila.quebec/etc/lmod/modulerc.lua
INFO 2022-05-20 13:45:58,768 env.py:  50: MODULESHOME:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-20 13:45:58,768 env.py:  50: OLDPWD:	/home/mila/r/rajkuman/mina/mphil-vissl/configs
INFO 2022-05-20 13:45:58,768 env.py:  50: PATH:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin:/home/mila/r/rajkuman/.local/bin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/condabin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:/opt/slurm/bin:/sbin:/bin:/usr/sbin:/usr/bin
INFO 2022-05-20 13:45:58,769 env.py:  50: PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig
INFO 2022-05-20 13:45:58,769 env.py:  50: PROCESSOR_ARCHITECTURE:	amd64
INFO 2022-05-20 13:45:58,769 env.py:  50: PWD:	/home/mila/r/rajkuman/mina/mphil-vissl
INFO 2022-05-20 13:45:58,770 env.py:  50: PYTHONNOUSERSITE:	True
INFO 2022-05-20 13:45:58,770 env.py:  50: PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7
INFO 2022-05-20 13:45:58,771 env.py:  50: PYXTERM_DIMENSIONS:	80x25
INFO 2022-05-20 13:45:58,771 env.py:  50: RANK:	0
INFO 2022-05-20 13:45:58,771 env.py:  50: ROCR_VISIBLE_DEVICES:	0
INFO 2022-05-20 13:45:58,772 env.py:  50: SACCT_FORMAT:	User,JobID,Jobname,partition,state,time,start,end,elapsed,nnodes,ncpus,reqmem,alloctres,nodelist,workdir
INFO 2022-05-20 13:45:58,772 env.py:  50: SCRATCH:	/network/scratch/r/rajkuman
INFO 2022-05-20 13:45:58,773 env.py:  50: SHELL:	/bin/bash
INFO 2022-05-20 13:45:58,773 env.py:  50: SHLVL:	3
INFO 2022-05-20 13:45:58,773 env.py:  50: SINFO_FORMAT:	%18N %.6D %.11T %.4c %.8z %.6m %.8d %.6w %.22f %80E
INFO 2022-05-20 13:45:58,774 env.py:  50: SLURMD_NODENAME:	kepler5
INFO 2022-05-20 13:45:58,774 env.py:  50: SLURM_CLUSTER_NAME:	mila
INFO 2022-05-20 13:45:58,775 env.py:  50: SLURM_CONF:	/etc/slurm/slurm.conf
INFO 2022-05-20 13:45:58,775 env.py:  50: SLURM_CPUS_ON_NODE:	4
INFO 2022-05-20 13:45:58,775 env.py:  50: SLURM_CPUS_PER_TASK:	4
INFO 2022-05-20 13:45:58,776 env.py:  50: SLURM_EXPORT_ENV:	PATH,LANG,USER,HOME,SHELL,JUPYTERHUB_API_TOKEN,JPY_API_TOKEN,JUPYTERHUB_CLIENT_ID,JUPYTERHUB_HOST,JUPYTERHUB_OAUTH_CALLBACK_URL,JUPYTERHUB_USER,JUPYTERHUB_SERVER_NAME,JUPYTERHUB_API_URL,JUPYTERHUB_ACTIVITY_URL,JUPYTERHUB_BASE_URL,JUPYTERHUB_SERVICE_PREFIX
INFO 2022-05-20 13:45:58,776 env.py:  50: SLURM_GET_USER_ENV:	1
INFO 2022-05-20 13:45:58,776 env.py:  50: SLURM_GTIDS:	0
INFO 2022-05-20 13:45:58,777 env.py:  50: SLURM_JOBID:	1843477
INFO 2022-05-20 13:45:58,777 env.py:  50: SLURM_JOB_ACCOUNT:	mila
INFO 2022-05-20 13:45:58,778 env.py:  50: SLURM_JOB_CPUS_PER_NODE:	4
INFO 2022-05-20 13:45:58,778 env.py:  50: SLURM_JOB_GID:	1471600619
INFO 2022-05-20 13:45:58,778 env.py:  50: SLURM_JOB_GPUS:	1
INFO 2022-05-20 13:45:58,779 env.py:  50: SLURM_JOB_ID:	1843477
INFO 2022-05-20 13:45:58,779 env.py:  50: SLURM_JOB_NAME:	jupyterhub-rajkuman
INFO 2022-05-20 13:45:58,780 env.py:  50: SLURM_JOB_NODELIST:	kepler5
INFO 2022-05-20 13:45:58,780 env.py:  50: SLURM_JOB_NUM_NODES:	1
INFO 2022-05-20 13:45:58,780 env.py:  50: SLURM_JOB_PARTITION:	unkillable
INFO 2022-05-20 13:45:58,781 env.py:  50: SLURM_JOB_QOS:	normal
INFO 2022-05-20 13:45:58,781 env.py:  50: SLURM_JOB_UID:	1471600619
INFO 2022-05-20 13:45:58,782 env.py:  50: SLURM_JOB_USER:	rajkuman
INFO 2022-05-20 13:45:58,782 env.py:  50: SLURM_LOCALID:	0
INFO 2022-05-20 13:45:58,782 env.py:  50: SLURM_MEM_PER_NODE:	24000
INFO 2022-05-20 13:45:58,783 env.py:  50: SLURM_NNODES:	1
INFO 2022-05-20 13:45:58,783 env.py:  50: SLURM_NODEID:	0
INFO 2022-05-20 13:45:58,784 env.py:  50: SLURM_NODELIST:	kepler5
INFO 2022-05-20 13:45:58,784 env.py:  50: SLURM_NODE_ALIASES:	(null)
INFO 2022-05-20 13:45:58,784 env.py:  50: SLURM_NPROCS:	1
INFO 2022-05-20 13:45:58,785 env.py:  50: SLURM_NTASKS:	1
INFO 2022-05-20 13:45:58,785 env.py:  50: SLURM_PRIO_PROCESS:	0
INFO 2022-05-20 13:45:58,786 env.py:  50: SLURM_PROCID:	0
INFO 2022-05-20 13:45:58,786 env.py:  50: SLURM_SUBMIT_DIR:	/var/lib/jupyterhub
INFO 2022-05-20 13:45:58,787 env.py:  50: SLURM_SUBMIT_HOST:	jupyter
INFO 2022-05-20 13:45:58,787 env.py:  50: SLURM_TASKS_PER_NODE:	1
INFO 2022-05-20 13:45:58,787 env.py:  50: SLURM_TASK_PID:	5314
INFO 2022-05-20 13:45:58,788 env.py:  50: SLURM_TMPDIR:	/Tmp/slurm.1843477.0
INFO 2022-05-20 13:45:58,788 env.py:  50: SLURM_TOPOLOGY_ADDR:	kepler5
INFO 2022-05-20 13:45:58,789 env.py:  50: SLURM_TOPOLOGY_ADDR_PATTERN:	node
INFO 2022-05-20 13:45:58,789 env.py:  50: SLURM_WORKING_CLUSTER:	mila:slurm:6817:9216:109
INFO 2022-05-20 13:45:58,789 env.py:  50: SQUEUE_FORMAT:	%.8i %.8u %.12P %.14j %.3t %16S %.10M %.5D %.4C %.10b %.7m %N (%r) %k
INFO 2022-05-20 13:45:58,790 env.py:  50: S_COLORS:	auto
INFO 2022-05-20 13:45:58,790 env.py:  50: TERM:	xterm
INFO 2022-05-20 13:45:58,791 env.py:  50: TMPDIR:	/tmp
INFO 2022-05-20 13:45:58,791 env.py:  50: USER:	rajkuman
INFO 2022-05-20 13:45:58,792 env.py:  50: WORLD_SIZE:	1
INFO 2022-05-20 13:45:58,792 env.py:  50: XDG_SESSION_ID:	c415
INFO 2022-05-20 13:45:58,792 env.py:  50: _:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin/python
INFO 2022-05-20 13:45:58,793 env.py:  50: _CE_CONDA:	
INFO 2022-05-20 13:45:58,793 env.py:  50: _CE_M:	
INFO 2022-05-20 13:45:58,794 env.py:  50: _LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua
INFO 2022-05-20 13:45:58,794 env.py:  50: _ModuleTable001_:	X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtNaWxhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL01pbGEubHVhIixbImZ1bGxOYW1lIl09Ik1pbGEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17bG1vZD17WyJzdGlja3kiXT0xLH0sfSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJNaWxhIix9LGFuYWNvbmRhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL2FuYWNvbmRhLzMubHVhIixbImZ1bGxOYW1lIl09ImFuYWNvbmRh
INFO 2022-05-20 13:45:58,794 env.py:  50: _ModuleTable002_:	LzMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJhbmFjb25kYS8zIix9LGdjYz17WyJmbiJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZS9nY2MvNy40LjAubHVhIixbImZ1bGxOYW1lIl09ImdjYy83LjQuMCIsWyJsb2FkT3JkZXIiXT0yLHByb3BUPXtsbW9kPXtbInN0aWNreSJdPTEsfSx9LFsic3RhY2tEZXB0aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09ImdjYy83LjQuMCIsfSx9LG1wYXRoQT17Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Nv
INFO 2022-05-20 13:45:58,795 env.py:  50: _ModuleTable003_:	bXBpbGVyIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50cyIsIi9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9DdWRhIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL1B5dG9yY2giLCIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZTovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29tcGlsZXI6L2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50czovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ3VkYTovY3Zt
INFO 2022-05-20 13:45:58,795 env.py:  50: _ModuleTable004_:	ZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvUHl0b3JjaDovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfQ==
INFO 2022-05-20 13:45:58,796 env.py:  50: _ModuleTable_Sz_:	4
INFO 2022-05-20 13:45:58,796 env.py:  50: __Init_Default_Modules:	1
INFO 2022-05-20 13:45:58,797 env.py:  50: __LMOD_REF_COUNT_CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1
INFO 2022-05-20 13:45:58,797 env.py:  50: __LMOD_REF_COUNT_CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0:1
INFO 2022-05-20 13:45:58,797 env.py:  50: __LMOD_REF_COUNT_CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include:1
INFO 2022-05-20 13:45:58,798 env.py:  50: __LMOD_REF_COUNT_CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3:1
INFO 2022-05-20 13:45:58,798 env.py:  50: __LMOD_REF_COUNT_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib:1
INFO 2022-05-20 13:45:58,799 env.py:  50: __LMOD_REF_COUNT_LOADEDMODULES:	Mila:1;gcc/7.4.0:1;anaconda/3:1
INFO 2022-05-20 13:45:58,799 env.py:  50: __LMOD_REF_COUNT_MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man:1
INFO 2022-05-20 13:45:58,800 env.py:  50: __LMOD_REF_COUNT_MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:1;/cvmfs/config.mila.quebec/modules/Compiler:1;/cvmfs/config.mila.quebec/modules/Environments:1;/cvmfs/config.mila.quebec/modules/Cuda:1;/cvmfs/config.mila.quebec/modules/Pytorch:1;/cvmfs/config.mila.quebec/modules/Tensorflow:1
INFO 2022-05-20 13:45:58,800 env.py:  50: __LMOD_REF_COUNT_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:1;/opt/slurm/bin:1;/sbin:1;/bin:1;/usr/sbin:1;/usr/bin:1
INFO 2022-05-20 13:45:58,801 env.py:  50: __LMOD_REF_COUNT_PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig:1
INFO 2022-05-20 13:45:58,801 env.py:  50: __LMOD_REF_COUNT_PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7:1
INFO 2022-05-20 13:45:58,801 env.py:  50: __LMOD_REF_COUNT__LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:1;/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:1;/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua:1
INFO 2022-05-20 13:45:58,802 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 13:45:58,803 train.py: 105: Setting seed....
INFO 2022-05-20 13:45:58,803 misc.py: 173: MACHINE SEED: 28
INFO 2022-05-20 13:45:58,832 hydra_config.py: 132: Training with config:
INFO 2022-05-20 13:45:58,845 hydra_config.py: 141: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints/before_poison/upstream',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 4,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/cifar100/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['CIFAR100-upstream'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 256,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/cifar100/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['CIFAR100-upstream'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'Resize', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'CHECK_NAN': True,
           'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 200,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': ['res5'],
                                    'num_meters': 1,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'model_output_mask': False,
            'name': 'accuracy_list_meter',
            'names': ['accuracy_list_meter'],
            'precision_at_k_list_meter': {'meter_names': [],
                                          'num_meters': 1,
                                          'topk_values': [1]},
            'recall_at_k_list_meter': {'meter_names': [],
                                       'num_meters': 1,
                                       'topk_values': [1]}},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'BASE_MODEL_NAME': 'multi_input_output_model',
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['res5',
                                                                        ['AdaptiveAvgPool2d',
                                                                         [[1,
                                                                           1]]]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['eval_mlp',
                                {'dims': [2048, 100], 'in_channels': 2048}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': 8,
                              'SYNC_BN_TYPE': 'apex'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'BLOCK': 'Bottleneck',
                                 'CONV1_KERNEL': 7,
                                 'CONV1_PADDING': 3,
                                 'CONV1_STRIDE': 2,
                                 'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'MAXPOOL': True,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': './checkpoints/before_poison/upstream/params_file_cache/vissl/model_zoo/swav_4gpu_bs64_400ep_2x224_6x96_queue_swav_8node_resnet_28_07_20.5e967ca0/model_final_checkpoint_phase399.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0005},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 28,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.01,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [8, 16, 24],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.01,
                                                      0.001,
                                                      0.0001,
                                                      1e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.01,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [8, 16, 24],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.01,
                                                           0.001,
                                                           0.0001,
                                                           1e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0005},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2022-05-20 13:46:02,686 train.py: 117: System config:
-------------------  ---------------------------------------------------------------------------------------------------------------
sys.platform         linux
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                1.19.5
Pillow               9.0.1
vissl                0.1.6 @/home/mila/r/rajkuman/mina/mphil-vissl/vissl
GPU available        True
GPU 0                Tesla V100-PCIE-16GB
CUDA_HOME            /usr/local/cuda
torchvision          0.9.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torchvision
hydra                1.0.7 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/hydra_core-1.0.7-py3.8.egg/hydra
classy_vision        0.7.0.dev @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/classy_vision
tensorboard          2.9.0
apex                 0.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/apex
PyTorch              1.8.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  -----------------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               16
On-line CPU(s) list  0-15
Thread(s) per core   2
Core(s) per socket   4
Socket(s)            2
NUMA node(s)         2
Vendor ID            GenuineIntel
CPU family           6
Model                63
Model name           Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz
Stepping             2
CPU MHz              2580.390
CPU max MHz          3500.0000
CPU min MHz          1200.0000
BogoMIPS             5999.93
Virtualization       VT-x
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             10240K
NUMA node0 CPU(s)    0-3,8-11
NUMA node1 CPU(s)    4-7,12-15
-------------------  -----------------------------------------
INFO 2022-05-20 13:46:02,691 trainer_main.py: 112: Using Distributed init method: tcp://localhost:34675, world_size: 1, rank: 0
INFO 2022-05-20 13:46:02,704 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2022-05-20 13:46:02,705 trainer_main.py: 130: | initialized host kepler5 as rank 0 (0)
INFO 2022-05-20 13:46:19,899 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2022-05-20 13:46:19,901 train_task.py: 455: Building model....
INFO 2022-05-20 13:46:19,902 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2022-05-20 13:46:19,903 resnext.py:  66: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2022-05-20 13:46:19,903 resnext.py:  93: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2022-05-20 13:46:20,646 feature_extractor.py:  50: Freezing model trunk...
INFO 2022-05-20 13:46:20,666 model_helpers.py: 178: Using SyncBN group size: 1
INFO 2022-05-20 13:46:20,667 model_helpers.py: 182: Converting BN layers to Apex SyncBN
INFO 2022-05-20 13:46:20,668 distributed_c10d.py: 187: Added key: store_based_barrier_key:2 to store for rank: 0
INFO 2022-05-20 13:46:20,679 train_task.py: 472: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2022-05-20 13:46:20,679 base_ssl_model.py: 195: Freezing model trunk...
INFO 2022-05-20 13:46:20,680 train_task.py: 656: Broadcast model BN buffers from primary on every forward pass
INFO 2022-05-20 13:46:20,681 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2022-05-20 13:46:20,740 optimizer_helper.py: 293: 
Trainable params: 4, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 0, 
Trunk Unregularized Parameters 0, 
Head Regularized Parameters: 2, 
Head Unregularized Parameters: 2 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2022-05-20 13:46:20,743 util.py: 276: Attempting to load checkpoint from ./checkpoints/before_poison/upstream/model_phase9.torch
INFO 2022-05-20 13:46:22,687 util.py: 281: Loaded checkpoint from ./checkpoints/before_poison/upstream/model_phase9.torch
INFO 2022-05-20 13:46:22,688 util.py: 240: Broadcasting checkpoint loaded from ./checkpoints/before_poison/upstream/model_phase9.torch
INFO 2022-05-20 13:46:25,931 ssl_dataset.py: 156: Rank: 0 split: TEST Data files:
['data/CIFAR-100-upstream/test']
INFO 2022-05-20 13:46:25,932 ssl_dataset.py: 159: Rank: 0 split: TEST Label files:
['data/CIFAR-100-upstream/test']
INFO 2022-05-20 13:46:26,123 disk_dataset.py:  86: Loaded 9000 samples from folder data/CIFAR-100-upstream/test
INFO 2022-05-20 13:46:26,127 ssl_dataset.py: 156: Rank: 0 split: TRAIN Data files:
['data/CIFAR-100-upstream/train']
INFO 2022-05-20 13:46:26,127 ssl_dataset.py: 159: Rank: 0 split: TRAIN Label files:
['data/CIFAR-100-upstream/train']
INFO 2022-05-20 13:46:26,980 disk_dataset.py:  86: Loaded 45000 samples from folder data/CIFAR-100-upstream/train
INFO 2022-05-20 13:46:26,981 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 13:46:26,988 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-20 13:46:26,988 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:46:26,997 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-20 13:46:27,003 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-20 13:46:27,004 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-20 13:46:27,005 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:46:27,006 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-20 13:46:27,006 train_task.py: 384: Building loss...
INFO 2022-05-20 13:46:27,015 train_task.py: 759: ======Loaded loss state from checkpoint======
INFO 2022-05-20 13:46:27,016 train_task.py: 576: =======Updating classy state_dict from checkpoint=======
INFO 2022-05-20 13:46:27,016 base_ssl_model.py: 446: Rank 0: Loading Trunk state dict....
INFO 2022-05-20 13:46:27,099 base_ssl_model.py: 459: Rank 0: Loading Heads state dict....
INFO 2022-05-20 13:46:27,100 base_ssl_model.py: 474: Rank 0: Model state dict loaded!
INFO 2022-05-20 13:46:27,110 checkpoint.py: 672: Loaded: base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2022-05-20 13:46:27,111 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,111 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,112 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,112 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,113 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,113 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,114 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,114 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,115 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,115 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,116 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,116 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,117 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,118 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,118 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,119 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,119 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,120 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,120 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,121 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,121 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,122 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,123 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,123 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,124 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,125 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,125 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,126 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,126 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2022-05-20 13:46:27,127 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,127 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,128 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,128 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,129 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,129 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,130 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,131 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,131 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,132 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,132 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,133 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,134 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,134 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,135 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,136 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,136 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,136 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,137 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,137 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,138 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,139 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,139 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,140 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,140 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,141 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,141 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,142 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,142 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-20 13:46:27,143 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,143 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,144 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,144 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,145 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,145 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,146 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,146 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,147 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,148 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,148 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,149 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,149 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,150 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,151 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,151 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,152 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,152 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,153 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,154 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,154 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,155 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,155 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,156 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,156 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,157 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,158 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,158 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,159 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,159 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,159 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2022-05-20 13:46:27,160 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,161 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,161 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,162 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,162 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,163 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,163 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,164 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,164 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,165 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,165 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,166 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,167 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,167 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,168 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,168 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,169 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,169 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,170 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,170 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,171 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,171 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,172 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,173 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,173 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,173 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,174 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,175 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,175 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,176 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,176 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,177 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,177 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,177 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,178 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,178 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,179 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,179 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,179 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,180 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,180 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,181 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,181 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,182 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,182 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,183 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,184 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-20 13:46:27,184 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,184 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,185 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,185 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,186 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,186 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,187 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,188 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,188 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,189 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,189 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,190 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,191 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,191 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,192 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,192 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,193 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,193 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,194 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,194 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,195 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,195 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,196 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,196 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,196 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,197 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,197 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,198 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,198 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,199 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,199 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2022-05-20 13:46:27,200 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,200 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,201 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,202 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,202 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,203 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,203 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,204 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,205 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,205 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,206 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,207 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,207 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,208 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,208 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,209 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,209 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,210 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,210 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,211 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,211 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,212 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,212 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,213 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,213 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,214 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,215 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,215 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,215 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,216 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,216 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,217 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,217 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,218 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,218 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,219 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,219 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,220 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,220 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,220 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,221 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,221 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,222 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,222 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,223 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,223 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,224 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,224 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,225 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,225 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,226 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,226 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,227 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,227 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,228 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,228 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,229 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,230 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,230 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,231 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,231 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,232 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,232 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,233 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,233 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,234 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,234 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,235 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,235 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,236 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,236 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,237 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,237 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,238 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,238 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,239 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,239 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,240 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,240 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,241 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,241 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,242 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,242 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-20 13:46:27,243 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,243 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,244 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,244 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,245 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,245 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-20 13:46:27,246 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,246 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,247 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,247 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,248 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,249 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,249 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,250 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,250 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,251 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,251 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,252 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,252 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,253 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,253 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,254 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,255 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,256 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,256 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,257 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,257 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,258 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,258 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,259 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,259 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2022-05-20 13:46:27,260 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,261 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,262 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,263 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,263 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,264 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,264 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,265 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,265 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,266 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,266 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,267 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,267 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,267 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,268 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,268 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,269 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,269 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,270 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,271 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,271 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,272 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,272 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,273 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2022-05-20 13:46:27,273 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-20 13:46:27,274 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,274 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,275 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,275 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-20 13:46:27,276 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2022-05-20 13:46:27,276 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-20 13:46:27,277 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,277 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,278 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,278 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,279 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2022-05-20 13:46:27,279 checkpoint.py: 672: Loaded: 0.channel_bn.weight                                                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,280 checkpoint.py: 672: Loaded: 0.channel_bn.bias                                                    of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,281 checkpoint.py: 672: Loaded: 0.channel_bn.running_mean                                            of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,281 checkpoint.py: 672: Loaded: 0.channel_bn.running_var                                             of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-20 13:46:27,282 checkpoint.py: 657: Ignored layer:	0.channel_bn.num_batches_tracked
INFO 2022-05-20 13:46:27,282 checkpoint.py: 672: Loaded: 0.clf.clf.0.weight                                                   of shape: torch.Size([100, 2048]) from checkpoint
INFO 2022-05-20 13:46:27,282 checkpoint.py: 672: Loaded: 0.clf.clf.0.bias                                                     of shape: torch.Size([100]) from checkpoint
INFO 2022-05-20 13:46:27,283 checkpoint.py: 685: Extra layers not loaded from checkpoint: []
INFO 2022-05-20 13:46:27,339 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:47:32,365 trainer_main.py: 268: Training 28 epochs
INFO 2022-05-20 13:47:32,367 trainer_main.py: 269: One epoch = 176 iterations.
INFO 2022-05-20 13:47:32,369 trainer_main.py: 270: Total 45000 samples in one epoch
INFO 2022-05-20 13:47:32,371 trainer_main.py: 276: Total 4928 iterations for training
INFO 2022-05-20 13:47:32,619 logger.py:  84: Fri May 20 13:47:32 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:82:00.0 Off |                    0 |
| N/A   37C    P0    37W / 250W |   1419MiB / 16160MiB |     27%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      2772      C   python                           1415MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-20 13:47:32,690 trainer_main.py: 173: Model is:
 Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)
              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AdaptiveAvgPool2d(output_size=[1, 1])
    )
  )
  (heads): ModuleList(
    (0): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=2048, out_features=100, bias=True)
        )
      )
    )
  )
)
INFO 2022-05-20 13:47:32,692 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2022-05-20 13:47:32,696 trainer_main.py: 175: Starting training....
INFO 2022-05-20 13:47:32,697 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:48:37,681 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:48:37,682 state_update_hooks.py: 115: Starting phase 19 [test]
INFO 2022-05-20 13:48:54,200 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:48:54,209 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 459
INFO 2022-05-20 13:48:54,211 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.1333}, 'top_5': {'res5': 95.6222}}
INFO 2022-05-20 13:48:54,211 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:48:54,216 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:48:54,217 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 20, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:49:55,869 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:49:55,870 state_update_hooks.py: 115: Starting phase 20 [train]
INFO 2022-05-20 13:50:14,047 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 1800; lr: 0.001; loss: 0.36655; btime(ms): 2124; eta: 1:50:45; peak_mem(M): 4879;
INFO 2022-05-20 13:51:12,875 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:51:12,878 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 437
INFO 2022-05-20 13:51:12,880 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  202.89 ms  202.96 ms
             forward:   22.56 ms  219.78 ms
        loss_compute:    1.09 ms    1.07 ms
     loss_all_reduce:    0.19 ms    0.19 ms
       meters_update:    6.45 ms    6.53 ms
            backward:    1.88 ms    1.92 ms
      optimizer_step:    0.87 ms    0.90 ms
    train_step_total:  437.23 ms  437.25 ms
INFO 2022-05-20 13:51:12,882 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 91.9933}, 'top_5': {'res5': 99.1622}}
INFO 2022-05-20 13:51:12,883 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:51:12,886 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:51:12,887 log_hooks.py: 425: [phase: 10] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:51:14,026 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase10.torch
INFO 2022-05-20 13:51:14,027 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:51:14,032 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:51:14,033 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 21, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:52:13,730 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:52:13,732 state_update_hooks.py: 115: Starting phase 21 [test]
INFO 2022-05-20 13:52:28,559 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:52:28,568 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 412
INFO 2022-05-20 13:52:28,569 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2778}, 'top_5': {'res5': 95.64439999999999}}
INFO 2022-05-20 13:52:28,570 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:52:28,574 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:52:28,574 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 22, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:53:24,960 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:53:24,961 state_update_hooks.py: 115: Starting phase 22 [train]
INFO 2022-05-20 13:53:54,325 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 2000; lr: 0.001; loss: 0.33142; btime(ms): 1223; eta: 0:59:41; peak_mem(M): 4879;
INFO 2022-05-20 13:54:44,011 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:54:44,013 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 449
INFO 2022-05-20 13:54:44,015 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  216.77 ms  217.01 ms
             forward:   16.71 ms  215.02 ms
        loss_compute:    0.85 ms    0.85 ms
     loss_all_reduce:    0.16 ms    0.17 ms
       meters_update:    6.68 ms    6.77 ms
            backward:    1.82 ms    1.87 ms
      optimizer_step:    0.87 ms    0.92 ms
    train_step_total:  448.84 ms  448.86 ms
INFO 2022-05-20 13:54:44,016 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.02669999999999}, 'top_5': {'res5': 99.1467}}
INFO 2022-05-20 13:54:44,017 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:54:44,021 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:54:44,022 log_hooks.py: 425: [phase: 11] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:54:45,120 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase11.torch
INFO 2022-05-20 13:54:45,121 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:54:45,125 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:54:45,126 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 23, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:55:43,707 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:55:43,708 state_update_hooks.py: 115: Starting phase 23 [test]
INFO 2022-05-20 13:55:57,924 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:55:57,932 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 395
INFO 2022-05-20 13:55:57,933 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.3}, 'top_5': {'res5': 95.6333}}
INFO 2022-05-20 13:55:57,934 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:55:57,938 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:55:57,939 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 24, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:56:55,811 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:56:55,813 state_update_hooks.py: 115: Starting phase 24 [train]
INFO 2022-05-20 13:57:35,017 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 2200; lr: 0.001; loss: 0.35936; btime(ms): 1099; eta: 0:49:58; peak_mem(M): 4879;
INFO 2022-05-20 13:58:11,971 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:58:11,972 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 432
INFO 2022-05-20 13:58:11,973 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  193.80 ms  193.88 ms
             forward:   18.25 ms  215.83 ms
        loss_compute:    0.85 ms    0.84 ms
     loss_all_reduce:    0.17 ms    0.17 ms
       meters_update:    6.98 ms    7.06 ms
            backward:    1.71 ms    1.75 ms
      optimizer_step:    0.89 ms    0.93 ms
    train_step_total:  432.41 ms  432.43 ms
INFO 2022-05-20 13:58:11,975 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.1733}, 'top_5': {'res5': 99.1356}}
INFO 2022-05-20 13:58:11,975 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:58:11,979 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:58:11,980 log_hooks.py: 425: [phase: 12] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 13:58:13,087 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase12.torch
INFO 2022-05-20 13:58:13,088 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 13:58:13,092 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 13:58:13,092 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 25, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 13:59:13,286 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 13:59:13,287 state_update_hooks.py: 115: Starting phase 25 [test]
INFO 2022-05-20 13:59:27,388 trainer_main.py: 214: Meters synced
INFO 2022-05-20 13:59:27,396 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 391
INFO 2022-05-20 13:59:27,398 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2}, 'top_5': {'res5': 95.65559999999999}}
INFO 2022-05-20 13:59:27,399 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:59:27,403 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 13:59:27,404 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 26, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:00:28,353 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:00:28,354 state_update_hooks.py: 115: Starting phase 26 [train]
INFO 2022-05-20 14:01:15,783 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 2400; lr: 0.001; loss: 0.42504; btime(ms): 1049; eta: 0:44:14; peak_mem(M): 4879;
INFO 2022-05-20 14:01:41,430 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:01:41,432 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 415
INFO 2022-05-20 14:01:41,433 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  187.77 ms  188.04 ms
             forward:   13.97 ms  215.79 ms
        loss_compute:    0.80 ms    0.79 ms
     loss_all_reduce:    0.14 ms    0.15 ms
       meters_update:    5.35 ms    5.43 ms
            backward:    1.45 ms    1.50 ms
      optimizer_step:    0.76 ms    0.79 ms
    train_step_total:  414.94 ms  414.95 ms
INFO 2022-05-20 14:01:41,434 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.28}, 'top_5': {'res5': 99.1511}}
INFO 2022-05-20 14:01:41,434 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:01:41,437 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:01:41,438 log_hooks.py: 425: [phase: 13] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:01:42,543 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase13.torch
INFO 2022-05-20 14:01:42,543 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:01:42,548 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:01:42,549 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 27, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:02:42,188 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:02:42,189 state_update_hooks.py: 115: Starting phase 27 [test]
INFO 2022-05-20 14:02:55,826 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:02:55,833 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 378
INFO 2022-05-20 14:02:55,834 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.1111}, 'top_5': {'res5': 95.6778}}
INFO 2022-05-20 14:02:55,835 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:02:55,839 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:02:55,840 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 28, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:03:52,723 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:03:52,725 state_update_hooks.py: 115: Starting phase 28 [train]
INFO 2022-05-20 14:04:49,525 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 2600; lr: 0.001; loss: 0.32239; btime(ms): 1016; eta: 0:39:26; peak_mem(M): 4879;
INFO 2022-05-20 14:05:05,125 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:05:05,126 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 411
INFO 2022-05-20 14:05:05,127 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  183.01 ms  183.29 ms
             forward:   14.65 ms  216.12 ms
        loss_compute:    0.77 ms    0.76 ms
     loss_all_reduce:    0.14 ms    0.14 ms
       meters_update:    5.61 ms    5.68 ms
            backward:    1.41 ms    1.45 ms
      optimizer_step:    0.74 ms    0.77 ms
    train_step_total:  411.11 ms  411.12 ms
INFO 2022-05-20 14:05:05,129 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.2956}, 'top_5': {'res5': 99.1867}}
INFO 2022-05-20 14:05:05,129 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:05:05,133 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:05:05,133 log_hooks.py: 425: [phase: 14] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:05:06,244 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase14.torch
INFO 2022-05-20 14:05:06,245 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:05:06,249 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:05:06,251 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 29, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:06:03,213 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:06:03,216 state_update_hooks.py: 115: Starting phase 29 [test]
INFO 2022-05-20 14:06:17,235 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:06:17,242 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 389
INFO 2022-05-20 14:06:17,243 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.3}, 'top_5': {'res5': 95.65559999999999}}
INFO 2022-05-20 14:06:17,244 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:06:17,247 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:06:17,248 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 30, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:07:13,520 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:07:13,521 state_update_hooks.py: 115: Starting phase 30 [train]
INFO 2022-05-20 14:08:21,012 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 2800; lr: 0.001; loss: 0.35492; btime(ms): 993; eta: 0:35:15; peak_mem(M): 4879;
INFO 2022-05-20 14:08:26,360 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:08:26,362 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 413
INFO 2022-05-20 14:08:26,363 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  184.20 ms  184.47 ms
             forward:   14.87 ms  216.43 ms
        loss_compute:    0.81 ms    0.80 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    5.82 ms    5.90 ms
            backward:    1.56 ms    1.60 ms
      optimizer_step:    0.78 ms    0.81 ms
    train_step_total:  413.59 ms  413.60 ms
INFO 2022-05-20 14:08:26,364 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.4356}, 'top_5': {'res5': 99.1644}}
INFO 2022-05-20 14:08:26,365 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:08:26,368 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:08:26,369 log_hooks.py: 425: [phase: 15] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:08:27,476 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase15.torch
INFO 2022-05-20 14:08:27,477 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:08:27,481 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:08:27,482 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 31, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:09:24,138 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:09:24,138 state_update_hooks.py: 115: Starting phase 31 [test]
INFO 2022-05-20 14:09:38,082 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:09:38,092 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 387
INFO 2022-05-20 14:09:38,094 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2556}, 'top_5': {'res5': 95.7}}
INFO 2022-05-20 14:09:38,094 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:09:38,098 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:09:38,099 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 32, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:10:37,757 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:10:37,759 state_update_hooks.py: 115: Starting phase 32 [train]
INFO 2022-05-20 14:11:51,939 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:11:51,940 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 421
INFO 2022-05-20 14:11:51,941 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  190.11 ms  190.39 ms
             forward:   15.04 ms  216.67 ms
        loss_compute:    0.82 ms    0.82 ms
     loss_all_reduce:    0.16 ms    0.16 ms
       meters_update:    6.08 ms    6.16 ms
            backward:    1.70 ms    1.74 ms
      optimizer_step:    0.84 ms    0.88 ms
    train_step_total:  421.20 ms  421.21 ms
INFO 2022-05-20 14:11:51,943 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.4156}, 'top_5': {'res5': 99.2178}}
INFO 2022-05-20 14:11:51,943 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:11:51,947 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:11:51,948 log_hooks.py: 425: [phase: 16] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:11:53,055 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase16.torch
INFO 2022-05-20 14:11:53,056 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:11:53,060 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:11:53,061 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 33, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:12:50,889 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:12:50,890 state_update_hooks.py: 115: Starting phase 33 [test]
INFO 2022-05-20 14:13:05,355 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:13:05,362 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 402
INFO 2022-05-20 14:13:05,364 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2333}, 'top_5': {'res5': 95.6889}}
INFO 2022-05-20 14:13:05,365 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:13:05,368 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:13:05,369 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 34, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:14:05,064 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:14:05,065 state_update_hooks.py: 115: Starting phase 34 [train]
INFO 2022-05-20 14:14:09,005 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 3000; lr: 0.0001; loss: 0.33316; btime(ms): 1044; eta: 0:33:34; peak_mem(M): 4879;
INFO 2022-05-20 14:15:23,540 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:15:23,541 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 445
INFO 2022-05-20 14:15:23,542 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  217.69 ms  217.75 ms
             forward:   13.99 ms  216.73 ms
        loss_compute:    0.76 ms    0.75 ms
     loss_all_reduce:    0.14 ms    0.14 ms
       meters_update:    5.08 ms    5.15 ms
            backward:    1.53 ms    1.58 ms
      optimizer_step:    0.75 ms    0.78 ms
    train_step_total:  445.63 ms  445.64 ms
INFO 2022-05-20 14:15:23,543 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.5711}, 'top_5': {'res5': 99.2111}}
INFO 2022-05-20 14:15:23,544 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:15:23,547 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:15:23,548 log_hooks.py: 425: [phase: 17] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:15:24,656 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase17.torch
INFO 2022-05-20 14:15:24,657 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:15:24,661 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:15:24,662 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 35, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:16:26,727 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:16:26,728 state_update_hooks.py: 115: Starting phase 35 [test]
INFO 2022-05-20 14:16:41,163 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:16:41,171 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 401
INFO 2022-05-20 14:16:41,172 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.34440000000001}, 'top_5': {'res5': 95.6667}}
INFO 2022-05-20 14:16:41,173 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:16:41,177 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:16:41,178 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 36, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:17:41,275 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:17:41,275 state_update_hooks.py: 115: Starting phase 36 [train]
INFO 2022-05-20 14:17:55,618 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 3200; lr: 0.0001; loss: 0.30983; btime(ms): 1033; eta: 0:29:45; peak_mem(M): 4879;
INFO 2022-05-20 14:18:57,073 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:18:57,074 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 430
INFO 2022-05-20 14:18:57,075 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  200.33 ms  200.63 ms
             forward:   15.93 ms  216.48 ms
        loss_compute:    0.86 ms    0.86 ms
     loss_all_reduce:    0.15 ms    0.15 ms
       meters_update:    5.95 ms    6.03 ms
            backward:    1.56 ms    1.61 ms
      optimizer_step:    0.81 ms    0.85 ms
    train_step_total:  430.38 ms  430.39 ms
INFO 2022-05-20 14:18:57,077 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.56219999999999}, 'top_5': {'res5': 99.20219999999999}}
INFO 2022-05-20 14:18:57,078 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:18:57,081 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:18:57,082 log_hooks.py: 425: [phase: 18] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:18:58,193 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase18.torch
INFO 2022-05-20 14:18:58,193 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:18:58,197 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:18:58,198 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 37, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:20:00,037 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:20:00,038 state_update_hooks.py: 115: Starting phase 37 [test]
INFO 2022-05-20 14:20:14,691 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:20:14,700 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 407
INFO 2022-05-20 14:20:14,701 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2444}, 'top_5': {'res5': 95.7111}}
INFO 2022-05-20 14:20:14,701 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:20:14,706 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:20:14,706 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 38, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:21:15,339 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:21:15,340 state_update_hooks.py: 115: Starting phase 38 [train]
INFO 2022-05-20 14:21:39,993 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 3400; lr: 0.0001; loss: 0.2937; btime(ms): 1023; eta: 0:26:04; peak_mem(M): 4879;
INFO 2022-05-20 14:22:31,281 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:22:31,283 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 431
INFO 2022-05-20 14:22:31,284 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  202.03 ms  202.33 ms
             forward:   15.11 ms  216.46 ms
        loss_compute:    0.83 ms    0.82 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    5.87 ms    5.95 ms
            backward:    1.48 ms    1.52 ms
      optimizer_step:    0.83 ms    0.86 ms
    train_step_total:  431.19 ms  431.21 ms
INFO 2022-05-20 14:22:31,285 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.5844}, 'top_5': {'res5': 99.2089}}
INFO 2022-05-20 14:22:31,285 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:22:31,289 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:22:31,290 log_hooks.py: 425: [phase: 19] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:22:32,398 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase19.torch
INFO 2022-05-20 14:22:32,399 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:22:32,403 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:22:32,404 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 39, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:23:32,672 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:23:32,673 state_update_hooks.py: 115: Starting phase 39 [test]
INFO 2022-05-20 14:23:47,546 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:23:47,555 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 413
INFO 2022-05-20 14:23:47,556 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2111}, 'top_5': {'res5': 95.7222}}
INFO 2022-05-20 14:23:47,557 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:23:47,561 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:23:47,562 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 40, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:24:51,107 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:24:51,108 state_update_hooks.py: 115: Starting phase 40 [train]
INFO 2022-05-20 14:25:27,116 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 3600; lr: 0.0001; loss: 0.3792; btime(ms): 1017; eta: 0:22:30; peak_mem(M): 4879;
INFO 2022-05-20 14:26:08,649 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:26:08,650 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 440
INFO 2022-05-20 14:26:08,651 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  210.62 ms  210.90 ms
             forward:   15.32 ms  216.34 ms
        loss_compute:    0.81 ms    0.80 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    5.82 ms    5.90 ms
            backward:    1.56 ms    1.60 ms
      optimizer_step:    0.84 ms    0.88 ms
    train_step_total:  440.29 ms  440.30 ms
INFO 2022-05-20 14:26:08,653 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.66}, 'top_5': {'res5': 99.23110000000001}}
INFO 2022-05-20 14:26:08,654 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:26:08,657 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:26:08,658 log_hooks.py: 425: [phase: 20] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:26:09,718 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase20.torch
INFO 2022-05-20 14:26:09,719 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:26:09,723 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:26:09,724 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 41, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:27:10,211 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:27:10,213 state_update_hooks.py: 115: Starting phase 41 [test]
INFO 2022-05-20 14:27:24,977 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:27:24,986 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 410
INFO 2022-05-20 14:27:24,987 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2778}, 'top_5': {'res5': 95.6889}}
INFO 2022-05-20 14:27:24,988 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:27:24,992 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:27:24,993 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 42, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:28:25,505 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:28:25,505 state_update_hooks.py: 115: Starting phase 42 [train]
INFO 2022-05-20 14:29:12,237 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 3800; lr: 0.0001; loss: 0.31538; btime(ms): 1011; eta: 0:19:00; peak_mem(M): 4879;
INFO 2022-05-20 14:29:42,004 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:29:42,005 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 434
INFO 2022-05-20 14:29:42,006 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  204.32 ms  204.39 ms
             forward:   14.87 ms  216.58 ms
        loss_compute:    0.83 ms    0.82 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    5.53 ms    5.61 ms
            backward:    1.50 ms    1.54 ms
      optimizer_step:    0.82 ms    0.85 ms
    train_step_total:  434.37 ms  434.38 ms
INFO 2022-05-20 14:29:42,007 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.56}, 'top_5': {'res5': 99.2778}}
INFO 2022-05-20 14:29:42,008 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:29:42,011 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:29:42,012 log_hooks.py: 425: [phase: 21] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:29:43,111 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase21.torch
INFO 2022-05-20 14:29:43,112 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:29:43,116 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:29:43,117 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 43, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:30:46,407 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:30:46,407 state_update_hooks.py: 115: Starting phase 43 [test]
INFO 2022-05-20 14:31:00,799 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:31:00,806 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 399
INFO 2022-05-20 14:31:00,808 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.12219999999999}, 'top_5': {'res5': 95.6778}}
INFO 2022-05-20 14:31:00,809 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:31:00,813 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:31:00,814 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 44, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:31:59,972 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:31:59,974 state_update_hooks.py: 115: Starting phase 44 [train]
INFO 2022-05-20 14:32:55,803 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 4000; lr: 0.0001; loss: 0.35301; btime(ms): 1005; eta: 0:15:33; peak_mem(M): 4879;
INFO 2022-05-20 14:33:14,940 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:33:14,941 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 425
INFO 2022-05-20 14:33:14,942 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  195.95 ms  196.01 ms
             forward:   15.52 ms  216.61 ms
        loss_compute:    0.82 ms    0.81 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    6.35 ms    6.43 ms
            backward:    1.61 ms    1.65 ms
      optimizer_step:    0.80 ms    0.83 ms
    train_step_total:  425.67 ms  425.68 ms
INFO 2022-05-20 14:33:14,944 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.5733}, 'top_5': {'res5': 99.2689}}
INFO 2022-05-20 14:33:14,945 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:33:14,949 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:33:14,950 log_hooks.py: 425: [phase: 22] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:33:16,058 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase22.torch
INFO 2022-05-20 14:33:16,059 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:33:16,062 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:33:16,063 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 45, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:34:15,028 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:34:15,029 state_update_hooks.py: 115: Starting phase 45 [test]
INFO 2022-05-20 14:34:29,627 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:34:29,638 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 405
INFO 2022-05-20 14:34:29,640 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.3667}, 'top_5': {'res5': 95.7}}
INFO 2022-05-20 14:34:29,641 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:34:29,645 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:34:29,646 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 46, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:35:30,421 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:35:30,422 state_update_hooks.py: 115: Starting phase 46 [train]
INFO 2022-05-20 14:36:36,651 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 4200; lr: 0.0001; loss: 0.30977; btime(ms): 999; eta: 0:12:07; peak_mem(M): 4879;
INFO 2022-05-20 14:36:45,952 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:36:45,953 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 429
INFO 2022-05-20 14:36:45,954 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  198.39 ms  198.69 ms
             forward:   15.73 ms  216.44 ms
        loss_compute:    0.87 ms    0.86 ms
     loss_all_reduce:    0.16 ms    0.16 ms
       meters_update:    6.07 ms    6.15 ms
            backward:    1.57 ms    1.61 ms
      optimizer_step:    0.84 ms    0.88 ms
    train_step_total:  428.86 ms  428.87 ms
INFO 2022-05-20 14:36:45,956 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.7422}, 'top_5': {'res5': 99.2222}}
INFO 2022-05-20 14:36:45,956 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:36:45,960 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:36:45,960 log_hooks.py: 425: [phase: 23] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:36:47,071 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase23.torch
INFO 2022-05-20 14:36:47,072 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:36:47,076 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:36:47,077 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 47, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:37:45,322 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:37:45,324 state_update_hooks.py: 115: Starting phase 47 [test]
INFO 2022-05-20 14:37:59,130 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:37:59,139 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 383
INFO 2022-05-20 14:37:59,140 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2889}, 'top_5': {'res5': 95.65559999999999}}
INFO 2022-05-20 14:37:59,141 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:37:59,145 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:37:59,146 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 48, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:38:58,391 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:38:58,392 state_update_hooks.py: 115: Starting phase 48 [train]
INFO 2022-05-20 14:40:12,792 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:40:12,794 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 422
INFO 2022-05-20 14:40:12,795 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  192.80 ms  192.86 ms
             forward:   15.82 ms  216.72 ms
        loss_compute:    0.84 ms    0.83 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    6.17 ms    6.25 ms
            backward:    1.54 ms    1.59 ms
      optimizer_step:    0.85 ms    0.89 ms
    train_step_total:  422.42 ms  422.44 ms
INFO 2022-05-20 14:40:12,796 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.4933}, 'top_5': {'res5': 99.2244}}
INFO 2022-05-20 14:40:12,797 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:40:12,801 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:40:12,801 log_hooks.py: 425: [phase: 24] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:40:13,908 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase24.torch
INFO 2022-05-20 14:40:13,909 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:40:13,912 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:40:13,914 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 49, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:41:12,818 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:41:12,819 state_update_hooks.py: 115: Starting phase 49 [test]
INFO 2022-05-20 14:41:27,059 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:41:27,067 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 395
INFO 2022-05-20 14:41:27,069 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.1556}, 'top_5': {'res5': 95.6333}}
INFO 2022-05-20 14:41:27,069 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:41:27,073 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:41:27,074 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 50, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:42:24,393 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:42:24,396 state_update_hooks.py: 115: Starting phase 50 [train]
INFO 2022-05-20 14:42:24,788 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 4400; lr: 1e-05; loss: 0.32687; btime(ms): 1005; eta: 0:08:51; peak_mem(M): 4879;
INFO 2022-05-20 14:43:39,118 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:43:39,120 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 424
INFO 2022-05-20 14:43:39,121 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  194.53 ms  194.60 ms
             forward:   14.77 ms  216.78 ms
        loss_compute:    0.84 ms    0.84 ms
     loss_all_reduce:    0.16 ms    0.16 ms
       meters_update:    5.89 ms    5.97 ms
            backward:    1.53 ms    1.57 ms
      optimizer_step:    0.83 ms    0.86 ms
    train_step_total:  424.26 ms  424.27 ms
INFO 2022-05-20 14:43:39,122 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.6778}, 'top_5': {'res5': 99.21560000000001}}
INFO 2022-05-20 14:43:39,123 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:43:39,127 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:43:39,127 log_hooks.py: 425: [phase: 25] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:43:40,230 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase25.torch
INFO 2022-05-20 14:43:40,230 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:43:40,235 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:43:40,236 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 51, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:44:39,065 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:44:39,068 state_update_hooks.py: 115: Starting phase 51 [test]
INFO 2022-05-20 14:44:53,522 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:44:53,530 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 401
INFO 2022-05-20 14:44:53,531 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.3}, 'top_5': {'res5': 95.6889}}
INFO 2022-05-20 14:44:53,531 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:44:53,535 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:44:53,536 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 52, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:45:53,510 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:45:53,512 state_update_hooks.py: 115: Starting phase 52 [train]
INFO 2022-05-20 14:46:03,832 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 4600; lr: 1e-05; loss: 0.33669; btime(ms): 1017; eta: 0:05:33; peak_mem(M): 4879;
INFO 2022-05-20 14:47:07,519 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:47:07,521 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 420
INFO 2022-05-20 14:47:07,522 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  190.98 ms  191.04 ms
             forward:   14.59 ms  216.60 ms
        loss_compute:    0.79 ms    0.78 ms
     loss_all_reduce:    0.14 ms    0.15 ms
       meters_update:    5.23 ms    5.31 ms
            backward:    1.52 ms    1.56 ms
      optimizer_step:    0.78 ms    0.80 ms
    train_step_total:  420.23 ms  420.24 ms
INFO 2022-05-20 14:47:07,523 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.76440000000001}, 'top_5': {'res5': 99.2089}}
INFO 2022-05-20 14:47:07,524 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:47:07,527 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:47:07,528 log_hooks.py: 425: [phase: 26] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:47:08,633 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_phase26.torch
INFO 2022-05-20 14:47:08,634 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:47:08,638 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:47:08,639 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 53, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:48:05,060 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:48:05,061 state_update_hooks.py: 115: Starting phase 53 [test]
INFO 2022-05-20 14:48:18,639 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:48:18,646 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 377
INFO 2022-05-20 14:48:18,647 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2667}, 'top_5': {'res5': 95.6889}}
INFO 2022-05-20 14:48:18,648 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:48:18,652 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:48:18,652 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 54, 'num_samples': 45000, 'total_size': 45000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:49:14,915 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:49:14,917 state_update_hooks.py: 115: Starting phase 54 [train]
INFO 2022-05-20 14:49:35,680 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 4800; lr: 1e-05; loss: 0.3701; btime(ms): 1009; eta: 0:02:09; peak_mem(M): 4879;
INFO 2022-05-20 14:50:29,497 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:50:29,499 log_hooks.py: 568: Average train batch time (ms) for 176 batches: 423
INFO 2022-05-20 14:50:29,500 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  193.24 ms  193.29 ms
             forward:   15.32 ms  216.90 ms
        loss_compute:    0.81 ms    0.80 ms
     loss_all_reduce:    0.15 ms    0.16 ms
       meters_update:    5.85 ms    5.93 ms
            backward:    1.64 ms    1.68 ms
      optimizer_step:    0.79 ms    0.82 ms
    train_step_total:  423.46 ms  423.48 ms
INFO 2022-05-20 14:50:29,501 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 92.6844}, 'top_5': {'res5': 99.2289}}
INFO 2022-05-20 14:50:29,502 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:50:29,505 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:50:29,505 log_hooks.py: 425: [phase: 27] Saving checkpoint to ./checkpoints/before_poison/upstream
INFO 2022-05-20 14:50:30,608 checkpoint.py: 131: Saved checkpoint: ./checkpoints/before_poison/upstream/model_final_checkpoint_phase27.torch
INFO 2022-05-20 14:50:30,609 checkpoint.py: 140: Creating symlink...
INFO 2022-05-20 14:50:30,612 checkpoint.py: 144: Created symlink: ./checkpoints/before_poison/upstream/checkpoint.torch
INFO 2022-05-20 14:50:30,613 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 55, 'num_samples': 9000, 'total_size': 9000, 'shuffle': True, 'seed': 0}
INFO 2022-05-20 14:51:30,735 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-20 14:51:30,736 state_update_hooks.py: 115: Starting phase 55 [test]
INFO 2022-05-20 14:51:44,431 trainer_main.py: 214: Meters synced
INFO 2022-05-20 14:51:44,439 log_hooks.py: 568: Average test batch time (ms) for 36 batches: 380
INFO 2022-05-20 14:51:44,440 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 77.2556}, 'top_5': {'res5': 95.7444}}
INFO 2022-05-20 14:51:44,440 io.py:  63: Saving data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:51:44,444 io.py:  89: Saved data to file: ./checkpoints/before_poison/upstream/metrics.json
INFO 2022-05-20 14:51:44,556 train.py: 131: All Done!
INFO 2022-05-20 14:51:44,557 logger.py:  73: Shutting down loggers...
INFO 2022-05-20 14:51:44,565 distributed_launcher.py: 168: All Done!
INFO 2022-05-20 14:51:44,566 logger.py:  73: Shutting down loggers...
