INFO 2022-05-22 11:15:34,087 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2022-05-22 11:15:34,088 env.py:  50: ARCH:	x86_64
INFO 2022-05-22 11:15:34,089 env.py:  50: BASH_ENV:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/init/bash
INFO 2022-05-22 11:15:34,089 env.py:  50: BASH_FUNC_ml%%:	() {  eval $($LMOD_DIR/ml_cmd "$@")
}
INFO 2022-05-22 11:15:34,090 env.py:  50: BASH_FUNC_module%%:	() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
INFO 2022-05-22 11:15:34,090 env.py:  50: CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64
INFO 2022-05-22 11:15:34,091 env.py:  50: CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0
INFO 2022-05-22 11:15:34,091 env.py:  50: COLUMNS:	202
INFO 2022-05-22 11:15:34,091 env.py:  50: CONDA_ACTIVATE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/etc/profile.d/conda.sh
INFO 2022-05-22 11:15:34,092 env.py:  50: CONDA_DEFAULT_ENV:	vissl_env
INFO 2022-05-22 11:15:34,092 env.py:  50: CONDA_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/conda
INFO 2022-05-22 11:15:34,093 env.py:  50: CONDA_PREFIX:	/home/mila/r/rajkuman/.conda/envs/vissl_env
INFO 2022-05-22 11:15:34,093 env.py:  50: CONDA_PROMPT_MODIFIER:	(vissl_env) 
INFO 2022-05-22 11:15:34,094 env.py:  50: CONDA_PYTHON_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/python
INFO 2022-05-22 11:15:34,094 env.py:  50: CONDA_SHLVL:	1
INFO 2022-05-22 11:15:34,094 env.py:  50: CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include
INFO 2022-05-22 11:15:34,095 env.py:  50: CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3
INFO 2022-05-22 11:15:34,095 env.py:  50: CUDA_VISIBLE_DEVICES:	0
INFO 2022-05-22 11:15:34,096 env.py:  50: ENVIRONMENT:	BATCH
INFO 2022-05-22 11:15:34,096 env.py:  50: GPU_DEVICE_ORDINAL:	0
INFO 2022-05-22 11:15:34,097 env.py:  50: HOME:	/home/mila/r/rajkuman
INFO 2022-05-22 11:15:34,097 env.py:  50: HOSTNAME:	cn-b004
INFO 2022-05-22 11:15:34,097 env.py:  50: ID:	debian
INFO 2022-05-22 11:15:34,098 env.py:  50: JPY_API_TOKEN:	6084da437bea4d8096d988bb636a59fc
INFO 2022-05-22 11:15:34,098 env.py:  50: JUPYTERHUB_ACTIVITY_URL:	http://172.16.2.123:8081/hub/api/users/rajkuman/activity
INFO 2022-05-22 11:15:34,099 env.py:  50: JUPYTERHUB_API_TOKEN:	6084da437bea4d8096d988bb636a59fc
INFO 2022-05-22 11:15:34,099 env.py:  50: JUPYTERHUB_API_URL:	http://172.16.2.123:8081/hub/api
INFO 2022-05-22 11:15:34,100 env.py:  50: JUPYTERHUB_BASE_URL:	/
INFO 2022-05-22 11:15:34,100 env.py:  50: JUPYTERHUB_CLIENT_ID:	jupyterhub-user-rajkuman
INFO 2022-05-22 11:15:34,100 env.py:  50: JUPYTERHUB_HOST:	
INFO 2022-05-22 11:15:34,101 env.py:  50: JUPYTERHUB_OAUTH_CALLBACK_URL:	/user/rajkuman/oauth_callback
INFO 2022-05-22 11:15:34,101 env.py:  50: JUPYTERHUB_SERVER_NAME:	
INFO 2022-05-22 11:15:34,102 env.py:  50: JUPYTERHUB_SERVICE_PREFIX:	/user/rajkuman/
INFO 2022-05-22 11:15:34,102 env.py:  50: JUPYTERHUB_USER:	rajkuman
INFO 2022-05-22 11:15:34,103 env.py:  50: JUPYTER_SERVER_ROOT:	/home/mila/r/rajkuman
INFO 2022-05-22 11:15:34,103 env.py:  50: JUPYTER_SERVER_URL:	http://0.0.0.0:38953/user/rajkuman/
INFO 2022-05-22 11:15:34,104 env.py:  50: KERNEL_LAUNCH_TIMEOUT:	40
INFO 2022-05-22 11:15:34,104 env.py:  50: LANG:	en_US.UTF-8
INFO 2022-05-22 11:15:34,105 env.py:  50: LESSCLOSE:	/bin/lesspipe %s %s
INFO 2022-05-22 11:15:34,105 env.py:  50: LESSOPEN:	| /bin/lesspipe %s
INFO 2022-05-22 11:15:34,106 env.py:  50: LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib
INFO 2022-05-22 11:15:34,106 env.py:  50: LINES:	50
INFO 2022-05-22 11:15:34,106 env.py:  50: LMOD_CMD:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec/lmod
INFO 2022-05-22 11:15:34,107 env.py:  50: LMOD_DIR:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec
INFO 2022-05-22 11:15:34,107 env.py:  50: LMOD_PACKAGE_PATH:	/cvmfs/config.mila.quebec/etc/lmod/
INFO 2022-05-22 11:15:34,108 env.py:  50: LMOD_PKG:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-22 11:15:34,108 env.py:  50: LMOD_ROOT:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod
INFO 2022-05-22 11:15:34,108 env.py:  50: LMOD_SETTARG_FULL_SUPPORT:	no
INFO 2022-05-22 11:15:34,109 env.py:  50: LMOD_SYSTEM_DEFAULT_MODULES:	Mila:gcc/7.4.0
INFO 2022-05-22 11:15:34,109 env.py:  50: LMOD_VERSION:	8.3.17
INFO 2022-05-22 11:15:34,110 env.py:  50: LMOD_sys:	Linux
INFO 2022-05-22 11:15:34,110 env.py:  50: LOADEDMODULES:	Mila:gcc/7.4.0:anaconda/3
INFO 2022-05-22 11:15:34,111 env.py:  50: LOCAL_RANK:	0
INFO 2022-05-22 11:15:34,111 env.py:  50: LOGNAME:	rajkuman
INFO 2022-05-22 11:15:34,112 env.py:  50: LS_COLORS:	rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
INFO 2022-05-22 11:15:34,113 env.py:  50: MAIL:	/var/mail/rajkuman
INFO 2022-05-22 11:15:34,113 env.py:  50: MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man::
INFO 2022-05-22 11:15:34,114 env.py:  50: MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:/cvmfs/config.mila.quebec/modules/Compiler:/cvmfs/config.mila.quebec/modules/Environments:/cvmfs/config.mila.quebec/modules/Cuda:/cvmfs/config.mila.quebec/modules/Pytorch:/cvmfs/config.mila.quebec/modules/Tensorflow
INFO 2022-05-22 11:15:34,114 env.py:  50: MODULEPATH_ROOT:	/cvmfs/config.mila.quebec/modules
INFO 2022-05-22 11:15:34,115 env.py:  50: MODULERCFILE:	/cvmfs/config.mila.quebec/etc/lmod/modulerc.lua
INFO 2022-05-22 11:15:34,115 env.py:  50: MODULESHOME:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-22 11:15:34,116 env.py:  50: OLDPWD:	/home/mila/r/rajkuman
INFO 2022-05-22 11:15:34,116 env.py:  50: PATH:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin:/home/mila/r/rajkuman/.local/bin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/condabin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:/opt/slurm/bin:/sbin:/bin:/usr/sbin:/usr/bin
INFO 2022-05-22 11:15:34,117 env.py:  50: PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig
INFO 2022-05-22 11:15:34,117 env.py:  50: PROCESSOR_ARCHITECTURE:	amd64
INFO 2022-05-22 11:15:34,118 env.py:  50: PWD:	/home/mila/r/rajkuman/mina/mphil-vissl
INFO 2022-05-22 11:15:34,118 env.py:  50: PYTHONNOUSERSITE:	True
INFO 2022-05-22 11:15:34,118 env.py:  50: PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7
INFO 2022-05-22 11:15:34,119 env.py:  50: PYXTERM_DIMENSIONS:	80x25
INFO 2022-05-22 11:15:34,119 env.py:  50: RANK:	0
INFO 2022-05-22 11:15:34,120 env.py:  50: ROCR_VISIBLE_DEVICES:	0
INFO 2022-05-22 11:15:34,120 env.py:  50: SACCT_FORMAT:	User,JobID,Jobname,partition,state,time,start,end,elapsed,nnodes,ncpus,reqmem,alloctres,nodelist,workdir
INFO 2022-05-22 11:15:34,121 env.py:  50: SCRATCH:	/network/scratch/r/rajkuman
INFO 2022-05-22 11:15:34,121 env.py:  50: SHELL:	/bin/bash
INFO 2022-05-22 11:15:34,122 env.py:  50: SHLVL:	3
INFO 2022-05-22 11:15:34,122 env.py:  50: SINFO_FORMAT:	%18N %.6D %.11T %.4c %.8z %.6m %.8d %.6w %.22f %80E
INFO 2022-05-22 11:15:34,123 env.py:  50: SLURMD_NODENAME:	cn-b004
INFO 2022-05-22 11:15:34,123 env.py:  50: SLURM_CLUSTER_NAME:	mila
INFO 2022-05-22 11:15:34,124 env.py:  50: SLURM_CONF:	/etc/slurm/slurm.conf
INFO 2022-05-22 11:15:34,124 env.py:  50: SLURM_CPUS_ON_NODE:	4
INFO 2022-05-22 11:15:34,125 env.py:  50: SLURM_CPUS_PER_TASK:	4
INFO 2022-05-22 11:15:34,125 env.py:  50: SLURM_EXPORT_ENV:	PATH,LANG,USER,HOME,SHELL,JUPYTERHUB_API_TOKEN,JPY_API_TOKEN,JUPYTERHUB_CLIENT_ID,JUPYTERHUB_HOST,JUPYTERHUB_OAUTH_CALLBACK_URL,JUPYTERHUB_USER,JUPYTERHUB_SERVER_NAME,JUPYTERHUB_API_URL,JUPYTERHUB_ACTIVITY_URL,JUPYTERHUB_BASE_URL,JUPYTERHUB_SERVICE_PREFIX
INFO 2022-05-22 11:15:34,126 env.py:  50: SLURM_GET_USER_ENV:	1
INFO 2022-05-22 11:15:34,126 env.py:  50: SLURM_GTIDS:	0
INFO 2022-05-22 11:15:34,127 env.py:  50: SLURM_JOBID:	1847271
INFO 2022-05-22 11:15:34,127 env.py:  50: SLURM_JOB_ACCOUNT:	mila
INFO 2022-05-22 11:15:34,128 env.py:  50: SLURM_JOB_CPUS_PER_NODE:	4
INFO 2022-05-22 11:15:34,128 env.py:  50: SLURM_JOB_GID:	1471600619
INFO 2022-05-22 11:15:34,128 env.py:  50: SLURM_JOB_GPUS:	0
INFO 2022-05-22 11:15:34,129 env.py:  50: SLURM_JOB_ID:	1847271
INFO 2022-05-22 11:15:34,129 env.py:  50: SLURM_JOB_NAME:	jupyterhub-rajkuman
INFO 2022-05-22 11:15:34,130 env.py:  50: SLURM_JOB_NODELIST:	cn-b004
INFO 2022-05-22 11:15:34,130 env.py:  50: SLURM_JOB_NUM_NODES:	1
INFO 2022-05-22 11:15:34,131 env.py:  50: SLURM_JOB_PARTITION:	unkillable
INFO 2022-05-22 11:15:34,131 env.py:  50: SLURM_JOB_QOS:	normal
INFO 2022-05-22 11:15:34,132 env.py:  50: SLURM_JOB_UID:	1471600619
INFO 2022-05-22 11:15:34,132 env.py:  50: SLURM_JOB_USER:	rajkuman
INFO 2022-05-22 11:15:34,133 env.py:  50: SLURM_LOCALID:	0
INFO 2022-05-22 11:15:34,133 env.py:  50: SLURM_MEM_PER_NODE:	24000
INFO 2022-05-22 11:15:34,134 env.py:  50: SLURM_NNODES:	1
INFO 2022-05-22 11:15:34,134 env.py:  50: SLURM_NODEID:	0
INFO 2022-05-22 11:15:34,135 env.py:  50: SLURM_NODELIST:	cn-b004
INFO 2022-05-22 11:15:34,136 env.py:  50: SLURM_NODE_ALIASES:	(null)
INFO 2022-05-22 11:15:34,136 env.py:  50: SLURM_NPROCS:	1
INFO 2022-05-22 11:15:34,137 env.py:  50: SLURM_NTASKS:	1
INFO 2022-05-22 11:15:34,137 env.py:  50: SLURM_PRIO_PROCESS:	0
INFO 2022-05-22 11:15:34,138 env.py:  50: SLURM_PROCID:	0
INFO 2022-05-22 11:15:34,138 env.py:  50: SLURM_SUBMIT_DIR:	/var/lib/jupyterhub
INFO 2022-05-22 11:15:34,138 env.py:  50: SLURM_SUBMIT_HOST:	jupyter
INFO 2022-05-22 11:15:34,139 env.py:  50: SLURM_TASKS_PER_NODE:	1
INFO 2022-05-22 11:15:34,139 env.py:  50: SLURM_TASK_PID:	62445
INFO 2022-05-22 11:15:34,140 env.py:  50: SLURM_TMPDIR:	/Tmp/slurm.1847271.0
INFO 2022-05-22 11:15:34,140 env.py:  50: SLURM_TOPOLOGY_ADDR:	cn-b004
INFO 2022-05-22 11:15:34,141 env.py:  50: SLURM_TOPOLOGY_ADDR_PATTERN:	node
INFO 2022-05-22 11:15:34,141 env.py:  50: SLURM_WORKING_CLUSTER:	mila:slurm:6817:9216:109
INFO 2022-05-22 11:15:34,142 env.py:  50: SQUEUE_FORMAT:	%.8i %.8u %.12P %.14j %.3t %16S %.10M %.5D %.4C %.10b %.7m %N (%r) %k
INFO 2022-05-22 11:15:34,142 env.py:  50: S_COLORS:	auto
INFO 2022-05-22 11:15:34,142 env.py:  50: TERM:	xterm
INFO 2022-05-22 11:15:34,143 env.py:  50: TMPDIR:	/tmp
INFO 2022-05-22 11:15:34,143 env.py:  50: USER:	rajkuman
INFO 2022-05-22 11:15:34,144 env.py:  50: WORLD_SIZE:	1
INFO 2022-05-22 11:15:34,144 env.py:  50: XDG_SESSION_ID:	c832
INFO 2022-05-22 11:15:34,145 env.py:  50: _:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin/python
INFO 2022-05-22 11:15:34,145 env.py:  50: _CE_CONDA:	
INFO 2022-05-22 11:15:34,146 env.py:  50: _CE_M:	
INFO 2022-05-22 11:15:34,146 env.py:  50: _LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua
INFO 2022-05-22 11:15:34,146 env.py:  50: _ModuleTable001_:	X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtNaWxhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL01pbGEubHVhIixbImZ1bGxOYW1lIl09Ik1pbGEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17bG1vZD17WyJzdGlja3kiXT0xLH0sfSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJNaWxhIix9LGFuYWNvbmRhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL2FuYWNvbmRhLzMubHVhIixbImZ1bGxOYW1lIl09ImFuYWNvbmRh
INFO 2022-05-22 11:15:34,147 env.py:  50: _ModuleTable002_:	LzMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJhbmFjb25kYS8zIix9LGdjYz17WyJmbiJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZS9nY2MvNy40LjAubHVhIixbImZ1bGxOYW1lIl09ImdjYy83LjQuMCIsWyJsb2FkT3JkZXIiXT0yLHByb3BUPXtsbW9kPXtbInN0aWNreSJdPTEsfSx9LFsic3RhY2tEZXB0aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09ImdjYy83LjQuMCIsfSx9LG1wYXRoQT17Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Nv
INFO 2022-05-22 11:15:34,147 env.py:  50: _ModuleTable003_:	bXBpbGVyIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50cyIsIi9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9DdWRhIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL1B5dG9yY2giLCIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZTovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29tcGlsZXI6L2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50czovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ3VkYTovY3Zt
INFO 2022-05-22 11:15:34,148 env.py:  50: _ModuleTable004_:	ZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvUHl0b3JjaDovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfQ==
INFO 2022-05-22 11:15:34,148 env.py:  50: _ModuleTable_Sz_:	4
INFO 2022-05-22 11:15:34,149 env.py:  50: __Init_Default_Modules:	1
INFO 2022-05-22 11:15:34,149 env.py:  50: __LMOD_REF_COUNT_CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1
INFO 2022-05-22 11:15:34,150 env.py:  50: __LMOD_REF_COUNT_CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0:1
INFO 2022-05-22 11:15:34,150 env.py:  50: __LMOD_REF_COUNT_CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include:1
INFO 2022-05-22 11:15:34,150 env.py:  50: __LMOD_REF_COUNT_CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3:1
INFO 2022-05-22 11:15:34,151 env.py:  50: __LMOD_REF_COUNT_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib:1
INFO 2022-05-22 11:15:34,151 env.py:  50: __LMOD_REF_COUNT_LOADEDMODULES:	Mila:1;gcc/7.4.0:1;anaconda/3:1
INFO 2022-05-22 11:15:34,152 env.py:  50: __LMOD_REF_COUNT_MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man:1
INFO 2022-05-22 11:15:34,152 env.py:  50: __LMOD_REF_COUNT_MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:1;/cvmfs/config.mila.quebec/modules/Compiler:1;/cvmfs/config.mila.quebec/modules/Environments:1;/cvmfs/config.mila.quebec/modules/Cuda:1;/cvmfs/config.mila.quebec/modules/Pytorch:1;/cvmfs/config.mila.quebec/modules/Tensorflow:1
INFO 2022-05-22 11:15:34,152 env.py:  50: __LMOD_REF_COUNT_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:1;/opt/slurm/bin:1;/sbin:1;/bin:1;/usr/sbin:1;/usr/bin:1
INFO 2022-05-22 11:15:34,153 env.py:  50: __LMOD_REF_COUNT_PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig:1
INFO 2022-05-22 11:15:34,153 env.py:  50: __LMOD_REF_COUNT_PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7:1
INFO 2022-05-22 11:15:34,154 env.py:  50: __LMOD_REF_COUNT__LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:1;/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:1;/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua:1
INFO 2022-05-22 11:15:34,154 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-22 11:15:34,155 train.py: 105: Setting seed....
INFO 2022-05-22 11:15:34,155 misc.py: 173: MACHINE SEED: 28
INFO 2022-05-22 11:15:34,175 hydra_config.py: 132: Training with config:
INFO 2022-05-22 11:15:34,193 hydra_config.py: 141: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints/after_poison/imagenet',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 4,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['imagenet1k_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 256,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['imagenet1k_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'CHECK_NAN': True,
           'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 200,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': ['conv1',
                                                    'res2',
                                                    'res3',
                                                    'res4',
                                                    'res5'],
                                    'num_meters': 5,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'model_output_mask': False,
            'name': 'accuracy_list_meter',
            'names': ['accuracy_list_meter'],
            'precision_at_k_list_meter': {'meter_names': [],
                                          'num_meters': 1,
                                          'topk_values': [1]},
            'recall_at_k_list_meter': {'meter_names': [],
                                       'num_meters': 1,
                                       'topk_values': [1]}},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'BASE_MODEL_NAME': 'multi_input_output_model',
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',
                                                                        ['AvgPool2d',
                                                                         [[10,
                                                                           10],
                                                                          10,
                                                                          4]]],
                                                                       ['res2',
                                                                        ['AvgPool2d',
                                                                         [[16,
                                                                           16],
                                                                          8,
                                                                          0]]],
                                                                       ['res3',
                                                                        ['AvgPool2d',
                                                                         [[13,
                                                                           13],
                                                                          5,
                                                                          0]]],
                                                                       ['res4',
                                                                        ['AvgPool2d',
                                                                         [[8,
                                                                           8],
                                                                          3,
                                                                          0]]],
                                                                       ['res5',
                                                                        ['AvgPool2d',
                                                                         [[6,
                                                                           6],
                                                                          1,
                                                                          0]]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 64}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 256}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 512}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 1024}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 2048}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': 8,
                              'SYNC_BN_TYPE': 'apex'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'BLOCK': 'Bottleneck',
                                 'CONV1_KERNEL': 7,
                                 'CONV1_PADDING': 3,
                                 'CONV1_STRIDE': 2,
                                 'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'MAXPOOL': True,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': './checkpoints/poisoned/model_final_checkpoint_phase99.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0005},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 28,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.01,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [8, 16, 24],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.01,
                                                      0.001,
                                                      0.0001,
                                                      1e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.01,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [8, 16, 24],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.01,
                                                           0.001,
                                                           0.0001,
                                                           1e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0005},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2022-05-22 11:15:36,744 train.py: 117: System config:
-------------------  ---------------------------------------------------------------------------------------------------------------
sys.platform         linux
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                1.19.5
Pillow               9.0.1
vissl                0.1.6 @/home/mila/r/rajkuman/mina/mphil-vissl/vissl
GPU available        True
GPU 0                Tesla V100-SXM2-32GB
CUDA_HOME            None
torchvision          0.9.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torchvision
hydra                1.0.7 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/hydra_core-1.0.7-py3.8.egg/hydra
classy_vision        0.7.0.dev @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/classy_vision
tensorboard          2.9.0
apex                 0.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/apex
PyTorch              1.8.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ----------------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               80
On-line CPU(s) list  0-79
Thread(s) per core   2
Core(s) per socket   20
Socket(s)            2
NUMA node(s)         2
Vendor ID            GenuineIntel
CPU family           6
Model                85
Model name           Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz
Stepping             7
CPU MHz              3329.290
CPU max MHz          3900.0000
CPU min MHz          800.0000
BogoMIPS             4200.00
Virtualization       VT-x
L1d cache            32K
L1i cache            32K
L2 cache             1024K
L3 cache             28160K
NUMA node0 CPU(s)    0-19,40-59
NUMA node1 CPU(s)    20-39,60-79
-------------------  ----------------------------------------
INFO 2022-05-22 11:15:36,746 trainer_main.py: 112: Using Distributed init method: tcp://localhost:35055, world_size: 1, rank: 0
INFO 2022-05-22 11:15:36,753 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2022-05-22 11:15:36,753 trainer_main.py: 130: | initialized host cn-b004 as rank 0 (0)
INFO 2022-05-22 11:15:46,728 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2022-05-22 11:15:46,729 train_task.py: 455: Building model....
INFO 2022-05-22 11:15:46,730 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2022-05-22 11:15:46,730 resnext.py:  66: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2022-05-22 11:15:46,731 resnext.py:  93: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2022-05-22 11:15:47,285 feature_extractor.py:  50: Freezing model trunk...
INFO 2022-05-22 11:15:47,595 model_helpers.py: 178: Using SyncBN group size: 1
INFO 2022-05-22 11:15:47,596 model_helpers.py: 182: Converting BN layers to Apex SyncBN
INFO 2022-05-22 11:15:47,596 distributed_c10d.py: 187: Added key: store_based_barrier_key:2 to store for rank: 0
INFO 2022-05-22 11:15:47,604 train_task.py: 472: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2022-05-22 11:15:47,605 base_ssl_model.py: 195: Freezing model trunk...
INFO 2022-05-22 11:15:47,606 train_task.py: 429: Initializing model from: ./checkpoints/poisoned/model_final_checkpoint_phase99.torch
INFO 2022-05-22 11:15:47,607 util.py: 276: Attempting to load checkpoint from ./checkpoints/poisoned/model_final_checkpoint_phase99.torch
INFO 2022-05-22 11:15:48,110 util.py: 281: Loaded checkpoint from ./checkpoints/poisoned/model_final_checkpoint_phase99.torch
INFO 2022-05-22 11:15:48,111 util.py: 240: Broadcasting checkpoint loaded from ./checkpoints/poisoned/model_final_checkpoint_phase99.torch
INFO 2022-05-22 11:15:53,712 train_task.py: 435: Checkpoint loaded: ./checkpoints/poisoned/model_final_checkpoint_phase99.torch...
INFO 2022-05-22 11:15:53,715 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2022-05-22 11:15:53,715 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,716 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,716 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,717 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,717 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,718 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,718 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,719 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,719 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,719 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,720 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,720 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,720 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,721 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,721 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,721 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,722 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,722 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,723 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,723 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,723 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,724 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,724 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,724 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,725 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,725 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,725 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,726 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,726 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2022-05-22 11:15:53,727 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,727 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,728 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,728 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,728 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,729 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,729 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,730 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,730 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,730 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,731 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,731 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,731 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,732 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,732 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,732 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,733 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,733 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,733 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,734 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,734 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,735 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,735 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,736 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,736 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,736 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,737 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,737 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,738 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-22 11:15:53,738 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,738 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,739 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,739 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,740 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,740 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,740 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,741 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,741 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,742 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,742 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,743 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,743 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,744 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,744 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,744 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,745 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,745 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,746 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,746 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,746 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,747 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,747 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,748 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,748 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,749 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,749 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,749 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,750 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,750 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,751 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2022-05-22 11:15:53,751 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,751 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,752 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,752 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,752 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,753 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,753 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,754 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,754 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,754 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,755 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,755 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,755 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,756 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,756 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,757 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,757 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,757 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,758 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,758 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,759 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,759 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,759 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,760 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,760 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,761 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,761 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,762 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,762 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,763 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,763 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,764 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,764 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,764 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,765 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,765 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,766 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,766 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,767 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,767 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,768 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,768 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,769 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,769 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,770 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,770 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,771 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-22 11:15:53,771 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,771 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,772 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,772 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,773 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,773 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,774 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,774 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,775 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,775 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,776 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,777 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,777 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,778 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,779 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,779 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,780 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,780 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,781 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,782 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,782 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,783 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,783 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,784 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,785 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,785 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,786 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,787 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,787 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,788 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,788 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2022-05-22 11:15:53,789 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,790 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,790 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,791 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,791 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,792 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,793 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,793 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,794 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,795 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,795 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,796 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,796 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,797 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,798 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,798 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,799 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,799 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,800 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,800 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,801 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,802 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,802 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,803 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,803 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,804 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,805 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,805 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,806 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,806 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,807 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,808 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,808 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,809 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,809 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,810 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,810 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,811 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,812 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,812 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,813 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,813 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,814 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,814 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,815 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,816 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,816 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,817 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,817 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,818 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,818 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,819 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,820 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,820 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,821 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,821 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,822 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,822 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,823 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,823 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,824 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,825 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,825 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,826 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,827 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,827 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,828 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,828 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,829 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,829 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,830 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,830 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,831 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,832 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,832 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,833 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,834 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,834 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,835 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,835 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,836 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,836 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,837 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-22 11:15:53,838 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,838 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,839 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,840 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,840 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,841 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-22 11:15:53,841 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,842 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,843 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,843 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,844 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,844 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,845 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,846 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,847 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,847 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,848 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,849 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,849 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,850 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,851 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,851 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,852 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,852 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,853 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,854 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,855 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,855 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,856 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,856 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,857 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2022-05-22 11:15:53,858 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,858 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,859 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,860 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,860 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,861 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,862 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,862 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,863 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,863 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,864 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,864 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,865 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,866 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,867 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,867 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,868 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,868 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,869 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,869 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,870 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,870 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,871 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,871 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2022-05-22 11:15:53,872 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-22 11:15:53,873 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,873 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,874 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,875 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-22 11:15:53,875 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2022-05-22 11:15:53,876 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-22 11:15:53,876 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,877 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,878 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,878 checkpoint.py: 885: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-22 11:15:53,879 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2022-05-22 11:15:53,879 checkpoint.py: 894: Not found:		heads.0.channel_bn.weight, not initialized
INFO 2022-05-22 11:15:53,880 checkpoint.py: 894: Not found:		heads.0.channel_bn.bias, not initialized
INFO 2022-05-22 11:15:53,880 checkpoint.py: 894: Not found:		heads.0.channel_bn.running_mean, not initialized
INFO 2022-05-22 11:15:53,881 checkpoint.py: 894: Not found:		heads.0.channel_bn.running_var, not initialized
INFO 2022-05-22 11:15:53,881 checkpoint.py: 851: Ignored layer:	heads.0.channel_bn.num_batches_tracked
INFO 2022-05-22 11:15:53,881 checkpoint.py: 894: Not found:		heads.0.clf.clf.0.weight, not initialized
INFO 2022-05-22 11:15:53,882 checkpoint.py: 894: Not found:		heads.0.clf.clf.0.bias, not initialized
INFO 2022-05-22 11:15:53,882 checkpoint.py: 894: Not found:		heads.1.channel_bn.weight, not initialized
INFO 2022-05-22 11:15:53,882 checkpoint.py: 894: Not found:		heads.1.channel_bn.bias, not initialized
INFO 2022-05-22 11:15:53,883 checkpoint.py: 894: Not found:		heads.1.channel_bn.running_mean, not initialized
INFO 2022-05-22 11:15:53,883 checkpoint.py: 894: Not found:		heads.1.channel_bn.running_var, not initialized
INFO 2022-05-22 11:15:53,884 checkpoint.py: 851: Ignored layer:	heads.1.channel_bn.num_batches_tracked
INFO 2022-05-22 11:15:53,884 checkpoint.py: 894: Not found:		heads.1.clf.clf.0.weight, not initialized
INFO 2022-05-22 11:15:53,884 checkpoint.py: 894: Not found:		heads.1.clf.clf.0.bias, not initialized
INFO 2022-05-22 11:15:53,885 checkpoint.py: 894: Not found:		heads.2.channel_bn.weight, not initialized
INFO 2022-05-22 11:15:53,885 checkpoint.py: 894: Not found:		heads.2.channel_bn.bias, not initialized
INFO 2022-05-22 11:15:53,885 checkpoint.py: 894: Not found:		heads.2.channel_bn.running_mean, not initialized
INFO 2022-05-22 11:15:53,886 checkpoint.py: 894: Not found:		heads.2.channel_bn.running_var, not initialized
INFO 2022-05-22 11:15:53,886 checkpoint.py: 851: Ignored layer:	heads.2.channel_bn.num_batches_tracked
INFO 2022-05-22 11:15:53,886 checkpoint.py: 894: Not found:		heads.2.clf.clf.0.weight, not initialized
INFO 2022-05-22 11:15:53,887 checkpoint.py: 894: Not found:		heads.2.clf.clf.0.bias, not initialized
INFO 2022-05-22 11:15:53,887 checkpoint.py: 894: Not found:		heads.3.channel_bn.weight, not initialized
INFO 2022-05-22 11:15:53,887 checkpoint.py: 894: Not found:		heads.3.channel_bn.bias, not initialized
INFO 2022-05-22 11:15:53,888 checkpoint.py: 894: Not found:		heads.3.channel_bn.running_mean, not initialized
INFO 2022-05-22 11:15:53,888 checkpoint.py: 894: Not found:		heads.3.channel_bn.running_var, not initialized
INFO 2022-05-22 11:15:53,888 checkpoint.py: 851: Ignored layer:	heads.3.channel_bn.num_batches_tracked
INFO 2022-05-22 11:15:53,888 checkpoint.py: 894: Not found:		heads.3.clf.clf.0.weight, not initialized
INFO 2022-05-22 11:15:53,889 checkpoint.py: 894: Not found:		heads.3.clf.clf.0.bias, not initialized
INFO 2022-05-22 11:15:53,889 checkpoint.py: 894: Not found:		heads.4.channel_bn.weight, not initialized
INFO 2022-05-22 11:15:53,889 checkpoint.py: 894: Not found:		heads.4.channel_bn.bias, not initialized
INFO 2022-05-22 11:15:53,890 checkpoint.py: 894: Not found:		heads.4.channel_bn.running_mean, not initialized
INFO 2022-05-22 11:15:53,890 checkpoint.py: 894: Not found:		heads.4.channel_bn.running_var, not initialized
INFO 2022-05-22 11:15:53,891 checkpoint.py: 851: Ignored layer:	heads.4.channel_bn.num_batches_tracked
INFO 2022-05-22 11:15:53,891 checkpoint.py: 894: Not found:		heads.4.clf.clf.0.weight, not initialized
INFO 2022-05-22 11:15:53,891 checkpoint.py: 894: Not found:		heads.4.clf.clf.0.bias, not initialized
INFO 2022-05-22 11:15:53,892 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['heads.0.clf.0.weight', 'heads.0.clf.0.bias']
INFO 2022-05-22 11:15:53,893 train_task.py: 656: Broadcast model BN buffers from primary on every forward pass
INFO 2022-05-22 11:15:53,893 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2022-05-22 11:15:53,980 optimizer_helper.py: 293: 
Trainable params: 20, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 0, 
Trunk Unregularized Parameters 0, 
Head Regularized Parameters: 10, 
Head Unregularized Parameters: 10 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2022-05-22 11:15:53,982 ssl_dataset.py: 156: Rank: 0 split: TEST Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-22 11:15:53,983 ssl_dataset.py: 159: Rank: 0 split: TEST Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-22 11:15:54,778 disk_dataset.py:  86: Loaded 50000 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/val
INFO 2022-05-22 11:15:54,780 ssl_dataset.py: 156: Rank: 0 split: TRAIN Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-22 11:15:54,780 ssl_dataset.py: 159: Rank: 0 split: TRAIN Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-22 11:16:13,248 disk_dataset.py:  86: Loaded 1281167 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/train
INFO 2022-05-22 11:16:13,249 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-22 11:16:13,250 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-22 11:16:13,250 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 11:16:13,251 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-22 11:16:13,252 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-22 11:16:13,253 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-22 11:16:13,254 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 11:16:13,255 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-22 11:16:13,255 train_task.py: 384: Building loss...
INFO 2022-05-22 11:16:13,257 trainer_main.py: 268: Training 28 epochs
INFO 2022-05-22 11:16:13,257 trainer_main.py: 269: One epoch = 5005 iterations.
INFO 2022-05-22 11:16:13,258 trainer_main.py: 270: Total 1281167 samples in one epoch
INFO 2022-05-22 11:16:13,258 trainer_main.py: 276: Total 140140 iterations for training
INFO 2022-05-22 11:16:13,429 logger.py:  84: Sun May 22 11:16:13 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:15:00.0 Off |                    0 |
| N/A   28C    P0    52W / 300W |   1438MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     48950      C   python                           1435MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-22 11:16:13,432 trainer_main.py: 173: Model is:
 Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)
              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)
      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)
      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)
      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)
      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)
    )
  )
  (heads): ModuleList(
    (0): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (1): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (2): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
    (3): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (4): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
  )
)
INFO 2022-05-22 11:16:13,433 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2022-05-22 11:16:13,433 trainer_main.py: 175: Starting training....
INFO 2022-05-22 11:16:13,434 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 11:16:59,615 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 11:16:59,617 log_hooks.py:  76: ========= Memory Summary at on_phase_start =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  419840 KB |  419840 KB |  419840 KB |     512 B  |
|       from large pool |  401920 KB |  401920 KB |  401920 KB |       0 B  |
|       from small pool |   17920 KB |   17920 KB |   17920 KB |     512 B  |
|---------------------------------------------------------------------------|
| Active memory         |  419840 KB |  419840 KB |  419840 KB |     512 B  |
|       from large pool |  401920 KB |  401920 KB |  401920 KB |       0 B  |
|       from small pool |   17920 KB |   17920 KB |   17920 KB |     512 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  450560 KB |  450560 KB |  450560 KB |       0 B  |
|       from large pool |  430080 KB |  430080 KB |  430080 KB |       0 B  |
|       from small pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   30720 KB |   30724 KB |   90264 KB |   59544 KB |
|       from large pool |   28160 KB |   28160 KB |   74496 KB |   46336 KB |
|       from small pool |    2560 KB |    2564 KB |   15768 KB |   13208 KB |
|---------------------------------------------------------------------------|
| Allocations           |     357    |     357    |     358    |       1    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     334    |     334    |     335    |       1    |
|---------------------------------------------------------------------------|
| Active allocs         |     357    |     357    |     358    |       1    |
|       from large pool |      23    |      23    |      23    |       0    |
|       from small pool |     334    |     334    |     335    |       1    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      21    |      21    |      21    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       8    |       8    |      16    |       8    |
|       from large pool |       5    |       5    |       5    |       0    |
|       from small pool |       3    |       5    |      11    |       8    |
|===========================================================================|


INFO 2022-05-22 11:16:59,617 state_update_hooks.py: 115: Starting phase 0 [train]
INFO 2022-05-22 11:17:02,542 log_hooks.py:  76: ========= Memory Summary at on_forward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  664495 KB |    6296 MB |   63299 MB |   62650 MB |
|       from large pool |  641536 KB |    6279 MB |   63276 MB |   62650 MB |
|       from small pool |   22959 KB |      22 MB |      22 MB |       0 MB |
|---------------------------------------------------------------------------|
| Active memory         |  664495 KB |    6296 MB |   63299 MB |   62650 MB |
|       from large pool |  641536 KB |    6279 MB |   63276 MB |   62650 MB |
|       from small pool |   22959 KB |      22 MB |      22 MB |       0 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7490 MB |   11100 MB |   27038 MB |   19548 MB |
|       from large pool |    7464 MB |   11080 MB |   27012 MB |   19548 MB |
|       from small pool |      26 MB |      26 MB |      26 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    3381 MB |    3415 MB |   43084 MB |   39703 MB |
|       from large pool |    3377 MB |    3411 MB |   43065 MB |   39687 MB |
|       from small pool |       3 MB |       3 MB |      19 MB |      15 MB |
|---------------------------------------------------------------------------|
| Allocations           |     391    |     396    |     651    |     260    |
|       from large pool |      34    |      34    |     179    |     145    |
|       from small pool |     357    |     363    |     472    |     115    |
|---------------------------------------------------------------------------|
| Active allocs         |     391    |     397    |     651    |     260    |
|       from large pool |      34    |      34    |     179    |     145    |
|       from small pool |     357    |     364    |     472    |     115    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      28    |      28    |      38    |      10    |
|       from large pool |      15    |      17    |      25    |      10    |
|       from small pool |      13    |      13    |      13    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      26    |      26    |     128    |     102    |
|       from large pool |       8    |      10    |      66    |      58    |
|       from small pool |      18    |      18    |      62    |      44    |
|===========================================================================|


INFO 2022-05-22 11:17:02,766 log_hooks.py:  76: ========= Memory Summary at on_backward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  748450 KB |    6296 MB |   63552 MB |   62821 MB |
|       from large pool |  725472 KB |    6279 MB |   63487 MB |   62779 MB |
|       from small pool |   22978 KB |      34 MB |      64 MB |      42 MB |
|---------------------------------------------------------------------------|
| Active memory         |  748450 KB |    6296 MB |   63552 MB |   62821 MB |
|       from large pool |  725472 KB |    6279 MB |   63487 MB |   62779 MB |
|       from small pool |   22978 KB |      34 MB |      64 MB |      42 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7502 MB |   11100 MB |   27050 MB |   19548 MB |
|       from large pool |    7464 MB |   11080 MB |   27012 MB |   19548 MB |
|       from small pool |      38 MB |      38 MB |      38 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1497 MB |    3415 MB |   43261 MB |   41764 MB |
|       from large pool |    1493 MB |    3411 MB |   43185 MB |   41691 MB |
|       from small pool |       3 MB |       5 MB |      76 MB |      72 MB |
|---------------------------------------------------------------------------|
| Allocations           |     388    |     410    |     799    |     411    |
|       from large pool |      29    |      36    |     189    |     160    |
|       from small pool |     359    |     376    |     610    |     251    |
|---------------------------------------------------------------------------|
| Active allocs         |     388    |     410    |     799    |     411    |
|       from large pool |      29    |      36    |     189    |     160    |
|       from small pool |     359    |     376    |     610    |     251    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      34    |      34    |      44    |      10    |
|       from large pool |      15    |      17    |      25    |      10    |
|       from small pool |      19    |      19    |      19    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      20    |      32    |     203    |     183    |
|       from large pool |       7    |      10    |      68    |      61    |
|       from small pool |      13    |      24    |     135    |     122    |
|===========================================================================|


INFO 2022-05-22 11:17:02,769 log_hooks.py:  76: ========= Memory Summary at on_update =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |     898 MB |    6296 MB |   64056 MB |   63157 MB |
|       from large pool |     876 MB |    6279 MB |   63991 MB |   63114 MB |
|       from small pool |      22 MB |      34 MB |      64 MB |      42 MB |
|---------------------------------------------------------------------------|
| Active memory         |     898 MB |    6296 MB |   64056 MB |   63157 MB |
|       from large pool |     876 MB |    6279 MB |   63991 MB |   63114 MB |
|       from small pool |      22 MB |      34 MB |      64 MB |      42 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    7502 MB |   11100 MB |   27050 MB |   19548 MB |
|       from large pool |    7464 MB |   11080 MB |   27012 MB |   19548 MB |
|       from small pool |      38 MB |      38 MB |      38 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1329 MB |    3415 MB |   43597 MB |   42268 MB |
|       from large pool |    1325 MB |    3411 MB |   43521 MB |   42195 MB |
|       from small pool |       3 MB |       5 MB |      76 MB |      72 MB |
|---------------------------------------------------------------------------|
| Allocations           |     408    |     410    |     849    |     441    |
|       from large pool |      34    |      36    |     204    |     170    |
|       from small pool |     374    |     376    |     645    |     271    |
|---------------------------------------------------------------------------|
| Active allocs         |     408    |     410    |     849    |     441    |
|       from large pool |      34    |      36    |     204    |     170    |
|       from small pool |     374    |     376    |     645    |     271    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      34    |      34    |      44    |      10    |
|       from large pool |      15    |      17    |      25    |      10    |
|       from small pool |      19    |      19    |      19    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      15    |      32    |     211    |     196    |
|       from large pool |       7    |      10    |      68    |      61    |
|       from small pool |       8    |      24    |     143    |     135    |
|===========================================================================|


INFO 2022-05-22 11:17:02,770 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 0; lr: 0.01; loss: 35.42216; btime(ms): 0; eta: 0:00:00; peak_mem(M): 6296;
INFO 2022-05-22 11:17:03,115 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 35.16895; btime(ms): 49514; eta: 80 days, 7:27:41; peak_mem(M): 6296; max_iterations: 140140;
INFO 2022-05-22 11:17:06,727 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 5; lr: 0.01; loss: 34.87841; btime(ms): 10617; eta: 17 days, 5:18:16; peak_mem(M): 6296;
INFO 2022-05-22 11:17:12,890 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 10; lr: 0.01; loss: 34.61042; btime(ms): 5929; eta: 9 days, 14:47:16; peak_mem(M): 6296;
INFO 2022-05-22 11:17:21,256 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 15; lr: 0.01; loss: 34.23561; btime(ms): 4316; eta: 7 days, 0:01:52; peak_mem(M): 6296;
INFO 2022-05-22 11:17:27,835 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 20; lr: 0.01; loss: 33.37158; btime(ms): 3708; eta: 6 days, 0:21:03; peak_mem(M): 6296;
INFO 2022-05-22 11:17:34,080 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 25; lr: 0.01; loss: 33.30909; btime(ms): 3216; eta: 5 days, 5:11:32; peak_mem(M): 6296;
INFO 2022-05-22 11:17:39,876 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 30; lr: 0.01; loss: 32.89217; btime(ms): 2874; eta: 4 days, 15:52:38; peak_mem(M): 6296;
INFO 2022-05-22 11:17:48,644 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 35; lr: 0.01; loss: 32.04638; btime(ms): 2627; eta: 4 days, 6:15:14; peak_mem(M): 6296;
INFO 2022-05-22 11:17:55,147 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 40; lr: 0.01; loss: 31.55247; btime(ms): 2514; eta: 4 days, 1:52:13; peak_mem(M): 6296;
INFO 2022-05-22 11:18:01,928 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 45; lr: 0.01; loss: 31.83426; btime(ms): 2406; eta: 3 days, 21:38:49; peak_mem(M): 6296;
INFO 2022-05-22 11:18:07,710 logger.py:  84: Sun May 22 11:18:07 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:15:00.0 Off |                    0 |
| N/A   33C    P0    62W / 300W |   8736MiB / 32510MiB |     39%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     48950      C   python                           8731MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-22 11:18:08,073 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 50; lr: 0.01; loss: 32.30118; btime(ms): 2283; eta: 3 days, 16:51:37; peak_mem(M): 6296;
INFO 2022-05-22 11:18:15,254 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 55; lr: 0.01; loss: 31.70684; btime(ms): 2177; eta: 3 days, 12:44:39; peak_mem(M): 6296;
INFO 2022-05-22 11:18:23,129 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 60; lr: 0.01; loss: 31.6997; btime(ms): 2120; eta: 3 days, 10:30:21; peak_mem(M): 6296;
INFO 2022-05-22 11:18:28,836 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 65; lr: 0.01; loss: 31.48855; btime(ms): 2078; eta: 3 days, 8:52:32; peak_mem(M): 6296;
INFO 2022-05-22 11:18:35,230 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 70; lr: 0.01; loss: 32.05585; btime(ms): 2024; eta: 3 days, 6:45:43; peak_mem(M): 6296;
INFO 2022-05-22 11:18:42,049 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 75; lr: 0.01; loss: 30.74632; btime(ms): 1968; eta: 3 days, 4:35:25; peak_mem(M): 6296;
INFO 2022-05-22 11:18:49,646 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 80; lr: 0.01; loss: 29.93839; btime(ms): 1919; eta: 3 days, 2:41:39; peak_mem(M): 6296;
INFO 2022-05-22 11:18:55,404 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 85; lr: 0.01; loss: 30.81292; btime(ms): 1902; eta: 3 days, 2:00:54; peak_mem(M): 6296;
INFO 2022-05-22 11:19:02,542 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 90; lr: 0.01; loss: 31.69897; btime(ms): 1876; eta: 3 days, 1:00:42; peak_mem(M): 6296;
INFO 2022-05-22 11:19:08,398 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 95; lr: 0.01; loss: 30.02592; btime(ms): 1832; eta: 2 days, 23:17:23; peak_mem(M): 6296;
INFO 2022-05-22 11:19:17,759 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 100; lr: 0.01; loss: 30.55076; btime(ms): 1803; eta: 2 days, 22:09:52; peak_mem(M): 6296;
INFO 2022-05-22 11:21:32,312 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 200; lr: 0.01; loss: 28.67557; btime(ms): 1575; eta: 2 days, 13:14:33; peak_mem(M): 6296;
INFO 2022-05-22 11:25:48,012 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 400; lr: 0.01; loss: 28.51602; btime(ms): 1431; eta: 2 days, 7:34:33; peak_mem(M): 6296;
INFO 2022-05-22 11:30:08,241 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 600; lr: 0.01; loss: 27.94054; btime(ms): 1386; eta: 2 days, 5:43:35; peak_mem(M): 6296;
INFO 2022-05-22 11:34:26,869 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 800; lr: 0.01; loss: 26.30709; btime(ms): 1361; eta: 2 days, 4:42:47; peak_mem(M): 6296;
INFO 2022-05-22 11:38:38,040 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1000; lr: 0.01; loss: 27.47092; btime(ms): 1341; eta: 2 days, 3:50:02; peak_mem(M): 6296;
INFO 2022-05-22 11:42:47,825 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1200; lr: 0.01; loss: 26.38167; btime(ms): 1325; eta: 2 days, 3:09:25; peak_mem(M): 6296;
INFO 2022-05-22 11:48:18,197 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1400; lr: 0.01; loss: 25.79311; btime(ms): 1369; eta: 2 days, 4:47:00; peak_mem(M): 6296;
INFO 2022-05-22 11:54:34,307 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1600; lr: 0.01; loss: 25.527; btime(ms): 1433; eta: 2 days, 7:09:44; peak_mem(M): 6296;
INFO 2022-05-22 12:01:13,695 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1800; lr: 0.01; loss: 25.69254; btime(ms): 1499; eta: 2 days, 9:38:25; peak_mem(M): 6296;
INFO 2022-05-22 12:08:29,388 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 2000; lr: 0.01; loss: 25.50956; btime(ms): 1565; eta: 2 days, 12:04:52; peak_mem(M): 6296;
INFO 2022-05-22 12:15:46,662 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 2200; lr: 0.01; loss: 24.8368; btime(ms): 1623; eta: 2 days, 14:13:27; peak_mem(M): 6296;
INFO 2022-05-22 12:23:13,263 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 2400; lr: 0.01; loss: 24.68797; btime(ms): 1674; eta: 2 days, 16:04:44; peak_mem(M): 6296;
INFO 2022-05-22 12:30:31,467 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 2600; lr: 0.01; loss: 25.16098; btime(ms): 1714; eta: 2 days, 17:30:00; peak_mem(M): 6296;
INFO 2022-05-22 12:37:46,951 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 2800; lr: 0.01; loss: 24.59203; btime(ms): 1747; eta: 2 days, 18:40:14; peak_mem(M): 6296;
INFO 2022-05-22 12:44:42,131 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 3000; lr: 0.01; loss: 23.43747; btime(ms): 1769; eta: 2 days, 19:24:08; peak_mem(M): 6296;
INFO 2022-05-22 12:51:43,461 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 3200; lr: 0.01; loss: 24.44951; btime(ms): 1790; eta: 2 days, 20:06:33; peak_mem(M): 6296;
INFO 2022-05-22 12:58:29,128 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 3400; lr: 0.01; loss: 24.99737; btime(ms): 1804; eta: 2 days, 20:32:37; peak_mem(M): 6296;
INFO 2022-05-22 13:05:10,450 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 3600; lr: 0.01; loss: 23.6968; btime(ms): 1815; eta: 2 days, 20:52:02; peak_mem(M): 6296;
INFO 2022-05-22 13:11:53,801 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 3800; lr: 0.01; loss: 24.51499; btime(ms): 1826; eta: 2 days, 21:10:03; peak_mem(M): 6296;
INFO 2022-05-22 13:17:20,705 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 4000; lr: 0.01; loss: 24.01471; btime(ms): 1816; eta: 2 days, 20:42:19; peak_mem(M): 6296;
INFO 2022-05-22 13:21:43,855 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 4200; lr: 0.01; loss: 24.85569; btime(ms): 1792; eta: 2 days, 19:42:07; peak_mem(M): 6296;
INFO 2022-05-22 13:26:04,089 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 4400; lr: 0.01; loss: 25.45719; btime(ms): 1770; eta: 2 days, 18:45:33; peak_mem(M): 6296;
INFO 2022-05-22 13:30:26,935 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 4600; lr: 0.01; loss: 24.18208; btime(ms): 1750; eta: 2 days, 17:54:53; peak_mem(M): 6296;
INFO 2022-05-22 13:34:42,060 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 4800; lr: 0.01; loss: 24.98827; btime(ms): 1730; eta: 2 days, 17:04:26; peak_mem(M): 6296;
INFO 2022-05-22 13:39:00,057 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 5000; lr: 0.01; loss: 23.62834; btime(ms): 1713; eta: 2 days, 16:18:56; peak_mem(M): 6296;
INFO 2022-05-22 13:39:02,882 trainer_main.py: 214: Meters synced
INFO 2022-05-22 13:39:02,886 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1702
INFO 2022-05-22 13:39:02,887 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1275.05 ms 1272.82 ms
             forward:   14.90 ms  241.82 ms
        loss_compute:    3.08 ms    3.24 ms
     loss_all_reduce:    0.14 ms    0.13 ms
       meters_update:  167.99 ms  168.20 ms
            backward:    4.78 ms    7.88 ms
      optimizer_step:    1.55 ms    4.06 ms
    train_step_total: 1702.65 ms 1702.88 ms
INFO 2022-05-22 13:39:02,888 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 3.3886, 'res2': 9.9747, 'res3': 15.554599999999999, 'res4': 22.497600000000002, 'res5': 19.5672}, 'top_5': {'conv1': 9.4669, 'res2': 22.2109, 'res3': 31.0084, 'res4': 41.1284, 'res5': 37.5059}}
INFO 2022-05-22 13:39:02,888 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 13:39:02,891 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 13:39:02,892 log_hooks.py: 425: [phase: 0] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 13:39:03,928 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase0.torch
INFO 2022-05-22 13:39:03,929 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 13:39:03,931 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 13:39:03,932 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 13:39:43,397 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 13:39:43,397 state_update_hooks.py: 115: Starting phase 1 [test]
INFO 2022-05-22 13:44:24,729 trainer_main.py: 214: Meters synced
INFO 2022-05-22 13:44:24,733 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1435
INFO 2022-05-22 13:44:24,734 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 5.83, 'res2': 16.088, 'res3': 23.86, 'res4': 32.403999999999996, 'res5': 26.932000000000002}, 'top_5': {'conv1': 14.544, 'res2': 32.36, 'res3': 43.568, 'res4': 55.01200000000001, 'res5': 48.856}}
INFO 2022-05-22 13:44:24,735 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 13:44:24,738 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 13:44:24,738 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 13:45:06,689 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 13:45:06,693 state_update_hooks.py: 115: Starting phase 2 [train]
INFO 2022-05-22 13:49:16,663 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5200; lr: 0.01; loss: 23.271; btime(ms): 1701; eta: 2 days, 15:45:49; peak_mem(M): 6296;
INFO 2022-05-22 13:53:40,354 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5400; lr: 0.01; loss: 23.63481; btime(ms): 1687; eta: 2 days, 15:09:29; peak_mem(M): 6296;
INFO 2022-05-22 13:58:06,442 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5600; lr: 0.01; loss: 23.08377; btime(ms): 1675; eta: 2 days, 14:36:09; peak_mem(M): 6296;
INFO 2022-05-22 14:02:23,638 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5800; lr: 0.01; loss: 23.05083; btime(ms): 1662; eta: 2 days, 14:01:35; peak_mem(M): 6296;
INFO 2022-05-22 14:06:49,098 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 6000; lr: 0.01; loss: 23.37482; btime(ms): 1651; eta: 2 days, 13:31:59; peak_mem(M): 6296;
INFO 2022-05-22 14:11:11,001 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 6200; lr: 0.01; loss: 23.25453; btime(ms): 1640; eta: 2 days, 13:02:31; peak_mem(M): 6296;
INFO 2022-05-22 14:15:48,429 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 6400; lr: 0.01; loss: 22.90438; btime(ms): 1632; eta: 2 days, 12:39:45; peak_mem(M): 6296;
INFO 2022-05-22 14:20:43,721 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 6600; lr: 0.01; loss: 23.81369; btime(ms): 1628; eta: 2 days, 12:23:57; peak_mem(M): 6296;
INFO 2022-05-22 14:25:45,385 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 6800; lr: 0.01; loss: 23.43752; btime(ms): 1624; eta: 2 days, 12:11:08; peak_mem(M): 6296;
INFO 2022-05-22 14:30:06,375 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 7000; lr: 0.01; loss: 22.31533; btime(ms): 1616; eta: 2 days, 11:46:17; peak_mem(M): 6296;
INFO 2022-05-22 14:34:29,755 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 7200; lr: 0.01; loss: 21.89857; btime(ms): 1608; eta: 2 days, 11:23:25; peak_mem(M): 6296;
INFO 2022-05-22 14:38:56,066 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 7400; lr: 0.01; loss: 24.0954; btime(ms): 1601; eta: 2 days, 11:02:03; peak_mem(M): 6296;
INFO 2022-05-22 14:43:24,171 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 7600; lr: 0.01; loss: 24.02476; btime(ms): 1594; eta: 2 days, 10:41:29; peak_mem(M): 6296;
INFO 2022-05-22 14:47:52,381 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 7800; lr: 0.01; loss: 23.71334; btime(ms): 1587; eta: 2 days, 10:21:45; peak_mem(M): 6296;
INFO 2022-05-22 14:52:16,856 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 8000; lr: 0.01; loss: 23.12053; btime(ms): 1581; eta: 2 days, 10:02:21; peak_mem(M): 6296;
INFO 2022-05-22 14:56:46,421 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 8200; lr: 0.01; loss: 24.69688; btime(ms): 1575; eta: 2 days, 9:44:49; peak_mem(M): 6296;
INFO 2022-05-22 15:01:13,675 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 8400; lr: 0.01; loss: 23.94523; btime(ms): 1570; eta: 2 days, 9:27:18; peak_mem(M): 6296;
INFO 2022-05-22 15:05:43,059 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 8600; lr: 0.01; loss: 23.32138; btime(ms): 1564; eta: 2 days, 9:10:45; peak_mem(M): 6296;
INFO 2022-05-22 15:10:08,495 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 8800; lr: 0.01; loss: 23.87059; btime(ms): 1559; eta: 2 days, 8:54:11; peak_mem(M): 6296;
INFO 2022-05-22 15:14:33,839 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 9000; lr: 0.01; loss: 23.79033; btime(ms): 1554; eta: 2 days, 8:37:50; peak_mem(M): 6296;
INFO 2022-05-22 15:18:55,247 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 9200; lr: 0.01; loss: 22.67533; btime(ms): 1549; eta: 2 days, 8:22:04; peak_mem(M): 6296;
INFO 2022-05-22 15:23:21,567 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 9400; lr: 0.01; loss: 22.53697; btime(ms): 1545; eta: 2 days, 8:07:02; peak_mem(M): 6296;
INFO 2022-05-22 15:27:48,001 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 9600; lr: 0.01; loss: 23.49155; btime(ms): 1540; eta: 2 days, 7:52:25; peak_mem(M): 6296;
INFO 2022-05-22 15:32:14,968 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 9800; lr: 0.01; loss: 22.6577; btime(ms): 1536; eta: 2 days, 7:38:19; peak_mem(M): 6296;
INFO 2022-05-22 15:36:37,018 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 10000; lr: 0.01; loss: 23.3673; btime(ms): 1532; eta: 2 days, 7:23:34; peak_mem(M): 6296;
INFO 2022-05-22 15:36:46,459 trainer_main.py: 214: Meters synced
INFO 2022-05-22 15:36:46,463 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1338
INFO 2022-05-22 15:36:46,464 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  980.02 ms  978.18 ms
             forward:   10.62 ms  214.55 ms
        loss_compute:    1.14 ms    1.12 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  131.88 ms  132.01 ms
            backward:    3.51 ms    6.13 ms
      optimizer_step:    1.42 ms    3.71 ms
    train_step_total: 1338.43 ms 1338.61 ms
INFO 2022-05-22 15:36:46,465 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 4.4962, 'res2': 13.2486, 'res3': 20.619100000000003, 'res4': 28.913800000000002, 'res5': 25.465300000000003}, 'top_5': {'conv1': 11.9756, 'res2': 27.6247, 'res3': 38.4415, 'res4': 49.4223, 'res5': 45.563500000000005}}
INFO 2022-05-22 15:36:46,465 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 15:36:46,467 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 15:36:46,468 log_hooks.py: 425: [phase: 1] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 15:36:47,852 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase1.torch
INFO 2022-05-22 15:36:47,852 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 15:36:47,854 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 15:36:47,855 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 15:37:28,465 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 15:37:28,465 state_update_hooks.py: 115: Starting phase 3 [test]
INFO 2022-05-22 15:42:34,692 trainer_main.py: 214: Meters synced
INFO 2022-05-22 15:42:34,698 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1562
INFO 2022-05-22 15:42:34,699 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 6.5280000000000005, 'res2': 17.64, 'res3': 26.392, 'res4': 35.321999999999996, 'res5': 30.016}, 'top_5': {'conv1': 16.02, 'res2': 34.966, 'res3': 46.884, 'res4': 57.936, 'res5': 51.93}}
INFO 2022-05-22 15:42:34,700 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 15:42:34,703 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 15:42:34,704 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 4, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 15:43:21,120 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 15:43:21,121 state_update_hooks.py: 115: Starting phase 4 [train]
INFO 2022-05-22 15:48:06,112 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 10200; lr: 0.01; loss: 22.72349; btime(ms): 1540; eta: 2 days, 7:35:16; peak_mem(M): 6296;
INFO 2022-05-22 15:52:57,797 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 10400; lr: 0.01; loss: 22.61273; btime(ms): 1538; eta: 2 days, 7:26:52; peak_mem(M): 6296;
INFO 2022-05-22 15:57:46,653 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 10600; lr: 0.01; loss: 23.46745; btime(ms): 1536; eta: 2 days, 7:18:03; peak_mem(M): 6296;
INFO 2022-05-22 16:02:23,875 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 10800; lr: 0.01; loss: 23.14099; btime(ms): 1534; eta: 2 days, 7:07:07; peak_mem(M): 6296;
INFO 2022-05-22 16:07:05,385 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 11000; lr: 0.01; loss: 23.58949; btime(ms): 1531; eta: 2 days, 6:57:13; peak_mem(M): 6296;
INFO 2022-05-22 16:11:35,254 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 11200; lr: 0.01; loss: 22.44499; btime(ms): 1528; eta: 2 days, 6:45:21; peak_mem(M): 6296;
INFO 2022-05-22 16:15:44,074 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 11400; lr: 0.01; loss: 22.72119; btime(ms): 1523; eta: 2 days, 6:29:48; peak_mem(M): 6296;
INFO 2022-05-22 16:19:50,219 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 11600; lr: 0.01; loss: 22.16663; btime(ms): 1518; eta: 2 days, 6:14:04; peak_mem(M): 6296;
INFO 2022-05-22 16:24:01,981 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 11800; lr: 0.01; loss: 23.27789; btime(ms): 1514; eta: 2 days, 5:59:35; peak_mem(M): 6296;
INFO 2022-05-22 16:28:10,567 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 12000; lr: 0.01; loss: 22.52997; btime(ms): 1510; eta: 2 days, 5:45:06; peak_mem(M): 6296;
INFO 2022-05-22 16:32:17,854 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 12200; lr: 0.01; loss: 22.99073; btime(ms): 1505; eta: 2 days, 5:30:56; peak_mem(M): 6296;
INFO 2022-05-22 16:36:31,061 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 12400; lr: 0.01; loss: 22.65639; btime(ms): 1502; eta: 2 days, 5:17:49; peak_mem(M): 6296;
INFO 2022-05-22 16:40:42,410 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 12600; lr: 0.01; loss: 22.86684; btime(ms): 1498; eta: 2 days, 5:04:50; peak_mem(M): 6296;
INFO 2022-05-22 16:44:49,190 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 12800; lr: 0.01; loss: 22.80403; btime(ms): 1494; eta: 2 days, 4:51:20; peak_mem(M): 6296;
INFO 2022-05-22 16:49:01,431 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 13000; lr: 0.01; loss: 23.32833; btime(ms): 1490; eta: 2 days, 4:38:56; peak_mem(M): 6296;
INFO 2022-05-22 16:53:09,852 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 13200; lr: 0.01; loss: 23.32033; btime(ms): 1487; eta: 2 days, 4:26:19; peak_mem(M): 6296;
INFO 2022-05-22 16:57:19,191 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 13400; lr: 0.01; loss: 22.05628; btime(ms): 1483; eta: 2 days, 4:14:06; peak_mem(M): 6296;
INFO 2022-05-22 17:01:29,191 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 13600; lr: 0.01; loss: 22.57244; btime(ms): 1480; eta: 2 days, 4:02:24; peak_mem(M): 6296;
INFO 2022-05-22 17:05:43,199 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 13800; lr: 0.01; loss: 23.07249; btime(ms): 1477; eta: 2 days, 3:50:46; peak_mem(M): 6296;
INFO 2022-05-22 17:09:54,244 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 14000; lr: 0.01; loss: 22.95549; btime(ms): 1474; eta: 2 days, 3:39:15; peak_mem(M): 6296;
INFO 2022-05-22 17:14:05,820 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 14200; lr: 0.01; loss: 24.30783; btime(ms): 1471; eta: 2 days, 3:28:12; peak_mem(M): 6296;
INFO 2022-05-22 17:18:19,468 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 14400; lr: 0.01; loss: 21.86327; btime(ms): 1468; eta: 2 days, 3:17:26; peak_mem(M): 6296;
INFO 2022-05-22 17:23:03,224 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 14600; lr: 0.01; loss: 23.11813; btime(ms): 1467; eta: 2 days, 3:11:09; peak_mem(M): 6296;
INFO 2022-05-22 17:27:46,766 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 14800; lr: 0.01; loss: 23.4981; btime(ms): 1467; eta: 2 days, 3:04:49; peak_mem(M): 6296;
INFO 2022-05-22 17:32:32,552 log_hooks.py: 277: Rank: 0; [ep: 2] iter: 15000; lr: 0.01; loss: 23.30572; btime(ms): 1466; eta: 2 days, 2:58:59; peak_mem(M): 6296;
INFO 2022-05-22 17:32:46,775 trainer_main.py: 214: Meters synced
INFO 2022-05-22 17:32:46,779 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1311
INFO 2022-05-22 17:32:46,779 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  952.21 ms  950.22 ms
             forward:   10.58 ms  214.53 ms
        loss_compute:    1.11 ms    1.09 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  132.80 ms  132.91 ms
            backward:    3.46 ms    6.10 ms
      optimizer_step:    1.37 ms    3.67 ms
    train_step_total: 1311.64 ms 1311.82 ms
INFO 2022-05-22 17:32:46,781 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 4.8152, 'res2': 14.1505, 'res3': 21.7884, 'res4': 30.499599999999997, 'res5': 27.0949}, 'top_5': {'conv1': 12.6385, 'res2': 28.921200000000002, 'res3': 40.1044, 'res4': 51.2921, 'res5': 47.641}}
INFO 2022-05-22 17:32:46,781 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 17:32:46,784 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 17:32:46,785 log_hooks.py: 425: [phase: 2] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 17:32:47,812 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase2.torch
INFO 2022-05-22 17:32:47,813 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 17:32:47,815 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 17:32:47,816 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 5, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 17:33:29,120 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 17:33:29,121 state_update_hooks.py: 115: Starting phase 5 [test]
INFO 2022-05-22 17:38:37,592 trainer_main.py: 214: Meters synced
INFO 2022-05-22 17:38:37,597 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1573
INFO 2022-05-22 17:38:37,598 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 6.934, 'res2': 18.482000000000003, 'res3': 27.454, 'res4': 36.19, 'res5': 31.003999999999998}, 'top_5': {'conv1': 16.782, 'res2': 35.72, 'res3': 47.910000000000004, 'res4': 58.85399999999999, 'res5': 53.108}}
INFO 2022-05-22 17:38:37,598 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 17:38:37,601 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 17:38:37,602 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 6, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 17:39:22,243 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 17:39:22,244 state_update_hooks.py: 115: Starting phase 6 [train]
INFO 2022-05-22 17:43:40,565 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 15200; lr: 0.01; loss: 21.98736; btime(ms): 1472; eta: 2 days, 3:06:06; peak_mem(M): 6296;
INFO 2022-05-22 17:48:15,637 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 15400; lr: 0.01; loss: 23.9821; btime(ms): 1471; eta: 2 days, 2:58:40; peak_mem(M): 6296;
INFO 2022-05-22 17:52:33,797 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 15600; lr: 0.01; loss: 22.72928; btime(ms): 1469; eta: 2 days, 2:49:09; peak_mem(M): 6296;
INFO 2022-05-22 17:56:38,630 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 15800; lr: 0.01; loss: 21.65198; btime(ms): 1466; eta: 2 days, 2:38:03; peak_mem(M): 6296;
INFO 2022-05-22 18:00:46,670 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 16000; lr: 0.01; loss: 22.43206; btime(ms): 1463; eta: 2 days, 2:27:16; peak_mem(M): 6296;
INFO 2022-05-22 18:04:52,502 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 16200; lr: 0.01; loss: 22.54223; btime(ms): 1460; eta: 2 days, 2:16:30; peak_mem(M): 6296;
INFO 2022-05-22 18:08:56,883 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 16400; lr: 0.01; loss: 22.05527; btime(ms): 1457; eta: 2 days, 2:06:03; peak_mem(M): 6296;
INFO 2022-05-22 18:13:03,383 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 16600; lr: 0.01; loss: 22.77639; btime(ms): 1455; eta: 2 days, 1:55:58; peak_mem(M): 6296;
INFO 2022-05-22 18:17:10,486 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 16800; lr: 0.01; loss: 22.61679; btime(ms): 1452; eta: 2 days, 1:45:56; peak_mem(M): 6296;
INFO 2022-05-22 18:21:16,342 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 17000; lr: 0.01; loss: 23.34804; btime(ms): 1450; eta: 2 days, 1:35:53; peak_mem(M): 6296;
INFO 2022-05-22 18:25:23,784 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 17200; lr: 0.01; loss: 23.61069; btime(ms): 1447; eta: 2 days, 1:26:09; peak_mem(M): 6296;
INFO 2022-05-22 18:29:32,006 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 17400; lr: 0.01; loss: 23.28069; btime(ms): 1445; eta: 2 days, 1:16:38; peak_mem(M): 6296;
INFO 2022-05-22 18:33:39,786 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 17600; lr: 0.01; loss: 21.63269; btime(ms): 1443; eta: 2 days, 1:07:10; peak_mem(M): 6296;
INFO 2022-05-22 18:37:46,449 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 17800; lr: 0.01; loss: 23.76998; btime(ms): 1440; eta: 2 days, 0:57:43; peak_mem(M): 6296;
INFO 2022-05-22 18:41:54,651 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 18000; lr: 0.01; loss: 22.18037; btime(ms): 1438; eta: 2 days, 0:48:32; peak_mem(M): 6296;
INFO 2022-05-22 18:46:02,296 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 18200; lr: 0.01; loss: 22.6193; btime(ms): 1436; eta: 2 days, 0:39:25; peak_mem(M): 6296;
INFO 2022-05-22 18:50:07,940 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 18400; lr: 0.01; loss: 22.25104; btime(ms): 1434; eta: 2 days, 0:30:10; peak_mem(M): 6296;
INFO 2022-05-22 18:54:16,786 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 18600; lr: 0.01; loss: 21.81143; btime(ms): 1432; eta: 2 days, 0:21:23; peak_mem(M): 6296;
INFO 2022-05-22 18:58:26,704 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 18800; lr: 0.01; loss: 22.21636; btime(ms): 1430; eta: 2 days, 0:12:47; peak_mem(M): 6296;
INFO 2022-05-22 19:02:40,767 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 19000; lr: 0.01; loss: 22.70419; btime(ms): 1428; eta: 2 days, 0:04:42; peak_mem(M): 6296;
INFO 2022-05-22 19:06:52,115 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 19200; lr: 0.01; loss: 22.46598; btime(ms): 1427; eta: 1 day, 23:56:28; peak_mem(M): 6296;
INFO 2022-05-22 19:11:03,646 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 19400; lr: 0.01; loss: 22.15669; btime(ms): 1425; eta: 1 day, 23:48:17; peak_mem(M): 6296;
INFO 2022-05-22 19:15:28,221 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 19600; lr: 0.01; loss: 21.60473; btime(ms): 1424; eta: 1 day, 23:41:30; peak_mem(M): 6296;
INFO 2022-05-22 19:20:19,358 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 19800; lr: 0.01; loss: 22.74107; btime(ms): 1424; eta: 1 day, 23:37:22; peak_mem(M): 6296;
INFO 2022-05-22 19:25:11,417 log_hooks.py: 277: Rank: 0; [ep: 3] iter: 20000; lr: 0.01; loss: 23.0654; btime(ms): 1424; eta: 1 day, 23:33:18; peak_mem(M): 6296;
INFO 2022-05-22 19:25:35,154 trainer_main.py: 214: Meters synced
INFO 2022-05-22 19:25:35,157 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1273
INFO 2022-05-22 19:25:35,157 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  919.98 ms  918.13 ms
             forward:   10.13 ms  214.53 ms
        loss_compute:    1.08 ms    1.06 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  126.84 ms  126.95 ms
            backward:    3.34 ms    5.98 ms
      optimizer_step:    1.33 ms    3.68 ms
    train_step_total: 1273.13 ms 1273.31 ms
INFO 2022-05-22 19:25:35,159 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 5.008900000000001, 'res2': 14.5748, 'res3': 22.4423, 'res4': 31.3479, 'res5': 27.9386}, 'top_5': {'conv1': 13.003300000000001, 'res2': 29.6025, 'res3': 40.9163, 'res4': 52.17659999999999, 'res5': 48.6627}}
INFO 2022-05-22 19:25:35,159 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 19:25:35,162 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 19:25:35,162 log_hooks.py: 425: [phase: 3] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 19:25:36,204 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase3.torch
INFO 2022-05-22 19:25:36,205 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 19:25:36,207 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 19:25:36,208 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 7, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 19:26:16,599 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 19:26:16,600 state_update_hooks.py: 115: Starting phase 7 [test]
INFO 2022-05-22 19:31:21,772 trainer_main.py: 214: Meters synced
INFO 2022-05-22 19:31:21,776 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1557
INFO 2022-05-22 19:31:21,777 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 6.864000000000001, 'res2': 18.872, 'res3': 27.506000000000004, 'res4': 36.403999999999996, 'res5': 31.203999999999997}, 'top_5': {'conv1': 16.778000000000002, 'res2': 36.44, 'res3': 48.392, 'res4': 59.324, 'res5': 53.644000000000005}}
INFO 2022-05-22 19:31:21,777 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 19:31:21,780 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 19:31:21,780 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 8, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 19:32:05,294 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 19:32:05,295 state_update_hooks.py: 115: Starting phase 8 [train]
INFO 2022-05-22 19:36:15,985 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 20200; lr: 0.01; loss: 21.88314; btime(ms): 1429; eta: 1 day, 23:38:06; peak_mem(M): 6296;
INFO 2022-05-22 19:40:54,755 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 20400; lr: 0.01; loss: 22.03576; btime(ms): 1429; eta: 1 day, 23:32:36; peak_mem(M): 6296;
INFO 2022-05-22 19:45:33,037 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 20600; lr: 0.01; loss: 22.13755; btime(ms): 1428; eta: 1 day, 23:27:00; peak_mem(M): 6296;
INFO 2022-05-22 19:50:02,920 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 20800; lr: 0.01; loss: 22.01231; btime(ms): 1428; eta: 1 day, 23:20:58; peak_mem(M): 6296;
INFO 2022-05-22 19:54:20,132 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 21000; lr: 0.01; loss: 23.09782; btime(ms): 1427; eta: 1 day, 23:13:36; peak_mem(M): 6296;
INFO 2022-05-22 19:58:41,077 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 21200; lr: 0.01; loss: 22.42908; btime(ms): 1425; eta: 1 day, 23:06:39; peak_mem(M): 6296;
INFO 2022-05-22 20:02:55,266 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 21400; lr: 0.01; loss: 22.48456; btime(ms): 1424; eta: 1 day, 22:59:07; peak_mem(M): 6296;
INFO 2022-05-22 20:07:11,844 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 21600; lr: 0.01; loss: 22.41224; btime(ms): 1423; eta: 1 day, 22:51:53; peak_mem(M): 6296;
INFO 2022-05-22 20:11:26,021 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 21800; lr: 0.01; loss: 22.72402; btime(ms): 1421; eta: 1 day, 22:44:28; peak_mem(M): 6296;
INFO 2022-05-22 20:15:43,606 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 22000; lr: 0.01; loss: 22.08608; btime(ms): 1420; eta: 1 day, 22:37:25; peak_mem(M): 6296;
INFO 2022-05-22 20:20:05,031 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 22200; lr: 0.01; loss: 24.17658; btime(ms): 1419; eta: 1 day, 22:30:44; peak_mem(M): 6296;
INFO 2022-05-22 20:24:25,007 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 22400; lr: 0.01; loss: 23.86442; btime(ms): 1418; eta: 1 day, 22:23:58; peak_mem(M): 6296;
INFO 2022-05-22 20:28:46,058 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 22600; lr: 0.01; loss: 22.41864; btime(ms): 1417; eta: 1 day, 22:17:08; peak_mem(M): 6296;
INFO 2022-05-22 20:33:03,993 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 22800; lr: 0.01; loss: 22.50525; btime(ms): 1416; eta: 1 day, 22:10:30; peak_mem(M): 6296;
INFO 2022-05-22 20:37:23,795 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 23000; lr: 0.01; loss: 22.40124; btime(ms): 1415; eta: 1 day, 22:03:50; peak_mem(M): 6296;
INFO 2022-05-22 20:41:44,818 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 23200; lr: 0.01; loss: 23.55773; btime(ms): 1414; eta: 1 day, 21:57:15; peak_mem(M): 6296;
INFO 2022-05-22 20:46:04,455 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 23400; lr: 0.01; loss: 22.83958; btime(ms): 1413; eta: 1 day, 21:50:42; peak_mem(M): 6296;
INFO 2022-05-22 20:50:22,973 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 23600; lr: 0.01; loss: 22.60722; btime(ms): 1412; eta: 1 day, 21:44:05; peak_mem(M): 6296;
INFO 2022-05-22 20:54:44,610 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 23800; lr: 0.01; loss: 22.83571; btime(ms): 1411; eta: 1 day, 21:37:34; peak_mem(M): 6296;
INFO 2022-05-22 20:59:04,221 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 24000; lr: 0.01; loss: 21.97146; btime(ms): 1411; eta: 1 day, 21:31:15; peak_mem(M): 6296;
INFO 2022-05-22 21:03:22,756 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 24200; lr: 0.01; loss: 21.95151; btime(ms): 1410; eta: 1 day, 21:24:42; peak_mem(M): 6296;
INFO 2022-05-22 21:07:57,462 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 24400; lr: 0.01; loss: 22.97079; btime(ms): 1409; eta: 1 day, 21:19:27; peak_mem(M): 6296;
INFO 2022-05-22 21:12:37,437 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 24600; lr: 0.01; loss: 22.80997; btime(ms): 1409; eta: 1 day, 21:14:17; peak_mem(M): 6296;
INFO 2022-05-22 21:17:19,762 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 24800; lr: 0.01; loss: 23.241; btime(ms): 1409; eta: 1 day, 21:09:33; peak_mem(M): 6296;
INFO 2022-05-22 21:22:06,877 log_hooks.py: 277: Rank: 0; [ep: 4] iter: 25000; lr: 0.01; loss: 21.97263; btime(ms): 1409; eta: 1 day, 21:05:19; peak_mem(M): 6296;
INFO 2022-05-22 21:22:33,556 trainer_main.py: 214: Meters synced
INFO 2022-05-22 21:22:33,559 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1324
INFO 2022-05-22 21:22:33,560 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  962.66 ms  960.66 ms
             forward:   10.72 ms  214.57 ms
        loss_compute:    1.14 ms    1.13 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  134.90 ms  135.04 ms
            backward:    3.43 ms    6.04 ms
      optimizer_step:    1.43 ms    3.68 ms
    train_step_total: 1324.14 ms 1324.33 ms
INFO 2022-05-22 21:22:33,561 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 5.132099999999999, 'res2': 14.8268, 'res3': 22.778599999999997, 'res4': 31.6365, 'res5': 28.4091}, 'top_5': {'conv1': 13.206000000000001, 'res2': 29.9582, 'res3': 41.2873, 'res4': 52.5476, 'res5': 49.2167}}
INFO 2022-05-22 21:22:33,561 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 21:22:33,564 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 21:22:33,564 log_hooks.py: 425: [phase: 4] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 21:22:34,634 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase4.torch
INFO 2022-05-22 21:22:34,634 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 21:22:34,637 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 21:22:34,637 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 9, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 21:23:15,951 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 21:23:15,952 state_update_hooks.py: 115: Starting phase 9 [test]
INFO 2022-05-22 21:28:31,042 trainer_main.py: 214: Meters synced
INFO 2022-05-22 21:28:31,048 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1607
INFO 2022-05-22 21:28:31,049 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 7.224, 'res2': 19.298000000000002, 'res3': 27.996, 'res4': 37.036, 'res5': 31.569999999999997}, 'top_5': {'conv1': 17.222, 'res2': 36.902, 'res3': 48.876, 'res4': 59.572, 'res5': 53.87}}
INFO 2022-05-22 21:28:31,050 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 21:28:31,052 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 21:28:31,053 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 10, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 21:29:18,463 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 21:29:18,463 state_update_hooks.py: 115: Starting phase 10 [train]
INFO 2022-05-22 21:33:36,136 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 25200; lr: 0.01; loss: 22.12578; btime(ms): 1414; eta: 1 day, 21:10:12; peak_mem(M): 6296;
INFO 2022-05-22 21:38:06,826 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 25400; lr: 0.01; loss: 21.50545; btime(ms): 1414; eta: 1 day, 21:04:38; peak_mem(M): 6296;
INFO 2022-05-22 21:42:15,755 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 25600; lr: 0.01; loss: 22.04398; btime(ms): 1413; eta: 1 day, 20:57:38; peak_mem(M): 6296;
INFO 2022-05-22 21:46:23,778 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 25800; lr: 0.01; loss: 22.71782; btime(ms): 1411; eta: 1 day, 20:50:34; peak_mem(M): 6296;
INFO 2022-05-22 21:50:34,356 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 26000; lr: 0.01; loss: 22.64938; btime(ms): 1410; eta: 1 day, 20:43:37; peak_mem(M): 6296;
INFO 2022-05-22 21:54:43,349 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 26200; lr: 0.01; loss: 22.73379; btime(ms): 1409; eta: 1 day, 20:36:36; peak_mem(M): 6296;
INFO 2022-05-22 21:58:56,533 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 26400; lr: 0.01; loss: 22.50666; btime(ms): 1408; eta: 1 day, 20:29:53; peak_mem(M): 6296;
INFO 2022-05-22 22:03:10,485 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 26600; lr: 0.01; loss: 22.56147; btime(ms): 1407; eta: 1 day, 20:23:05; peak_mem(M): 6296;
INFO 2022-05-22 22:07:21,939 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 26800; lr: 0.01; loss: 22.08279; btime(ms): 1406; eta: 1 day, 20:16:21; peak_mem(M): 6296;
INFO 2022-05-22 22:11:32,132 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 27000; lr: 0.01; loss: 22.64127; btime(ms): 1405; eta: 1 day, 20:09:36; peak_mem(M): 6296;
INFO 2022-05-22 22:15:41,714 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 27200; lr: 0.01; loss: 22.89756; btime(ms): 1404; eta: 1 day, 20:02:48; peak_mem(M): 6296;
INFO 2022-05-22 22:19:52,500 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 27400; lr: 0.01; loss: 23.74728; btime(ms): 1402; eta: 1 day, 19:56:11; peak_mem(M): 6296;
INFO 2022-05-22 22:24:05,496 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 27600; lr: 0.01; loss: 23.01763; btime(ms): 1401; eta: 1 day, 19:49:37; peak_mem(M): 6296;
INFO 2022-05-22 22:28:17,456 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 27800; lr: 0.01; loss: 22.38455; btime(ms): 1400; eta: 1 day, 19:43:06; peak_mem(M): 6296;
INFO 2022-05-22 22:32:26,563 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 28000; lr: 0.01; loss: 22.20367; btime(ms): 1399; eta: 1 day, 19:36:34; peak_mem(M): 6296;
INFO 2022-05-22 22:36:39,663 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 28200; lr: 0.01; loss: 24.2071; btime(ms): 1399; eta: 1 day, 19:30:16; peak_mem(M): 6296;
INFO 2022-05-22 22:40:51,789 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 28400; lr: 0.01; loss: 22.50296; btime(ms): 1398; eta: 1 day, 19:23:51; peak_mem(M): 6296;
INFO 2022-05-22 22:45:04,405 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 28600; lr: 0.01; loss: 22.15566; btime(ms): 1397; eta: 1 day, 19:17:29; peak_mem(M): 6296;
INFO 2022-05-22 22:49:16,331 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 28800; lr: 0.01; loss: 22.8638; btime(ms): 1396; eta: 1 day, 19:11:07; peak_mem(M): 6296;
INFO 2022-05-22 22:53:22,848 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 29000; lr: 0.01; loss: 22.4193; btime(ms): 1395; eta: 1 day, 19:04:26; peak_mem(M): 6296;
INFO 2022-05-22 22:57:36,112 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 29200; lr: 0.01; loss: 21.42844; btime(ms): 1394; eta: 1 day, 18:58:12; peak_mem(M): 6296;
INFO 2022-05-22 23:01:45,583 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 29400; lr: 0.01; loss: 22.43233; btime(ms): 1393; eta: 1 day, 18:51:46; peak_mem(M): 6296;
INFO 2022-05-22 23:06:28,695 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 29600; lr: 0.01; loss: 22.6076; btime(ms): 1393; eta: 1 day, 18:47:23; peak_mem(M): 6296;
INFO 2022-05-22 23:11:18,869 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 29800; lr: 0.01; loss: 21.05562; btime(ms): 1393; eta: 1 day, 18:43:26; peak_mem(M): 6296;
INFO 2022-05-22 23:16:02,744 log_hooks.py: 277: Rank: 0; [ep: 5] iter: 30000; lr: 0.01; loss: 23.66658; btime(ms): 1394; eta: 1 day, 18:39:05; peak_mem(M): 6296;
INFO 2022-05-22 23:16:40,297 trainer_main.py: 214: Meters synced
INFO 2022-05-22 23:16:40,300 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1287
INFO 2022-05-22 23:16:40,301 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  927.91 ms  925.98 ms
             forward:   10.42 ms  214.57 ms
        loss_compute:    1.12 ms    1.10 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  132.29 ms  132.41 ms
            backward:    3.39 ms    6.05 ms
      optimizer_step:    1.37 ms    3.68 ms
    train_step_total: 1286.89 ms 1287.08 ms
INFO 2022-05-22 23:16:40,302 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 5.151, 'res2': 15.0044, 'res3': 22.9814, 'res4': 31.9172, 'res5': 28.603099999999998}, 'top_5': {'conv1': 13.281200000000002, 'res2': 30.209000000000003, 'res3': 41.5726, 'res4': 52.7716, 'res5': 49.5017}}
INFO 2022-05-22 23:16:40,303 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 23:16:40,306 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 23:16:40,307 log_hooks.py: 425: [phase: 5] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-22 23:16:41,466 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase5.torch
INFO 2022-05-22 23:16:41,467 checkpoint.py: 140: Creating symlink...
INFO 2022-05-22 23:16:41,470 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-22 23:16:41,471 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 11, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 23:17:23,599 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 23:17:23,600 state_update_hooks.py: 115: Starting phase 11 [test]
INFO 2022-05-22 23:22:39,215 trainer_main.py: 214: Meters synced
INFO 2022-05-22 23:22:39,224 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1610
INFO 2022-05-22 23:22:39,225 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 7.321999999999999, 'res2': 19.168, 'res3': 27.939999999999998, 'res4': 36.696, 'res5': 31.480000000000004}, 'top_5': {'conv1': 17.506, 'res2': 36.693999999999996, 'res3': 48.948, 'res4': 59.378, 'res5': 54.034000000000006}}
INFO 2022-05-22 23:22:39,226 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 23:22:39,229 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-22 23:22:39,230 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 12, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-22 23:23:26,621 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-22 23:23:26,621 state_update_hooks.py: 115: Starting phase 12 [train]
INFO 2022-05-22 23:27:33,129 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 30200; lr: 0.01; loss: 22.23842; btime(ms): 1398; eta: 1 day, 18:42:31; peak_mem(M): 6296;
INFO 2022-05-22 23:32:02,396 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 30400; lr: 0.01; loss: 21.37099; btime(ms): 1398; eta: 1 day, 18:37:15; peak_mem(M): 6296;
INFO 2022-05-22 23:36:28,429 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 30600; lr: 0.01; loss: 22.12714; btime(ms): 1397; eta: 1 day, 18:31:49; peak_mem(M): 6296;
INFO 2022-05-22 23:40:45,543 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 30800; lr: 0.01; loss: 21.45925; btime(ms): 1397; eta: 1 day, 18:25:52; peak_mem(M): 6296;
INFO 2022-05-22 23:44:56,504 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 31000; lr: 0.01; loss: 22.27878; btime(ms): 1396; eta: 1 day, 18:19:34; peak_mem(M): 6296;
INFO 2022-05-22 23:49:09,035 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 31200; lr: 0.01; loss: 23.66087; btime(ms): 1395; eta: 1 day, 18:13:27; peak_mem(M): 6296;
INFO 2022-05-22 23:53:20,694 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 31400; lr: 0.01; loss: 21.87526; btime(ms): 1394; eta: 1 day, 18:07:05; peak_mem(M): 6296;
INFO 2022-05-22 23:57:34,876 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 31600; lr: 0.01; loss: 22.0068; btime(ms): 1393; eta: 1 day, 18:01:04; peak_mem(M): 6296;
INFO 2022-05-23 00:01:45,448 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 31800; lr: 0.01; loss: 22.39904; btime(ms): 1392; eta: 1 day, 17:54:52; peak_mem(M): 6296;
INFO 2022-05-23 00:05:54,609 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 32000; lr: 0.01; loss: 22.89461; btime(ms): 1391; eta: 1 day, 17:48:41; peak_mem(M): 6296;
INFO 2022-05-23 00:10:05,344 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 32200; lr: 0.01; loss: 22.87639; btime(ms): 1391; eta: 1 day, 17:42:31; peak_mem(M): 6296;
INFO 2022-05-23 00:14:11,708 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 32400; lr: 0.01; loss: 22.81927; btime(ms): 1390; eta: 1 day, 17:36:10; peak_mem(M): 6296;
INFO 2022-05-23 00:18:22,612 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 32600; lr: 0.01; loss: 22.74428; btime(ms): 1389; eta: 1 day, 17:30:07; peak_mem(M): 6296;
INFO 2022-05-23 00:22:29,466 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 32800; lr: 0.01; loss: 23.25411; btime(ms): 1388; eta: 1 day, 17:23:57; peak_mem(M): 6296;
INFO 2022-05-23 00:26:39,011 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 33000; lr: 0.01; loss: 21.85019; btime(ms): 1387; eta: 1 day, 17:17:56; peak_mem(M): 6296;
INFO 2022-05-23 00:30:49,939 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 33200; lr: 0.01; loss: 21.86803; btime(ms): 1386; eta: 1 day, 17:11:55; peak_mem(M): 6296;
INFO 2022-05-23 00:34:59,031 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 33400; lr: 0.01; loss: 22.19018; btime(ms): 1386; eta: 1 day, 17:05:51; peak_mem(M): 6296;
INFO 2022-05-23 00:39:05,835 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 33600; lr: 0.01; loss: 21.80715; btime(ms): 1385; eta: 1 day, 16:59:40; peak_mem(M): 6296;
INFO 2022-05-23 00:43:18,615 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 33800; lr: 0.01; loss: 22.48575; btime(ms): 1384; eta: 1 day, 16:53:49; peak_mem(M): 6296;
INFO 2022-05-23 00:47:25,485 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 34000; lr: 0.01; loss: 23.24543; btime(ms): 1383; eta: 1 day, 16:47:42; peak_mem(M): 6296;
INFO 2022-05-23 00:51:33,877 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 34200; lr: 0.01; loss: 21.01354; btime(ms): 1382; eta: 1 day, 16:41:40; peak_mem(M): 6296;
INFO 2022-05-23 00:55:44,865 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 34400; lr: 0.01; loss: 22.6181; btime(ms): 1382; eta: 1 day, 16:35:47; peak_mem(M): 6296;
INFO 2022-05-23 00:59:56,628 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 34600; lr: 0.01; loss: 21.86143; btime(ms): 1381; eta: 1 day, 16:29:58; peak_mem(M): 6296;
INFO 2022-05-23 01:04:13,068 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 34800; lr: 0.01; loss: 22.66963; btime(ms): 1380; eta: 1 day, 16:24:24; peak_mem(M): 6296;
INFO 2022-05-23 01:08:48,916 log_hooks.py: 277: Rank: 0; [ep: 6] iter: 35000; lr: 0.01; loss: 23.05562; btime(ms): 1380; eta: 1 day, 16:19:45; peak_mem(M): 6296;
INFO 2022-05-23 01:09:31,878 trainer_main.py: 214: Meters synced
INFO 2022-05-23 01:09:31,882 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1271
INFO 2022-05-23 01:09:31,883 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  914.15 ms  912.21 ms
             forward:   10.32 ms  214.52 ms
        loss_compute:    1.10 ms    1.08 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  131.04 ms  131.16 ms
            backward:    3.32 ms    5.97 ms
      optimizer_step:    1.40 ms    3.71 ms
    train_step_total: 1271.59 ms 1271.78 ms
INFO 2022-05-23 01:09:31,884 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 5.2315000000000005, 'res2': 15.1065, 'res3': 23.1582, 'res4': 31.998199999999997, 'res5': 28.7684}, 'top_5': {'conv1': 13.395399999999999, 'res2': 30.372500000000002, 'res3': 41.734300000000005, 'res4': 52.935500000000005, 'res5': 49.6594}}
INFO 2022-05-23 01:09:31,884 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 01:09:31,887 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 01:09:31,888 log_hooks.py: 425: [phase: 6] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 01:09:32,990 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase6.torch
INFO 2022-05-23 01:09:32,991 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 01:09:32,993 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 01:09:32,994 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 13, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 01:10:14,802 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 01:10:14,803 state_update_hooks.py: 115: Starting phase 13 [test]
INFO 2022-05-23 01:15:10,352 trainer_main.py: 214: Meters synced
INFO 2022-05-23 01:15:10,356 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1507
INFO 2022-05-23 01:15:10,357 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 7.282, 'res2': 19.212, 'res3': 28.242, 'res4': 36.916, 'res5': 31.724000000000004}, 'top_5': {'conv1': 17.526, 'res2': 36.892, 'res3': 49.248, 'res4': 59.762, 'res5': 54.19199999999999}}
INFO 2022-05-23 01:15:10,357 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 01:15:10,360 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 01:15:10,360 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 14, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 01:15:54,846 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 01:15:54,847 state_update_hooks.py: 115: Starting phase 14 [train]
INFO 2022-05-23 01:19:38,836 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 35200; lr: 0.01; loss: 21.98853; btime(ms): 1383; eta: 1 day, 16:20:06; peak_mem(M): 6296;
INFO 2022-05-23 01:24:10,514 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 35400; lr: 0.01; loss: 21.99203; btime(ms): 1383; eta: 1 day, 16:15:15; peak_mem(M): 6296;
INFO 2022-05-23 01:28:41,800 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 35600; lr: 0.01; loss: 21.94405; btime(ms): 1383; eta: 1 day, 16:10:23; peak_mem(M): 6296;
INFO 2022-05-23 01:33:13,857 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 35800; lr: 0.01; loss: 22.74387; btime(ms): 1383; eta: 1 day, 16:05:34; peak_mem(M): 6296;
INFO 2022-05-23 01:37:41,998 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 36000; lr: 0.01; loss: 21.45539; btime(ms): 1383; eta: 1 day, 16:00:27; peak_mem(M): 6296;
INFO 2022-05-23 01:42:25,005 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 36200; lr: 0.01; loss: 22.42167; btime(ms): 1383; eta: 1 day, 15:56:06; peak_mem(M): 6296;
INFO 2022-05-23 01:47:01,898 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 36400; lr: 0.01; loss: 21.7002; btime(ms): 1383; eta: 1 day, 15:51:29; peak_mem(M): 6296;
INFO 2022-05-23 01:51:16,894 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 36600; lr: 0.01; loss: 22.12552; btime(ms): 1382; eta: 1 day, 15:45:53; peak_mem(M): 6296;
INFO 2022-05-23 01:55:37,121 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 36800; lr: 0.01; loss: 22.50611; btime(ms): 1382; eta: 1 day, 15:40:32; peak_mem(M): 6296;
INFO 2022-05-23 01:59:54,916 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 37000; lr: 0.01; loss: 22.35889; btime(ms): 1381; eta: 1 day, 15:35:05; peak_mem(M): 6296;
INFO 2022-05-23 02:04:13,492 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 37200; lr: 0.01; loss: 22.44296; btime(ms): 1381; eta: 1 day, 15:29:45; peak_mem(M): 6296;
INFO 2022-05-23 02:08:34,230 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 37400; lr: 0.01; loss: 21.88772; btime(ms): 1380; eta: 1 day, 15:24:24; peak_mem(M): 6296;
INFO 2022-05-23 02:12:50,585 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 37600; lr: 0.01; loss: 22.91088; btime(ms): 1380; eta: 1 day, 15:19:03; peak_mem(M): 6296;
INFO 2022-05-23 02:17:07,556 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 37800; lr: 0.01; loss: 22.23885; btime(ms): 1379; eta: 1 day, 15:13:40; peak_mem(M): 6296;
INFO 2022-05-23 02:21:29,830 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 38000; lr: 0.01; loss: 21.83064; btime(ms): 1379; eta: 1 day, 15:08:24; peak_mem(M): 6296;
INFO 2022-05-23 02:25:51,766 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 38200; lr: 0.01; loss: 22.7702; btime(ms): 1379; eta: 1 day, 15:03:07; peak_mem(M): 6296;
INFO 2022-05-23 02:30:10,143 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 38400; lr: 0.01; loss: 23.66009; btime(ms): 1378; eta: 1 day, 14:57:48; peak_mem(M): 6296;
INFO 2022-05-23 02:34:27,660 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 38600; lr: 0.01; loss: 22.72116; btime(ms): 1378; eta: 1 day, 14:52:24; peak_mem(M): 6296;
INFO 2022-05-23 02:38:44,861 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 38800; lr: 0.01; loss: 21.75222; btime(ms): 1377; eta: 1 day, 14:47:01; peak_mem(M): 6296;
INFO 2022-05-23 02:43:02,454 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 39000; lr: 0.01; loss: 24.28573; btime(ms): 1377; eta: 1 day, 14:41:41; peak_mem(M): 6296;
INFO 2022-05-23 02:47:19,577 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 39200; lr: 0.01; loss: 21.83031; btime(ms): 1376; eta: 1 day, 14:36:26; peak_mem(M): 6296;
INFO 2022-05-23 02:51:39,167 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 39400; lr: 0.01; loss: 23.29944; btime(ms): 1376; eta: 1 day, 14:31:15; peak_mem(M): 6296;
INFO 2022-05-23 02:55:59,674 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 39600; lr: 0.01; loss: 22.51963; btime(ms): 1376; eta: 1 day, 14:26:04; peak_mem(M): 6296;
INFO 2022-05-23 03:00:30,374 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 39800; lr: 0.01; loss: 23.73058; btime(ms): 1376; eta: 1 day, 14:21:17; peak_mem(M): 6296;
INFO 2022-05-23 03:05:19,622 log_hooks.py: 277: Rank: 0; [ep: 7] iter: 40000; lr: 0.01; loss: 22.30891; btime(ms): 1376; eta: 1 day, 14:17:16; peak_mem(M): 6296;
INFO 2022-05-23 03:06:12,050 trainer_main.py: 214: Meters synced
INFO 2022-05-23 03:06:12,053 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1322
INFO 2022-05-23 03:06:12,054 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  961.41 ms  959.51 ms
             forward:   10.68 ms  214.56 ms
        loss_compute:    1.13 ms    1.12 ms
     loss_all_reduce:    0.09 ms    0.10 ms
       meters_update:  133.98 ms  134.10 ms
            backward:    3.39 ms    5.99 ms
      optimizer_step:    1.41 ms    3.69 ms
    train_step_total: 1321.93 ms 1322.11 ms
INFO 2022-05-23 03:06:12,055 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 5.2163, 'res2': 15.1712, 'res3': 23.1967, 'res4': 32.0897, 'res5': 28.8489}, 'top_5': {'conv1': 13.417499999999999, 'res2': 30.5041, 'res3': 41.8376, 'res4': 53.081500000000005, 'res5': 49.8375}}
INFO 2022-05-23 03:06:12,056 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 03:06:12,062 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 03:06:12,062 log_hooks.py: 425: [phase: 7] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 03:06:13,135 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase7.torch
INFO 2022-05-23 03:06:13,136 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 03:06:13,138 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 03:06:13,139 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 15, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 03:06:54,993 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 03:06:54,994 state_update_hooks.py: 115: Starting phase 15 [test]
INFO 2022-05-23 03:12:13,770 trainer_main.py: 214: Meters synced
INFO 2022-05-23 03:12:13,778 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1626
INFO 2022-05-23 03:12:13,779 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 7.340000000000001, 'res2': 19.317999999999998, 'res3': 28.32, 'res4': 36.95, 'res5': 31.879999999999995}, 'top_5': {'conv1': 17.64, 'res2': 37.116, 'res3': 49.193999999999996, 'res4': 59.888, 'res5': 54.166000000000004}}
INFO 2022-05-23 03:12:13,779 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 03:12:13,783 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 03:12:13,783 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 16, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 03:12:57,652 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 03:12:57,653 state_update_hooks.py: 115: Starting phase 16 [train]
INFO 2022-05-23 03:16:50,366 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 40200; lr: 0.001; loss: 23.68209; btime(ms): 1379; eta: 1 day, 14:18:22; peak_mem(M): 6296;
INFO 2022-05-23 03:21:43,612 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 40400; lr: 0.001; loss: 21.9055; btime(ms): 1380; eta: 1 day, 14:14:25; peak_mem(M): 6296;
INFO 2022-05-23 03:26:34,514 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 40600; lr: 0.001; loss: 21.99977; btime(ms): 1380; eta: 1 day, 14:10:23; peak_mem(M): 6296;
INFO 2022-05-23 03:31:08,565 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 40800; lr: 0.001; loss: 21.06353; btime(ms): 1380; eta: 1 day, 14:05:50; peak_mem(M): 6296;
INFO 2022-05-23 03:35:21,572 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 41000; lr: 0.001; loss: 21.28959; btime(ms): 1380; eta: 1 day, 14:00:22; peak_mem(M): 6296;
INFO 2022-05-23 03:39:33,359 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 41200; lr: 0.001; loss: 22.22287; btime(ms): 1379; eta: 1 day, 13:54:50; peak_mem(M): 6296;
INFO 2022-05-23 03:43:42,292 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 41400; lr: 0.001; loss: 21.35315; btime(ms): 1378; eta: 1 day, 13:49:12; peak_mem(M): 6296;
INFO 2022-05-23 03:47:50,318 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 41600; lr: 0.001; loss: 21.03922; btime(ms): 1378; eta: 1 day, 13:43:33; peak_mem(M): 6296;
INFO 2022-05-23 03:52:00,551 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 41800; lr: 0.001; loss: 21.27845; btime(ms): 1377; eta: 1 day, 13:38:00; peak_mem(M): 6296;
INFO 2022-05-23 03:56:09,828 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 42000; lr: 0.001; loss: 21.45237; btime(ms): 1377; eta: 1 day, 13:32:25; peak_mem(M): 6296;
INFO 2022-05-23 04:00:19,330 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 42200; lr: 0.001; loss: 19.77593; btime(ms): 1376; eta: 1 day, 13:26:52; peak_mem(M): 6296;
INFO 2022-05-23 04:04:26,602 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 42400; lr: 0.001; loss: 20.33906; btime(ms): 1375; eta: 1 day, 13:21:14; peak_mem(M): 6296;
INFO 2022-05-23 04:08:36,953 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 42600; lr: 0.001; loss: 21.95432; btime(ms): 1375; eta: 1 day, 13:15:44; peak_mem(M): 6296;
INFO 2022-05-23 04:12:46,644 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 42800; lr: 0.001; loss: 21.19782; btime(ms): 1374; eta: 1 day, 13:10:13; peak_mem(M): 6296;
INFO 2022-05-23 04:16:53,312 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 43000; lr: 0.001; loss: 21.86152; btime(ms): 1374; eta: 1 day, 13:04:37; peak_mem(M): 6296;
INFO 2022-05-23 04:21:05,260 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 43200; lr: 0.001; loss: 20.70521; btime(ms): 1373; eta: 1 day, 12:59:13; peak_mem(M): 6296;
INFO 2022-05-23 04:25:16,872 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 43400; lr: 0.001; loss: 22.42956; btime(ms): 1373; eta: 1 day, 12:53:48; peak_mem(M): 6296;
INFO 2022-05-23 04:29:29,444 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 43600; lr: 0.001; loss: 21.29859; btime(ms): 1372; eta: 1 day, 12:48:26; peak_mem(M): 6296;
INFO 2022-05-23 04:33:45,787 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 43800; lr: 0.001; loss: 20.57568; btime(ms): 1372; eta: 1 day, 12:43:06; peak_mem(M): 6296;
INFO 2022-05-23 04:37:55,865 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 44000; lr: 0.001; loss: 21.02907; btime(ms): 1371; eta: 1 day, 12:37:41; peak_mem(M): 6296;
INFO 2022-05-23 04:42:16,991 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 44200; lr: 0.001; loss: 20.15916; btime(ms): 1371; eta: 1 day, 12:32:37; peak_mem(M): 6296;
INFO 2022-05-23 04:46:37,823 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 44400; lr: 0.001; loss: 22.03664; btime(ms): 1370; eta: 1 day, 12:27:35; peak_mem(M): 6296;
INFO 2022-05-23 04:50:58,768 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 44600; lr: 0.001; loss: 22.11211; btime(ms): 1370; eta: 1 day, 12:22:32; peak_mem(M): 6296;
INFO 2022-05-23 04:55:51,022 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 44800; lr: 0.001; loss: 20.90148; btime(ms): 1371; eta: 1 day, 12:18:36; peak_mem(M): 6296;
INFO 2022-05-23 05:00:48,843 log_hooks.py: 277: Rank: 0; [ep: 8] iter: 45000; lr: 0.001; loss: 21.72565; btime(ms): 1371; eta: 1 day, 12:14:50; peak_mem(M): 6296;
INFO 2022-05-23 05:01:47,684 trainer_main.py: 214: Meters synced
INFO 2022-05-23 05:01:47,687 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1304
INFO 2022-05-23 05:01:47,688 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  945.47 ms  943.61 ms
             forward:   10.67 ms  214.57 ms
        loss_compute:    1.13 ms    1.12 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  132.22 ms  132.36 ms
            backward:    3.37 ms    6.00 ms
      optimizer_step:    1.41 ms    3.71 ms
    train_step_total: 1304.51 ms 1304.70 ms
INFO 2022-05-23 05:01:47,689 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.1776, 'res2': 17.6089, 'res3': 26.5971, 'res4': 35.9844, 'res5': 32.8237}, 'top_5': {'conv1': 15.287500000000001, 'res2': 33.6981, 'res3': 45.6885, 'res4': 56.868399999999994, 'res5': 53.9683}}
INFO 2022-05-23 05:01:47,690 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 05:01:47,696 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 05:01:47,697 log_hooks.py: 425: [phase: 8] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 05:01:48,777 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase8.torch
INFO 2022-05-23 05:01:48,778 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 05:01:48,781 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 05:01:48,783 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 17, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 05:02:34,268 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 05:02:34,268 state_update_hooks.py: 115: Starting phase 17 [test]
INFO 2022-05-23 05:07:59,666 trainer_main.py: 214: Meters synced
INFO 2022-05-23 05:07:59,672 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1660
INFO 2022-05-23 05:07:59,674 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 8.844000000000001, 'res2': 22.618, 'res3': 32.018, 'res4': 40.727999999999994, 'res5': 35.426}, 'top_5': {'conv1': 20.158, 'res2': 40.808, 'res3': 53.236000000000004, 'res4': 63.22, 'res5': 57.858}}
INFO 2022-05-23 05:07:59,674 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 05:07:59,677 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 05:07:59,677 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 18, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 05:08:44,460 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 05:08:44,461 state_update_hooks.py: 115: Starting phase 18 [train]
INFO 2022-05-23 05:12:33,620 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 45200; lr: 0.001; loss: 20.89886; btime(ms): 1375; eta: 1 day, 12:15:43; peak_mem(M): 6296;
INFO 2022-05-23 05:17:14,398 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 45400; lr: 0.001; loss: 21.50185; btime(ms): 1375; eta: 1 day, 12:11:20; peak_mem(M): 6296;
INFO 2022-05-23 05:21:49,773 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 45600; lr: 0.001; loss: 20.42328; btime(ms): 1375; eta: 1 day, 12:06:45; peak_mem(M): 6296;
INFO 2022-05-23 05:26:18,982 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 45800; lr: 0.001; loss: 20.47328; btime(ms): 1375; eta: 1 day, 12:01:58; peak_mem(M): 6296;
INFO 2022-05-23 05:30:49,022 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 46000; lr: 0.001; loss: 21.28203; btime(ms): 1374; eta: 1 day, 11:57:14; peak_mem(M): 6296;
INFO 2022-05-23 05:35:13,491 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 46200; lr: 0.001; loss: 20.47947; btime(ms): 1374; eta: 1 day, 11:52:19; peak_mem(M): 6296;
INFO 2022-05-23 05:39:33,764 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 46400; lr: 0.001; loss: 20.21553; btime(ms): 1374; eta: 1 day, 11:47:14; peak_mem(M): 6296;
INFO 2022-05-23 05:43:52,704 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 46600; lr: 0.001; loss: 20.78708; btime(ms): 1374; eta: 1 day, 11:42:13; peak_mem(M): 6296;
INFO 2022-05-23 05:48:15,553 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 46800; lr: 0.001; loss: 21.1961; btime(ms): 1373; eta: 1 day, 11:37:19; peak_mem(M): 6296;
INFO 2022-05-23 05:52:39,918 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 47000; lr: 0.001; loss: 20.69735; btime(ms): 1373; eta: 1 day, 11:32:18; peak_mem(M): 6296;
INFO 2022-05-23 05:57:04,281 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 47200; lr: 0.001; loss: 20.68734; btime(ms): 1373; eta: 1 day, 11:27:23; peak_mem(M): 6296;
INFO 2022-05-23 06:01:27,394 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 47400; lr: 0.001; loss: 21.3012; btime(ms): 1373; eta: 1 day, 11:22:28; peak_mem(M): 6296;
INFO 2022-05-23 06:05:57,606 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 47600; lr: 0.001; loss: 21.26414; btime(ms): 1373; eta: 1 day, 11:17:42; peak_mem(M): 6296;
INFO 2022-05-23 06:10:22,741 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 47800; lr: 0.001; loss: 20.88393; btime(ms): 1372; eta: 1 day, 11:12:51; peak_mem(M): 6296;
INFO 2022-05-23 06:14:44,315 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 48000; lr: 0.001; loss: 20.82469; btime(ms): 1372; eta: 1 day, 11:07:52; peak_mem(M): 6296;
INFO 2022-05-23 06:19:07,792 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 48200; lr: 0.001; loss: 20.80532; btime(ms): 1372; eta: 1 day, 11:02:58; peak_mem(M): 6296;
INFO 2022-05-23 06:23:32,603 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 48400; lr: 0.001; loss: 21.53544; btime(ms): 1372; eta: 1 day, 10:58:06; peak_mem(M): 6296;
INFO 2022-05-23 06:27:56,863 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 48600; lr: 0.001; loss: 21.19718; btime(ms): 1371; eta: 1 day, 10:53:10; peak_mem(M): 6296;
INFO 2022-05-23 06:32:16,929 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 48800; lr: 0.001; loss: 20.77132; btime(ms): 1371; eta: 1 day, 10:48:12; peak_mem(M): 6296;
INFO 2022-05-23 06:36:38,765 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 49000; lr: 0.001; loss: 20.39562; btime(ms): 1371; eta: 1 day, 10:43:15; peak_mem(M): 6296;
INFO 2022-05-23 06:41:00,178 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 49200; lr: 0.001; loss: 21.35701; btime(ms): 1371; eta: 1 day, 10:38:18; peak_mem(M): 6296;
INFO 2022-05-23 06:45:27,533 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 49400; lr: 0.001; loss: 20.79498; btime(ms): 1371; eta: 1 day, 10:33:32; peak_mem(M): 6296;
INFO 2022-05-23 06:50:16,945 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 49600; lr: 0.001; loss: 22.63691; btime(ms): 1371; eta: 1 day, 10:29:24; peak_mem(M): 6296;
INFO 2022-05-23 06:54:54,689 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 49800; lr: 0.001; loss: 20.84493; btime(ms): 1371; eta: 1 day, 10:24:54; peak_mem(M): 6296;
INFO 2022-05-23 06:59:33,941 log_hooks.py: 277: Rank: 0; [ep: 9] iter: 50000; lr: 0.001; loss: 20.4567; btime(ms): 1371; eta: 1 day, 10:20:34; peak_mem(M): 6296;
INFO 2022-05-23 07:00:39,573 trainer_main.py: 214: Meters synced
INFO 2022-05-23 07:00:39,576 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1341
INFO 2022-05-23 07:00:39,578 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  980.22 ms  978.42 ms
             forward:   11.10 ms  214.62 ms
        loss_compute:    1.16 ms    1.15 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  133.91 ms  134.03 ms
            backward:    3.42 ms    6.06 ms
      optimizer_step:    1.44 ms    3.72 ms
    train_step_total: 1341.48 ms 1341.68 ms
INFO 2022-05-23 07:00:39,579 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.5027, 'res2': 18.3731, 'res3': 27.490199999999998, 'res4': 36.971399999999996, 'res5': 33.5937}, 'top_5': {'conv1': 15.917300000000001, 'res2': 34.777, 'res3': 46.7766, 'res4': 57.916999999999994, 'res5': 54.875600000000006}}
INFO 2022-05-23 07:00:39,579 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 07:00:39,585 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 07:00:39,586 log_hooks.py: 425: [phase: 9] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 07:00:40,623 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase9.torch
INFO 2022-05-23 07:00:40,623 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 07:00:40,626 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 07:00:40,627 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 07:01:24,891 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 07:01:24,892 state_update_hooks.py: 115: Starting phase 19 [test]
INFO 2022-05-23 07:06:31,340 trainer_main.py: 214: Meters synced
INFO 2022-05-23 07:06:31,345 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1563
INFO 2022-05-23 07:06:31,346 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.094, 'res2': 23.06, 'res3': 32.403999999999996, 'res4': 41.052, 'res5': 35.666}, 'top_5': {'conv1': 20.626, 'res2': 41.532000000000004, 'res3': 53.71, 'res4': 63.748000000000005, 'res5': 58.228}}
INFO 2022-05-23 07:06:31,347 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 07:06:31,349 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 07:06:31,350 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 20, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 07:07:17,759 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 07:07:17,759 state_update_hooks.py: 115: Starting phase 20 [train]
INFO 2022-05-23 07:10:58,274 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50200; lr: 0.001; loss: 20.76728; btime(ms): 1374; eta: 1 day, 10:20:06; peak_mem(M): 6296;
INFO 2022-05-23 07:15:50,486 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50400; lr: 0.001; loss: 20.14964; btime(ms): 1374; eta: 1 day, 10:16:01; peak_mem(M): 6296;
INFO 2022-05-23 07:20:40,009 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50600; lr: 0.001; loss: 21.99973; btime(ms): 1374; eta: 1 day, 10:11:51; peak_mem(M): 6296;
INFO 2022-05-23 07:25:10,865 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50800; lr: 0.001; loss: 21.88778; btime(ms): 1374; eta: 1 day, 10:07:09; peak_mem(M): 6296;
INFO 2022-05-23 07:29:30,162 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51000; lr: 0.001; loss: 20.93183; btime(ms): 1374; eta: 1 day, 10:02:07; peak_mem(M): 6296;
INFO 2022-05-23 07:33:47,236 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51200; lr: 0.001; loss: 20.36345; btime(ms): 1374; eta: 1 day, 9:57:03; peak_mem(M): 6296;
INFO 2022-05-23 07:38:03,927 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51400; lr: 0.001; loss: 21.8088; btime(ms): 1373; eta: 1 day, 9:51:58; peak_mem(M): 6296;
INFO 2022-05-23 07:42:21,423 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51600; lr: 0.001; loss: 20.20635; btime(ms): 1373; eta: 1 day, 9:46:54; peak_mem(M): 6296;
INFO 2022-05-23 07:46:39,947 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51800; lr: 0.001; loss: 20.91832; btime(ms): 1373; eta: 1 day, 9:41:53; peak_mem(M): 6296;
INFO 2022-05-23 07:50:58,467 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52000; lr: 0.001; loss: 21.82716; btime(ms): 1372; eta: 1 day, 9:36:52; peak_mem(M): 6296;
INFO 2022-05-23 07:55:14,617 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52200; lr: 0.001; loss: 21.00909; btime(ms): 1372; eta: 1 day, 9:31:47; peak_mem(M): 6296;
INFO 2022-05-23 07:59:33,981 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52400; lr: 0.001; loss: 21.3715; btime(ms): 1372; eta: 1 day, 9:26:49; peak_mem(M): 6296;
INFO 2022-05-23 08:03:51,247 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52600; lr: 0.001; loss: 20.74566; btime(ms): 1372; eta: 1 day, 9:21:46; peak_mem(M): 6296;
INFO 2022-05-23 08:08:08,259 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52800; lr: 0.001; loss: 20.81684; btime(ms): 1371; eta: 1 day, 9:16:43; peak_mem(M): 6296;
INFO 2022-05-23 08:12:25,937 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53000; lr: 0.001; loss: 21.35978; btime(ms): 1371; eta: 1 day, 9:11:43; peak_mem(M): 6296;
INFO 2022-05-23 08:16:46,939 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53200; lr: 0.001; loss: 20.88417; btime(ms): 1371; eta: 1 day, 9:06:48; peak_mem(M): 6296;
INFO 2022-05-23 08:21:02,438 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53400; lr: 0.001; loss: 19.26861; btime(ms): 1370; eta: 1 day, 9:01:45; peak_mem(M): 6296;
INFO 2022-05-23 08:25:18,988 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53600; lr: 0.001; loss: 22.31125; btime(ms): 1370; eta: 1 day, 8:56:43; peak_mem(M): 6296;
INFO 2022-05-23 08:29:36,840 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53800; lr: 0.001; loss: 21.60176; btime(ms): 1370; eta: 1 day, 8:51:44; peak_mem(M): 6296;
INFO 2022-05-23 08:33:53,321 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54000; lr: 0.001; loss: 21.82139; btime(ms): 1369; eta: 1 day, 8:46:43; peak_mem(M): 6296;
INFO 2022-05-23 08:38:07,576 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54200; lr: 0.001; loss: 21.73344; btime(ms): 1369; eta: 1 day, 8:41:39; peak_mem(M): 6296;
INFO 2022-05-23 08:42:26,044 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54400; lr: 0.001; loss: 21.45543; btime(ms): 1369; eta: 1 day, 8:36:35; peak_mem(M): 6296;
INFO 2022-05-23 08:46:54,750 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54600; lr: 0.001; loss: 20.99264; btime(ms): 1369; eta: 1 day, 8:31:54; peak_mem(M): 6296;
INFO 2022-05-23 08:51:44,943 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54800; lr: 0.001; loss: 21.39345; btime(ms): 1369; eta: 1 day, 8:27:44; peak_mem(M): 6296;
INFO 2022-05-23 08:57:04,215 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2022-05-23 08:57:04,215 env.py:  50: ARCH:	x86_64
INFO 2022-05-23 08:57:04,216 env.py:  50: BASH_ENV:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/init/bash
INFO 2022-05-23 08:57:04,216 env.py:  50: BASH_FUNC_ml%%:	() {  eval $($LMOD_DIR/ml_cmd "$@")
}
INFO 2022-05-23 08:57:04,216 env.py:  50: BASH_FUNC_module%%:	() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
INFO 2022-05-23 08:57:04,217 env.py:  50: CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64
INFO 2022-05-23 08:57:04,217 env.py:  50: CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0
INFO 2022-05-23 08:57:04,217 env.py:  50: COLUMNS:	202
INFO 2022-05-23 08:57:04,217 env.py:  50: CONDA_ACTIVATE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/etc/profile.d/conda.sh
INFO 2022-05-23 08:57:04,218 env.py:  50: CONDA_DEFAULT_ENV:	vissl_env
INFO 2022-05-23 08:57:04,218 env.py:  50: CONDA_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/conda
INFO 2022-05-23 08:57:04,218 env.py:  50: CONDA_PREFIX:	/home/mila/r/rajkuman/.conda/envs/vissl_env
INFO 2022-05-23 08:57:04,219 env.py:  50: CONDA_PROMPT_MODIFIER:	(vissl_env) 
INFO 2022-05-23 08:57:04,219 env.py:  50: CONDA_PYTHON_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/python
INFO 2022-05-23 08:57:04,219 env.py:  50: CONDA_SHLVL:	1
INFO 2022-05-23 08:57:04,219 env.py:  50: CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include
INFO 2022-05-23 08:57:04,220 env.py:  50: CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3
INFO 2022-05-23 08:57:04,220 env.py:  50: CUDA_VISIBLE_DEVICES:	0
INFO 2022-05-23 08:57:04,220 env.py:  50: ENVIRONMENT:	BATCH
INFO 2022-05-23 08:57:04,220 env.py:  50: GPU_DEVICE_ORDINAL:	0
INFO 2022-05-23 08:57:04,221 env.py:  50: HOME:	/home/mila/r/rajkuman
INFO 2022-05-23 08:57:04,221 env.py:  50: HOSTNAME:	cn-b003
INFO 2022-05-23 08:57:04,221 env.py:  50: ID:	debian
INFO 2022-05-23 08:57:04,222 env.py:  50: JPY_API_TOKEN:	5ea8391a236a48d1a91878c22ca50441
INFO 2022-05-23 08:57:04,222 env.py:  50: JUPYTERHUB_ACTIVITY_URL:	http://172.16.2.123:8081/hub/api/users/rajkuman/activity
INFO 2022-05-23 08:57:04,222 env.py:  50: JUPYTERHUB_API_TOKEN:	5ea8391a236a48d1a91878c22ca50441
INFO 2022-05-23 08:57:04,222 env.py:  50: JUPYTERHUB_API_URL:	http://172.16.2.123:8081/hub/api
INFO 2022-05-23 08:57:04,223 env.py:  50: JUPYTERHUB_BASE_URL:	/
INFO 2022-05-23 08:57:04,223 env.py:  50: JUPYTERHUB_CLIENT_ID:	jupyterhub-user-rajkuman
INFO 2022-05-23 08:57:04,223 env.py:  50: JUPYTERHUB_HOST:	
INFO 2022-05-23 08:57:04,223 env.py:  50: JUPYTERHUB_OAUTH_CALLBACK_URL:	/user/rajkuman/oauth_callback
INFO 2022-05-23 08:57:04,224 env.py:  50: JUPYTERHUB_SERVER_NAME:	
INFO 2022-05-23 08:57:04,224 env.py:  50: JUPYTERHUB_SERVICE_PREFIX:	/user/rajkuman/
INFO 2022-05-23 08:57:04,224 env.py:  50: JUPYTERHUB_USER:	rajkuman
INFO 2022-05-23 08:57:04,225 env.py:  50: JUPYTER_SERVER_ROOT:	/home/mila/r/rajkuman
INFO 2022-05-23 08:57:04,225 env.py:  50: JUPYTER_SERVER_URL:	http://0.0.0.0:39135/user/rajkuman/
INFO 2022-05-23 08:57:04,225 env.py:  50: KERNEL_LAUNCH_TIMEOUT:	40
INFO 2022-05-23 08:57:04,225 env.py:  50: LANG:	en_US.UTF-8
INFO 2022-05-23 08:57:04,226 env.py:  50: LESSCLOSE:	/bin/lesspipe %s %s
INFO 2022-05-23 08:57:04,226 env.py:  50: LESSOPEN:	| /bin/lesspipe %s
INFO 2022-05-23 08:57:04,226 env.py:  50: LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib
INFO 2022-05-23 08:57:04,227 env.py:  50: LINES:	50
INFO 2022-05-23 08:57:04,227 env.py:  50: LMOD_CMD:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec/lmod
INFO 2022-05-23 08:57:04,227 env.py:  50: LMOD_DIR:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec
INFO 2022-05-23 08:57:04,227 env.py:  50: LMOD_PACKAGE_PATH:	/cvmfs/config.mila.quebec/etc/lmod/
INFO 2022-05-23 08:57:04,228 env.py:  50: LMOD_PKG:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-23 08:57:04,228 env.py:  50: LMOD_ROOT:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod
INFO 2022-05-23 08:57:04,228 env.py:  50: LMOD_SETTARG_FULL_SUPPORT:	no
INFO 2022-05-23 08:57:04,228 env.py:  50: LMOD_SYSTEM_DEFAULT_MODULES:	Mila:gcc/7.4.0
INFO 2022-05-23 08:57:04,229 env.py:  50: LMOD_VERSION:	8.3.17
INFO 2022-05-23 08:57:04,229 env.py:  50: LMOD_sys:	Linux
INFO 2022-05-23 08:57:04,229 env.py:  50: LOADEDMODULES:	Mila:gcc/7.4.0:anaconda/3
INFO 2022-05-23 08:57:04,230 env.py:  50: LOCAL_RANK:	0
INFO 2022-05-23 08:57:04,230 env.py:  50: LOGNAME:	rajkuman
INFO 2022-05-23 08:57:04,230 env.py:  50: LS_COLORS:	rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
INFO 2022-05-23 08:57:04,230 env.py:  50: MAIL:	/var/mail/rajkuman
INFO 2022-05-23 08:57:04,231 env.py:  50: MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man::
INFO 2022-05-23 08:57:04,231 env.py:  50: MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:/cvmfs/config.mila.quebec/modules/Compiler:/cvmfs/config.mila.quebec/modules/Environments:/cvmfs/config.mila.quebec/modules/Cuda:/cvmfs/config.mila.quebec/modules/Pytorch:/cvmfs/config.mila.quebec/modules/Tensorflow
INFO 2022-05-23 08:57:04,231 env.py:  50: MODULEPATH_ROOT:	/cvmfs/config.mila.quebec/modules
INFO 2022-05-23 08:57:04,232 env.py:  50: MODULERCFILE:	/cvmfs/config.mila.quebec/etc/lmod/modulerc.lua
INFO 2022-05-23 08:57:04,232 env.py:  50: MODULESHOME:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-23 08:57:04,232 env.py:  50: OLDPWD:	/home/mila/r/rajkuman
INFO 2022-05-23 08:57:04,232 env.py:  50: PATH:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin:/home/mila/r/rajkuman/.local/bin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/condabin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:/opt/slurm/bin:/sbin:/bin:/usr/sbin:/usr/bin
INFO 2022-05-23 08:57:04,233 env.py:  50: PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig
INFO 2022-05-23 08:57:04,233 env.py:  50: PROCESSOR_ARCHITECTURE:	amd64
INFO 2022-05-23 08:57:04,233 env.py:  50: PWD:	/home/mila/r/rajkuman/mina/mphil-vissl
INFO 2022-05-23 08:57:04,234 env.py:  50: PYTHONNOUSERSITE:	True
INFO 2022-05-23 08:57:04,234 env.py:  50: PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7
INFO 2022-05-23 08:57:04,234 env.py:  50: PYXTERM_DIMENSIONS:	80x25
INFO 2022-05-23 08:57:04,234 env.py:  50: RANK:	0
INFO 2022-05-23 08:57:04,235 env.py:  50: ROCR_VISIBLE_DEVICES:	0
INFO 2022-05-23 08:57:04,235 env.py:  50: SACCT_FORMAT:	User,JobID,Jobname,partition,state,time,start,end,elapsed,nnodes,ncpus,reqmem,alloctres,nodelist,workdir
INFO 2022-05-23 08:57:04,235 env.py:  50: SCRATCH:	/network/scratch/r/rajkuman
INFO 2022-05-23 08:57:04,235 env.py:  50: SHELL:	/bin/bash
INFO 2022-05-23 08:57:04,236 env.py:  50: SHLVL:	3
INFO 2022-05-23 08:57:04,236 env.py:  50: SINFO_FORMAT:	%18N %.6D %.11T %.4c %.8z %.6m %.8d %.6w %.22f %80E
INFO 2022-05-23 08:57:04,236 env.py:  50: SLURMD_NODENAME:	cn-b003
INFO 2022-05-23 08:57:04,237 env.py:  50: SLURM_CLUSTER_NAME:	mila
INFO 2022-05-23 08:57:04,237 env.py:  50: SLURM_CONF:	/etc/slurm/slurm.conf
INFO 2022-05-23 08:57:04,237 env.py:  50: SLURM_CPUS_ON_NODE:	4
INFO 2022-05-23 08:57:04,238 env.py:  50: SLURM_CPUS_PER_TASK:	4
INFO 2022-05-23 08:57:04,238 env.py:  50: SLURM_EXPORT_ENV:	PATH,LANG,USER,HOME,SHELL,JUPYTERHUB_API_TOKEN,JPY_API_TOKEN,JUPYTERHUB_CLIENT_ID,JUPYTERHUB_HOST,JUPYTERHUB_OAUTH_CALLBACK_URL,JUPYTERHUB_USER,JUPYTERHUB_SERVER_NAME,JUPYTERHUB_API_URL,JUPYTERHUB_ACTIVITY_URL,JUPYTERHUB_BASE_URL,JUPYTERHUB_SERVICE_PREFIX
INFO 2022-05-23 08:57:04,238 env.py:  50: SLURM_GET_USER_ENV:	1
INFO 2022-05-23 08:57:04,238 env.py:  50: SLURM_GTIDS:	0
INFO 2022-05-23 08:57:04,239 env.py:  50: SLURM_JOBID:	1849201
INFO 2022-05-23 08:57:04,239 env.py:  50: SLURM_JOB_ACCOUNT:	mila
INFO 2022-05-23 08:57:04,239 env.py:  50: SLURM_JOB_CPUS_PER_NODE:	4
INFO 2022-05-23 08:57:04,240 env.py:  50: SLURM_JOB_GID:	1471600619
INFO 2022-05-23 08:57:04,240 env.py:  50: SLURM_JOB_GPUS:	2
INFO 2022-05-23 08:57:04,240 env.py:  50: SLURM_JOB_ID:	1849201
INFO 2022-05-23 08:57:04,240 env.py:  50: SLURM_JOB_NAME:	jupyterhub-rajkuman
INFO 2022-05-23 08:57:04,241 env.py:  50: SLURM_JOB_NODELIST:	cn-b003
INFO 2022-05-23 08:57:04,241 env.py:  50: SLURM_JOB_NUM_NODES:	1
INFO 2022-05-23 08:57:04,241 env.py:  50: SLURM_JOB_PARTITION:	unkillable
INFO 2022-05-23 08:57:04,242 env.py:  50: SLURM_JOB_QOS:	normal
INFO 2022-05-23 08:57:04,242 env.py:  50: SLURM_JOB_UID:	1471600619
INFO 2022-05-23 08:57:04,242 env.py:  50: SLURM_JOB_USER:	rajkuman
INFO 2022-05-23 08:57:04,242 env.py:  50: SLURM_LOCALID:	0
INFO 2022-05-23 08:57:04,243 env.py:  50: SLURM_MEM_PER_NODE:	24000
INFO 2022-05-23 08:57:04,243 env.py:  50: SLURM_NNODES:	1
INFO 2022-05-23 08:57:04,243 env.py:  50: SLURM_NODEID:	0
INFO 2022-05-23 08:57:04,243 env.py:  50: SLURM_NODELIST:	cn-b003
INFO 2022-05-23 08:57:04,244 env.py:  50: SLURM_NODE_ALIASES:	(null)
INFO 2022-05-23 08:57:04,244 env.py:  50: SLURM_NPROCS:	1
INFO 2022-05-23 08:57:04,244 env.py:  50: SLURM_NTASKS:	1
INFO 2022-05-23 08:57:04,245 env.py:  50: SLURM_PRIO_PROCESS:	0
INFO 2022-05-23 08:57:04,245 env.py:  50: SLURM_PROCID:	0
INFO 2022-05-23 08:57:04,245 env.py:  50: SLURM_SUBMIT_DIR:	/var/lib/jupyterhub
INFO 2022-05-23 08:57:04,246 env.py:  50: SLURM_SUBMIT_HOST:	jupyter
INFO 2022-05-23 08:57:04,246 env.py:  50: SLURM_TASKS_PER_NODE:	1
INFO 2022-05-23 08:57:04,246 env.py:  50: SLURM_TASK_PID:	48198
INFO 2022-05-23 08:57:04,247 env.py:  50: SLURM_TMPDIR:	/Tmp/slurm.1849201.0
INFO 2022-05-23 08:57:04,247 env.py:  50: SLURM_TOPOLOGY_ADDR:	cn-b003
INFO 2022-05-23 08:57:04,247 env.py:  50: SLURM_TOPOLOGY_ADDR_PATTERN:	node
INFO 2022-05-23 08:57:04,247 env.py:  50: SLURM_WORKING_CLUSTER:	mila:slurm:6817:9216:109
INFO 2022-05-23 08:57:04,248 env.py:  50: SQUEUE_FORMAT:	%.8i %.8u %.12P %.14j %.3t %16S %.10M %.5D %.4C %.10b %.7m %N (%r) %k
INFO 2022-05-23 08:57:04,248 env.py:  50: S_COLORS:	auto
INFO 2022-05-23 08:57:04,248 env.py:  50: TERM:	xterm
INFO 2022-05-23 08:57:04,249 env.py:  50: TMPDIR:	/tmp
INFO 2022-05-23 08:57:04,249 env.py:  50: USER:	rajkuman
INFO 2022-05-23 08:57:04,249 env.py:  50: WORLD_SIZE:	1
INFO 2022-05-23 08:57:04,250 env.py:  50: XDG_SESSION_ID:	c776
INFO 2022-05-23 08:57:04,250 env.py:  50: _:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin/python
INFO 2022-05-23 08:57:04,250 env.py:  50: _CE_CONDA:	
INFO 2022-05-23 08:57:04,251 env.py:  50: _CE_M:	
INFO 2022-05-23 08:57:04,251 env.py:  50: _LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua
INFO 2022-05-23 08:57:04,251 env.py:  50: _ModuleTable001_:	X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtNaWxhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL01pbGEubHVhIixbImZ1bGxOYW1lIl09Ik1pbGEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17bG1vZD17WyJzdGlja3kiXT0xLH0sfSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJNaWxhIix9LGFuYWNvbmRhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL2FuYWNvbmRhLzMubHVhIixbImZ1bGxOYW1lIl09ImFuYWNvbmRh
INFO 2022-05-23 08:57:04,252 env.py:  50: _ModuleTable002_:	LzMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJhbmFjb25kYS8zIix9LGdjYz17WyJmbiJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZS9nY2MvNy40LjAubHVhIixbImZ1bGxOYW1lIl09ImdjYy83LjQuMCIsWyJsb2FkT3JkZXIiXT0yLHByb3BUPXtsbW9kPXtbInN0aWNreSJdPTEsfSx9LFsic3RhY2tEZXB0aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09ImdjYy83LjQuMCIsfSx9LG1wYXRoQT17Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Nv
INFO 2022-05-23 08:57:04,252 env.py:  50: _ModuleTable003_:	bXBpbGVyIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50cyIsIi9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9DdWRhIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL1B5dG9yY2giLCIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZTovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29tcGlsZXI6L2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50czovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ3VkYTovY3Zt
INFO 2022-05-23 08:57:04,252 env.py:  50: _ModuleTable004_:	ZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvUHl0b3JjaDovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfQ==
INFO 2022-05-23 08:57:04,252 env.py:  50: _ModuleTable_Sz_:	4
INFO 2022-05-23 08:57:04,253 env.py:  50: __Init_Default_Modules:	1
INFO 2022-05-23 08:57:04,253 env.py:  50: __LMOD_REF_COUNT_CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1
INFO 2022-05-23 08:57:04,253 env.py:  50: __LMOD_REF_COUNT_CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0:1
INFO 2022-05-23 08:57:04,254 env.py:  50: __LMOD_REF_COUNT_CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include:1
INFO 2022-05-23 08:57:04,254 env.py:  50: __LMOD_REF_COUNT_CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3:1
INFO 2022-05-23 08:57:04,254 env.py:  50: __LMOD_REF_COUNT_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib:1
INFO 2022-05-23 08:57:04,254 env.py:  50: __LMOD_REF_COUNT_LOADEDMODULES:	Mila:1;gcc/7.4.0:1;anaconda/3:1
INFO 2022-05-23 08:57:04,255 env.py:  50: __LMOD_REF_COUNT_MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man:1
INFO 2022-05-23 08:57:04,255 env.py:  50: __LMOD_REF_COUNT_MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:1;/cvmfs/config.mila.quebec/modules/Compiler:1;/cvmfs/config.mila.quebec/modules/Environments:1;/cvmfs/config.mila.quebec/modules/Cuda:1;/cvmfs/config.mila.quebec/modules/Pytorch:1;/cvmfs/config.mila.quebec/modules/Tensorflow:1
INFO 2022-05-23 08:57:04,255 env.py:  50: __LMOD_REF_COUNT_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:1;/opt/slurm/bin:1;/sbin:1;/bin:1;/usr/sbin:1;/usr/bin:1
INFO 2022-05-23 08:57:04,256 env.py:  50: __LMOD_REF_COUNT_PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig:1
INFO 2022-05-23 08:57:04,256 env.py:  50: __LMOD_REF_COUNT_PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7:1
INFO 2022-05-23 08:57:04,256 env.py:  50: __LMOD_REF_COUNT__LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:1;/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:1;/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua:1
INFO 2022-05-23 08:57:04,257 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-23 08:57:04,257 train.py: 105: Setting seed....
INFO 2022-05-23 08:57:04,257 misc.py: 173: MACHINE SEED: 28
INFO 2022-05-23 08:57:04,274 hydra_config.py: 132: Training with config:
INFO 2022-05-23 08:57:04,285 hydra_config.py: 141: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints/after_poison/imagenet',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 4,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['imagenet1k_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 256,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['imagenet1k_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'CHECK_NAN': True,
           'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 200,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': ['conv1',
                                                    'res2',
                                                    'res3',
                                                    'res4',
                                                    'res5'],
                                    'num_meters': 5,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'model_output_mask': False,
            'name': 'accuracy_list_meter',
            'names': ['accuracy_list_meter'],
            'precision_at_k_list_meter': {'meter_names': [],
                                          'num_meters': 1,
                                          'topk_values': [1]},
            'recall_at_k_list_meter': {'meter_names': [],
                                       'num_meters': 1,
                                       'topk_values': [1]}},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'BASE_MODEL_NAME': 'multi_input_output_model',
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',
                                                                        ['AvgPool2d',
                                                                         [[10,
                                                                           10],
                                                                          10,
                                                                          4]]],
                                                                       ['res2',
                                                                        ['AvgPool2d',
                                                                         [[16,
                                                                           16],
                                                                          8,
                                                                          0]]],
                                                                       ['res3',
                                                                        ['AvgPool2d',
                                                                         [[13,
                                                                           13],
                                                                          5,
                                                                          0]]],
                                                                       ['res4',
                                                                        ['AvgPool2d',
                                                                         [[8,
                                                                           8],
                                                                          3,
                                                                          0]]],
                                                                       ['res5',
                                                                        ['AvgPool2d',
                                                                         [[6,
                                                                           6],
                                                                          1,
                                                                          0]]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 64}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 256}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 512}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 1024}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 2048}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': 8,
                              'SYNC_BN_TYPE': 'apex'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'BLOCK': 'Bottleneck',
                                 'CONV1_KERNEL': 7,
                                 'CONV1_PADDING': 3,
                                 'CONV1_STRIDE': 2,
                                 'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'MAXPOOL': True,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': './checkpoints/poisoned/model_final_checkpoint_phase99.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0005},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 28,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.01,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [8, 16, 24],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.01,
                                                      0.001,
                                                      0.0001,
                                                      1e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.01,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [8, 16, 24],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.01,
                                                           0.001,
                                                           0.0001,
                                                           1e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0005},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2022-05-23 08:57:06,622 train.py: 117: System config:
-------------------  ---------------------------------------------------------------------------------------------------------------
sys.platform         linux
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                1.19.5
Pillow               9.0.1
vissl                0.1.6 @/home/mila/r/rajkuman/mina/mphil-vissl/vissl
GPU available        True
GPU 0                Tesla V100-SXM2-32GB
CUDA_HOME            /usr/local/cuda
torchvision          0.9.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torchvision
hydra                1.0.7 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/hydra_core-1.0.7-py3.8.egg/hydra
classy_vision        0.7.0.dev @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/classy_vision
tensorboard          2.9.0
apex                 0.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/apex
PyTorch              1.8.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ----------------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               80
On-line CPU(s) list  0-79
Thread(s) per core   2
Core(s) per socket   20
Socket(s)            2
NUMA node(s)         2
Vendor ID            GenuineIntel
CPU family           6
Model                85
Model name           Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz
Stepping             7
CPU MHz              3329.980
CPU max MHz          3900.0000
CPU min MHz          800.0000
BogoMIPS             4200.00
Virtualization       VT-x
L1d cache            32K
L1i cache            32K
L2 cache             1024K
L3 cache             28160K
NUMA node0 CPU(s)    0-19,40-59
NUMA node1 CPU(s)    20-39,60-79
-------------------  ----------------------------------------
INFO 2022-05-23 08:57:06,625 trainer_main.py: 112: Using Distributed init method: tcp://localhost:44371, world_size: 1, rank: 0
INFO 2022-05-23 08:57:06,632 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2022-05-23 08:57:06,633 trainer_main.py: 130: | initialized host cn-b003 as rank 0 (0)
INFO 2022-05-23 08:57:16,532 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2022-05-23 08:57:16,534 train_task.py: 455: Building model....
INFO 2022-05-23 08:57:16,534 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2022-05-23 08:57:16,535 resnext.py:  66: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2022-05-23 08:57:16,535 resnext.py:  93: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2022-05-23 08:57:17,112 feature_extractor.py:  50: Freezing model trunk...
INFO 2022-05-23 08:57:17,483 model_helpers.py: 178: Using SyncBN group size: 1
INFO 2022-05-23 08:57:17,484 model_helpers.py: 182: Converting BN layers to Apex SyncBN
INFO 2022-05-23 08:57:17,485 distributed_c10d.py: 187: Added key: store_based_barrier_key:2 to store for rank: 0
INFO 2022-05-23 08:57:17,493 train_task.py: 472: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2022-05-23 08:57:17,494 base_ssl_model.py: 195: Freezing model trunk...
INFO 2022-05-23 08:57:17,495 train_task.py: 656: Broadcast model BN buffers from primary on every forward pass
INFO 2022-05-23 08:57:17,495 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2022-05-23 08:57:17,589 optimizer_helper.py: 293: 
Trainable params: 20, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 0, 
Trunk Unregularized Parameters 0, 
Head Regularized Parameters: 10, 
Head Unregularized Parameters: 10 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2022-05-23 08:57:17,591 util.py: 276: Attempting to load checkpoint from ./checkpoints/after_poison/imagenet/model_phase9.torch
INFO 2022-05-23 08:57:18,547 util.py: 281: Loaded checkpoint from ./checkpoints/after_poison/imagenet/model_phase9.torch
INFO 2022-05-23 08:57:18,548 util.py: 240: Broadcasting checkpoint loaded from ./checkpoints/after_poison/imagenet/model_phase9.torch
INFO 2022-05-23 08:57:31,600 ssl_dataset.py: 156: Rank: 0 split: TEST Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-23 08:57:31,600 ssl_dataset.py: 159: Rank: 0 split: TEST Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-23 08:57:32,514 disk_dataset.py:  86: Loaded 50000 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/val
INFO 2022-05-23 08:57:32,515 ssl_dataset.py: 156: Rank: 0 split: TRAIN Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-23 08:57:32,515 ssl_dataset.py: 159: Rank: 0 split: TRAIN Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-23 08:57:42,809 disk_dataset.py:  86: Loaded 1281167 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/train
INFO 2022-05-23 08:57:42,810 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-23 08:57:42,810 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-23 08:57:42,810 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 08:57:42,811 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-23 08:57:42,812 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-23 08:57:42,813 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-23 08:57:42,813 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 08:57:42,814 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-23 08:57:42,815 train_task.py: 384: Building loss...
INFO 2022-05-23 08:57:42,817 train_task.py: 759: ======Loaded loss state from checkpoint======
INFO 2022-05-23 08:57:42,818 train_task.py: 576: =======Updating classy state_dict from checkpoint=======
INFO 2022-05-23 08:57:42,818 base_ssl_model.py: 446: Rank 0: Loading Trunk state dict....
INFO 2022-05-23 08:57:42,883 base_ssl_model.py: 459: Rank 0: Loading Heads state dict....
INFO 2022-05-23 08:57:42,959 base_ssl_model.py: 474: Rank 0: Model state dict loaded!
INFO 2022-05-23 08:57:42,967 checkpoint.py: 672: Loaded: base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2022-05-23 08:57:42,968 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,968 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,968 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,969 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,969 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,969 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,969 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,970 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,970 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,970 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,971 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,971 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:42,971 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,972 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,972 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,972 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,972 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2022-05-23 08:57:42,973 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,973 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,973 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,974 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,974 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,974 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2022-05-23 08:57:42,975 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,975 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,975 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,975 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,976 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,976 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2022-05-23 08:57:42,976 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,976 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,977 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,977 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,977 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,978 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,978 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:42,978 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,979 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,979 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,979 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,979 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2022-05-23 08:57:42,980 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,980 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,980 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,981 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,981 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,981 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2022-05-23 08:57:42,982 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,982 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,982 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,982 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,983 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,983 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,983 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:42,984 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,984 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,984 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,984 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:42,985 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2022-05-23 08:57:42,985 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,985 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,986 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,986 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,986 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:42,987 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2022-05-23 08:57:42,987 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,987 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,987 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,988 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,988 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,989 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,989 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:42,989 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,989 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,990 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,990 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,990 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2022-05-23 08:57:42,991 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,991 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,991 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,991 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,992 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,992 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2022-05-23 08:57:42,992 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,993 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,993 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,993 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,994 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,994 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2022-05-23 08:57:42,994 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,995 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,995 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,995 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,995 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,996 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2022-05-23 08:57:42,996 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:42,997 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,997 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,997 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,998 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:42,998 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2022-05-23 08:57:42,998 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:42,999 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,999 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,999 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:42,999 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,000 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,000 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,000 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,001 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,001 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,001 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,002 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,002 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,002 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,002 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,003 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,003 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,004 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,004 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,004 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,005 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,005 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,005 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,006 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,006 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,006 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,007 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,007 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,007 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,008 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,008 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,008 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,009 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,009 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,009 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-23 08:57:43,010 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,010 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,010 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,011 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,011 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,011 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,011 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,012 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,012 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,012 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,013 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,013 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,013 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,014 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,014 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,014 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,015 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,015 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,015 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,016 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,016 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,016 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,016 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,017 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,017 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,017 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,018 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,018 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,018 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,019 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,019 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2022-05-23 08:57:43,019 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,020 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,020 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,020 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,021 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,021 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,021 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,022 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,022 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,022 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,023 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,023 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,023 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,024 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,024 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,024 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,025 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,025 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,025 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,026 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,026 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,026 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,027 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,027 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,027 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,028 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,028 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,028 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,028 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,029 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,029 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,029 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,030 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,030 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,030 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,031 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,031 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,031 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,032 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,032 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,032 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,033 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,033 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,033 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,034 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,034 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,034 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,035 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,035 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,035 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,036 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,036 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,036 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,037 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,037 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,037 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,038 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,038 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,038 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,039 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,039 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,039 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,039 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,040 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,040 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,040 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,041 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,041 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,041 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,042 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,042 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,042 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,042 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,043 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,043 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,043 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,044 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,044 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,044 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,045 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,045 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,045 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,046 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,046 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,046 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,046 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,047 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,047 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,047 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,048 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,048 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,048 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,049 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,049 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,049 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,050 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,050 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,050 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,051 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,051 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,051 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,052 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,052 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,052 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,053 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,053 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,053 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,054 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,054 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,054 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,055 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,055 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,056 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,056 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2022-05-23 08:57:43,056 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,057 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,057 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,058 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,058 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,058 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,059 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,059 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,059 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,060 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,060 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,060 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,061 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,061 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,062 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,062 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,062 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,063 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,063 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,063 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,064 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,064 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,064 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,065 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2022-05-23 08:57:43,065 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-23 08:57:43,065 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,066 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,066 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,066 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,067 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2022-05-23 08:57:43,067 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-23 08:57:43,067 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,068 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,068 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,068 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,069 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2022-05-23 08:57:43,069 checkpoint.py: 672: Loaded: 0.channel_bn.weight                                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:43,070 checkpoint.py: 672: Loaded: 0.channel_bn.bias                                                    of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:43,070 checkpoint.py: 672: Loaded: 0.channel_bn.running_mean                                            of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:43,070 checkpoint.py: 672: Loaded: 0.channel_bn.running_var                                             of shape: torch.Size([64]) from checkpoint
INFO 2022-05-23 08:57:43,071 checkpoint.py: 657: Ignored layer:	0.channel_bn.num_batches_tracked
INFO 2022-05-23 08:57:43,071 checkpoint.py: 672: Loaded: 0.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-23 08:57:43,072 checkpoint.py: 672: Loaded: 0.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-23 08:57:43,072 checkpoint.py: 672: Loaded: 1.channel_bn.weight                                                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,072 checkpoint.py: 672: Loaded: 1.channel_bn.bias                                                    of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,073 checkpoint.py: 672: Loaded: 1.channel_bn.running_mean                                            of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,073 checkpoint.py: 672: Loaded: 1.channel_bn.running_var                                             of shape: torch.Size([256]) from checkpoint
INFO 2022-05-23 08:57:43,074 checkpoint.py: 657: Ignored layer:	1.channel_bn.num_batches_tracked
INFO 2022-05-23 08:57:43,074 checkpoint.py: 672: Loaded: 1.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-23 08:57:43,074 checkpoint.py: 672: Loaded: 1.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-23 08:57:43,075 checkpoint.py: 672: Loaded: 2.channel_bn.weight                                                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,075 checkpoint.py: 672: Loaded: 2.channel_bn.bias                                                    of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,075 checkpoint.py: 672: Loaded: 2.channel_bn.running_mean                                            of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,076 checkpoint.py: 672: Loaded: 2.channel_bn.running_var                                             of shape: torch.Size([512]) from checkpoint
INFO 2022-05-23 08:57:43,076 checkpoint.py: 657: Ignored layer:	2.channel_bn.num_batches_tracked
INFO 2022-05-23 08:57:43,077 checkpoint.py: 672: Loaded: 2.clf.clf.0.weight                                                   of shape: torch.Size([1000, 8192]) from checkpoint
INFO 2022-05-23 08:57:43,077 checkpoint.py: 672: Loaded: 2.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-23 08:57:43,077 checkpoint.py: 672: Loaded: 3.channel_bn.weight                                                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,078 checkpoint.py: 672: Loaded: 3.channel_bn.bias                                                    of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,078 checkpoint.py: 672: Loaded: 3.channel_bn.running_mean                                            of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,078 checkpoint.py: 672: Loaded: 3.channel_bn.running_var                                             of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-23 08:57:43,079 checkpoint.py: 657: Ignored layer:	3.channel_bn.num_batches_tracked
INFO 2022-05-23 08:57:43,079 checkpoint.py: 672: Loaded: 3.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-23 08:57:43,079 checkpoint.py: 672: Loaded: 3.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-23 08:57:43,080 checkpoint.py: 672: Loaded: 4.channel_bn.weight                                                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,080 checkpoint.py: 672: Loaded: 4.channel_bn.bias                                                    of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,080 checkpoint.py: 672: Loaded: 4.channel_bn.running_mean                                            of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,081 checkpoint.py: 672: Loaded: 4.channel_bn.running_var                                             of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-23 08:57:43,081 checkpoint.py: 657: Ignored layer:	4.channel_bn.num_batches_tracked
INFO 2022-05-23 08:57:43,082 checkpoint.py: 672: Loaded: 4.clf.clf.0.weight                                                   of shape: torch.Size([1000, 8192]) from checkpoint
INFO 2022-05-23 08:57:43,082 checkpoint.py: 672: Loaded: 4.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-23 08:57:43,082 checkpoint.py: 685: Extra layers not loaded from checkpoint: []
INFO 2022-05-23 08:57:43,272 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 08:58:25,752 trainer_main.py: 268: Training 28 epochs
INFO 2022-05-23 08:58:25,753 trainer_main.py: 269: One epoch = 5005 iterations.
INFO 2022-05-23 08:58:25,753 trainer_main.py: 270: Total 1281167 samples in one epoch
INFO 2022-05-23 08:58:25,753 trainer_main.py: 276: Total 140140 iterations for training
INFO 2022-05-23 08:58:26,050 logger.py:  84: Mon May 23 08:58:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:3A:00.0 Off |                    0 |
| N/A   31C    P0    53W / 300W |   1762MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     49167      C   python                           1757MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-23 08:58:26,053 trainer_main.py: 173: Model is:
 Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)
              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)
      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)
      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)
      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)
      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)
    )
  )
  (heads): ModuleList(
    (0): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (1): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (2): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
    (3): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (4): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
  )
)
INFO 2022-05-23 08:58:26,054 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2022-05-23 08:58:26,055 trainer_main.py: 175: Starting training....
INFO 2022-05-23 08:58:26,055 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 19, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 08:59:02,114 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 08:59:02,115 state_update_hooks.py: 115: Starting phase 19 [test]
INFO 2022-05-23 09:03:52,737 trainer_main.py: 214: Meters synced
INFO 2022-05-23 09:03:52,741 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1482
INFO 2022-05-23 09:03:52,742 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.094, 'res2': 23.06, 'res3': 32.403999999999996, 'res4': 41.052, 'res5': 35.666}, 'top_5': {'conv1': 20.626, 'res2': 41.532000000000004, 'res3': 53.71, 'res4': 63.748000000000005, 'res5': 58.228}}
INFO 2022-05-23 09:03:52,742 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 09:03:52,745 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 09:03:52,746 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 20, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 09:04:36,614 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 09:04:36,615 state_update_hooks.py: 115: Starting phase 20 [train]
INFO 2022-05-23 09:07:57,803 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50200; lr: 0.001; loss: 21.12635; btime(ms): 1652; eta: 1 day, 17:16:32; peak_mem(M): 6616;
INFO 2022-05-23 09:12:20,838 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50400; lr: 0.001; loss: 21.05939; btime(ms): 1528; eta: 1 day, 14:06:29; peak_mem(M): 6616;
INFO 2022-05-23 09:16:44,837 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50600; lr: 0.001; loss: 21.87467; btime(ms): 1472; eta: 1 day, 12:37:52; peak_mem(M): 6616;
INFO 2022-05-23 09:21:08,038 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 50800; lr: 0.001; loss: 21.83718; btime(ms): 1439; eta: 1 day, 11:43:44; peak_mem(M): 6616;
INFO 2022-05-23 09:25:30,192 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51000; lr: 0.001; loss: 20.82236; btime(ms): 1417; eta: 1 day, 11:05:28; peak_mem(M): 6616;
INFO 2022-05-23 09:29:50,886 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51200; lr: 0.001; loss: 20.47064; btime(ms): 1400; eta: 1 day, 10:35:38; peak_mem(M): 6616;
INFO 2022-05-23 09:34:14,194 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51400; lr: 0.001; loss: 22.17399; btime(ms): 1389; eta: 1 day, 10:14:54; peak_mem(M): 6616;
INFO 2022-05-23 09:38:37,542 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51600; lr: 0.001; loss: 20.40065; btime(ms): 1381; eta: 1 day, 9:58:04; peak_mem(M): 6616;
INFO 2022-05-23 09:43:01,404 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 51800; lr: 0.001; loss: 20.46059; btime(ms): 1374; eta: 1 day, 9:44:07; peak_mem(M): 6616;
INFO 2022-05-23 09:47:24,695 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52000; lr: 0.001; loss: 21.62663; btime(ms): 1369; eta: 1 day, 9:31:37; peak_mem(M): 6616;
INFO 2022-05-23 09:51:47,306 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52200; lr: 0.001; loss: 21.35464; btime(ms): 1364; eta: 1 day, 9:19:14; peak_mem(M): 6616;
INFO 2022-05-23 09:56:10,349 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52400; lr: 0.001; loss: 20.82257; btime(ms): 1360; eta: 1 day, 9:09:44; peak_mem(M): 6616;
INFO 2022-05-23 10:00:33,777 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52600; lr: 0.001; loss: 21.25432; btime(ms): 1357; eta: 1 day, 9:00:33; peak_mem(M): 6616;
INFO 2022-05-23 10:04:57,267 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 52800; lr: 0.001; loss: 20.80963; btime(ms): 1354; eta: 1 day, 8:52:02; peak_mem(M): 6616;
INFO 2022-05-23 10:09:17,975 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53000; lr: 0.001; loss: 21.02571; btime(ms): 1351; eta: 1 day, 8:42:51; peak_mem(M): 6616;
INFO 2022-05-23 10:13:47,100 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53200; lr: 0.001; loss: 20.8233; btime(ms): 1351; eta: 1 day, 8:37:48; peak_mem(M): 6616;
INFO 2022-05-23 10:18:08,379 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53400; lr: 0.001; loss: 19.90647; btime(ms): 1348; eta: 1 day, 8:29:43; peak_mem(M): 6616;
INFO 2022-05-23 10:22:31,260 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53600; lr: 0.001; loss: 22.29952; btime(ms): 1346; eta: 1 day, 8:22:32; peak_mem(M): 6616;
INFO 2022-05-23 10:26:52,757 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 53800; lr: 0.001; loss: 21.18597; btime(ms): 1344; eta: 1 day, 8:15:10; peak_mem(M): 6616;
INFO 2022-05-23 10:31:14,056 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54000; lr: 0.001; loss: 21.67878; btime(ms): 1342; eta: 1 day, 8:08:03; peak_mem(M): 6616;
INFO 2022-05-23 10:35:35,604 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54200; lr: 0.001; loss: 21.10042; btime(ms): 1341; eta: 1 day, 8:01:14; peak_mem(M): 6616;
INFO 2022-05-23 10:39:58,008 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54400; lr: 0.001; loss: 20.83411; btime(ms): 1339; eta: 1 day, 7:54:10; peak_mem(M): 6616;
INFO 2022-05-23 10:44:23,558 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54600; lr: 0.001; loss: 20.85523; btime(ms): 1339; eta: 1 day, 7:49:44; peak_mem(M): 6616;
INFO 2022-05-23 10:48:46,609 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 54800; lr: 0.001; loss: 21.52865; btime(ms): 1338; eta: 1 day, 7:43:51; peak_mem(M): 6616;
INFO 2022-05-23 10:53:11,726 log_hooks.py: 277: Rank: 0; [ep: 10] iter: 55000; lr: 0.001; loss: 21.72329; btime(ms): 1338; eta: 1 day, 7:38:41; peak_mem(M): 6616;
INFO 2022-05-23 10:54:19,103 trainer_main.py: 214: Meters synced
INFO 2022-05-23 10:54:19,106 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1315
INFO 2022-05-23 10:54:19,107 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  960.84 ms  958.81 ms
             forward:   10.51 ms  214.68 ms
        loss_compute:    1.11 ms    1.09 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  127.93 ms  128.05 ms
            backward:    3.35 ms    5.99 ms
      optimizer_step:    1.38 ms    3.68 ms
    train_step_total: 1315.00 ms 1315.20 ms
INFO 2022-05-23 10:54:19,108 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.6388, 'res2': 18.726100000000002, 'res3': 27.8515, 'res4': 37.4412, 'res5': 33.913}, 'top_5': {'conv1': 16.125600000000002, 'res2': 35.268899999999995, 'res3': 47.214099999999995, 'res4': 58.3299, 'res5': 55.1766}}
INFO 2022-05-23 10:54:19,109 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 10:54:19,113 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 10:54:19,113 log_hooks.py: 425: [phase: 10] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 10:54:20,432 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase10.torch
INFO 2022-05-23 10:54:20,433 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 10:54:20,435 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 10:54:20,437 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 21, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 10:54:57,682 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 10:54:57,682 state_update_hooks.py: 115: Starting phase 21 [test]
INFO 2022-05-23 10:59:45,585 trainer_main.py: 214: Meters synced
INFO 2022-05-23 10:59:45,589 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1468
INFO 2022-05-23 10:59:45,590 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.298, 'res2': 23.3, 'res3': 32.828, 'res4': 41.372, 'res5': 35.809999999999995}, 'top_5': {'conv1': 21.006, 'res2': 41.943999999999996, 'res3': 54.086, 'res4': 63.876, 'res5': 58.326}}
INFO 2022-05-23 10:59:45,590 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 10:59:45,593 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 10:59:45,593 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 22, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 11:00:27,499 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 11:00:27,500 state_update_hooks.py: 115: Starting phase 22 [train]
INFO 2022-05-23 11:03:39,619 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 55200; lr: 0.001; loss: 20.81995; btime(ms): 1355; eta: 1 day, 7:59:16; peak_mem(M): 6616;
INFO 2022-05-23 11:08:00,901 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 55400; lr: 0.001; loss: 20.89349; btime(ms): 1354; eta: 1 day, 7:52:21; peak_mem(M): 6616;
INFO 2022-05-23 11:12:21,901 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 55600; lr: 0.001; loss: 20.62025; btime(ms): 1352; eta: 1 day, 7:45:29; peak_mem(M): 6616;
INFO 2022-05-23 11:16:45,033 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 55800; lr: 0.001; loss: 20.41879; btime(ms): 1351; eta: 1 day, 7:39:16; peak_mem(M): 6616;
INFO 2022-05-23 11:21:08,649 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 56000; lr: 0.001; loss: 19.62994; btime(ms): 1350; eta: 1 day, 7:33:20; peak_mem(M): 6616;
INFO 2022-05-23 11:25:27,754 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 56200; lr: 0.001; loss: 20.28735; btime(ms): 1348; eta: 1 day, 7:26:30; peak_mem(M): 6616;
INFO 2022-05-23 11:29:27,243 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 56400; lr: 0.001; loss: 20.39138; btime(ms): 1343; eta: 1 day, 7:15:46; peak_mem(M): 6616;
INFO 2022-05-23 11:33:31,208 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 56600; lr: 0.001; loss: 20.68531; btime(ms): 1340; eta: 1 day, 7:06:18; peak_mem(M): 6616;
INFO 2022-05-23 11:37:53,171 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 56800; lr: 0.001; loss: 20.62925; btime(ms): 1339; eta: 1 day, 7:00:37; peak_mem(M): 6616;
INFO 2022-05-23 11:42:14,453 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 57000; lr: 0.001; loss: 21.08121; btime(ms): 1338; eta: 1 day, 6:54:56; peak_mem(M): 6616;
INFO 2022-05-23 11:46:34,581 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 57200; lr: 0.001; loss: 21.96372; btime(ms): 1337; eta: 1 day, 6:49:03; peak_mem(M): 6616;
INFO 2022-05-23 11:50:53,661 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 57400; lr: 0.001; loss: 20.86415; btime(ms): 1336; eta: 1 day, 6:43:05; peak_mem(M): 6616;
INFO 2022-05-23 11:55:15,493 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 57600; lr: 0.001; loss: 21.77232; btime(ms): 1335; eta: 1 day, 6:37:41; peak_mem(M): 6616;
INFO 2022-05-23 11:59:35,217 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 57800; lr: 0.001; loss: 20.69464; btime(ms): 1334; eta: 1 day, 6:31:59; peak_mem(M): 6616;
INFO 2022-05-23 12:03:56,164 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 58000; lr: 0.001; loss: 21.59075; btime(ms): 1334; eta: 1 day, 6:26:32; peak_mem(M): 6616;
INFO 2022-05-23 12:08:18,276 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 58200; lr: 0.001; loss: 21.25527; btime(ms): 1333; eta: 1 day, 6:21:20; peak_mem(M): 6616;
INFO 2022-05-23 12:12:37,706 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 58400; lr: 0.001; loss: 20.11465; btime(ms): 1332; eta: 1 day, 6:15:45; peak_mem(M): 6616;
INFO 2022-05-23 12:16:58,030 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 58600; lr: 0.001; loss: 21.30353; btime(ms): 1332; eta: 1 day, 6:10:21; peak_mem(M): 6616;
INFO 2022-05-23 12:21:05,399 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 58800; lr: 0.001; loss: 20.68617; btime(ms): 1330; eta: 1 day, 6:03:06; peak_mem(M): 6616;
INFO 2022-05-23 12:25:25,957 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 59000; lr: 0.001; loss: 19.55857; btime(ms): 1329; eta: 1 day, 5:57:52; peak_mem(M): 6616;
INFO 2022-05-23 12:29:48,126 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 59200; lr: 0.001; loss: 21.59343; btime(ms): 1329; eta: 1 day, 5:52:54; peak_mem(M): 6616;
INFO 2022-05-23 12:34:09,050 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 59400; lr: 0.001; loss: 21.98303; btime(ms): 1328; eta: 1 day, 5:47:48; peak_mem(M): 6616;
INFO 2022-05-23 12:38:27,188 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 59600; lr: 0.001; loss: 20.8388; btime(ms): 1327; eta: 1 day, 5:42:21; peak_mem(M): 6616;
INFO 2022-05-23 12:42:48,255 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 59800; lr: 0.001; loss: 19.91277; btime(ms): 1327; eta: 1 day, 5:37:20; peak_mem(M): 6616;
INFO 2022-05-23 12:47:10,823 log_hooks.py: 277: Rank: 0; [ep: 11] iter: 60000; lr: 0.001; loss: 21.04452; btime(ms): 1327; eta: 1 day, 5:32:33; peak_mem(M): 6616;
INFO 2022-05-23 12:48:21,456 trainer_main.py: 214: Meters synced
INFO 2022-05-23 12:48:21,460 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1293
INFO 2022-05-23 12:48:21,461 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  940.98 ms  939.32 ms
             forward:   10.48 ms  214.49 ms
        loss_compute:    1.12 ms    1.11 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  125.20 ms  125.30 ms
            backward:    3.34 ms    6.01 ms
      optimizer_step:    1.39 ms    3.75 ms
    train_step_total: 1293.31 ms 1293.52 ms
INFO 2022-05-23 12:48:21,462 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.7469, 'res2': 18.9178, 'res3': 27.982000000000003, 'res4': 37.587399999999995, 'res5': 34.049}, 'top_5': {'conv1': 16.317, 'res2': 35.457, 'res3': 47.429500000000004, 'res4': 58.5198, 'res5': 55.36450000000001}}
INFO 2022-05-23 12:48:21,462 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 12:48:21,468 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 12:48:21,468 log_hooks.py: 425: [phase: 11] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 12:48:22,763 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase11.torch
INFO 2022-05-23 12:48:22,764 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 12:48:22,766 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 12:48:22,767 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 23, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 12:49:02,934 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 12:49:02,935 state_update_hooks.py: 115: Starting phase 23 [test]
INFO 2022-05-23 12:53:48,863 trainer_main.py: 214: Meters synced
INFO 2022-05-23 12:53:48,867 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1458
INFO 2022-05-23 12:53:48,868 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.318, 'res2': 23.483999999999998, 'res3': 33.242, 'res4': 41.618, 'res5': 36.002}, 'top_5': {'conv1': 21.156, 'res2': 42.274, 'res3': 54.412000000000006, 'res4': 64.106, 'res5': 58.602}}
INFO 2022-05-23 12:53:48,868 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 12:53:48,871 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 12:53:48,872 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 24, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 12:54:32,095 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 12:54:32,096 state_update_hooks.py: 115: Starting phase 24 [train]
INFO 2022-05-23 12:57:37,405 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 60200; lr: 0.001; loss: 20.85946; btime(ms): 1336; eta: 1 day, 5:40:39; peak_mem(M): 6616;
INFO 2022-05-23 13:01:56,884 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 60400; lr: 0.001; loss: 19.92243; btime(ms): 1335; eta: 1 day, 5:35:15; peak_mem(M): 6616;
INFO 2022-05-23 13:06:19,877 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 60600; lr: 0.001; loss: 21.69143; btime(ms): 1335; eta: 1 day, 5:30:18; peak_mem(M): 6616;
INFO 2022-05-23 13:10:38,083 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 60800; lr: 0.001; loss: 21.50085; btime(ms): 1334; eta: 1 day, 5:24:48; peak_mem(M): 6616;
INFO 2022-05-23 13:14:53,575 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 61000; lr: 0.001; loss: 20.70674; btime(ms): 1333; eta: 1 day, 5:19:03; peak_mem(M): 6616;
INFO 2022-05-23 13:19:09,536 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 61200; lr: 0.001; loss: 21.85964; btime(ms): 1332; eta: 1 day, 5:13:24; peak_mem(M): 6616;
INFO 2022-05-23 13:23:25,791 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 61400; lr: 0.001; loss: 20.91571; btime(ms): 1331; eta: 1 day, 5:07:49; peak_mem(M): 6616;
INFO 2022-05-23 13:27:41,584 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 61600; lr: 0.001; loss: 20.39543; btime(ms): 1330; eta: 1 day, 5:02:15; peak_mem(M): 6616;
INFO 2022-05-23 13:31:56,091 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 61800; lr: 0.001; loss: 20.95152; btime(ms): 1330; eta: 1 day, 4:56:35; peak_mem(M): 6616;
INFO 2022-05-23 13:36:15,288 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 62000; lr: 0.001; loss: 20.89412; btime(ms): 1329; eta: 1 day, 4:51:26; peak_mem(M): 6616;
INFO 2022-05-23 13:40:27,172 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 62200; lr: 0.001; loss: 19.94977; btime(ms): 1328; eta: 1 day, 4:45:34; peak_mem(M): 6616;
INFO 2022-05-23 13:44:34,362 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 62400; lr: 0.001; loss: 21.46371; btime(ms): 1326; eta: 1 day, 4:39:17; peak_mem(M): 6616;
INFO 2022-05-23 13:48:42,736 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 62600; lr: 0.001; loss: 20.80556; btime(ms): 1325; eta: 1 day, 4:33:12; peak_mem(M): 6616;
INFO 2022-05-23 13:52:51,701 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 62800; lr: 0.001; loss: 21.84899; btime(ms): 1324; eta: 1 day, 4:27:13; peak_mem(M): 6616;
INFO 2022-05-23 13:57:02,119 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 63000; lr: 0.001; loss: 21.25404; btime(ms): 1323; eta: 1 day, 4:21:25; peak_mem(M): 6616;
INFO 2022-05-23 14:01:09,522 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 63200; lr: 0.001; loss: 20.93282; btime(ms): 1322; eta: 1 day, 4:15:24; peak_mem(M): 6616;
INFO 2022-05-23 14:05:19,363 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 63400; lr: 0.001; loss: 21.80353; btime(ms): 1321; eta: 1 day, 4:09:40; peak_mem(M): 6616;
INFO 2022-05-23 14:09:27,569 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 63600; lr: 0.001; loss: 21.15101; btime(ms): 1319; eta: 1 day, 4:03:48; peak_mem(M): 6616;
INFO 2022-05-23 14:13:38,165 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 63800; lr: 0.001; loss: 21.21791; btime(ms): 1319; eta: 1 day, 3:58:13; peak_mem(M): 6616;
INFO 2022-05-23 14:17:46,153 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 64000; lr: 0.001; loss: 20.62296; btime(ms): 1317; eta: 1 day, 3:52:26; peak_mem(M): 6616;
INFO 2022-05-23 14:21:56,352 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 64200; lr: 0.001; loss: 22.02058; btime(ms): 1317; eta: 1 day, 3:46:54; peak_mem(M): 6616;
INFO 2022-05-23 14:26:06,598 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 64400; lr: 0.001; loss: 21.06916; btime(ms): 1316; eta: 1 day, 3:41:24; peak_mem(M): 6616;
INFO 2022-05-23 14:30:12,668 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 64600; lr: 0.001; loss: 20.83792; btime(ms): 1315; eta: 1 day, 3:35:35; peak_mem(M): 6616;
INFO 2022-05-23 14:34:23,523 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 64800; lr: 0.001; loss: 21.14952; btime(ms): 1314; eta: 1 day, 3:30:12; peak_mem(M): 6616;
INFO 2022-05-23 14:38:31,902 log_hooks.py: 277: Rank: 0; [ep: 12] iter: 65000; lr: 0.001; loss: 21.12167; btime(ms): 1313; eta: 1 day, 3:24:39; peak_mem(M): 6616;
INFO 2022-05-23 14:39:51,423 trainer_main.py: 214: Meters synced
INFO 2022-05-23 14:39:51,427 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1262
INFO 2022-05-23 14:39:51,427 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  915.09 ms  913.23 ms
             forward:    9.95 ms  214.45 ms
        loss_compute:    1.07 ms    1.05 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  121.13 ms  121.24 ms
            backward:    3.25 ms    5.93 ms
      optimizer_step:    1.36 ms    3.69 ms
    train_step_total: 1262.43 ms 1262.62 ms
INFO 2022-05-23 14:39:51,428 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.7994, 'res2': 19.0839, 'res3': 28.2175, 'res4': 37.7812, 'res5': 34.1586}, 'top_5': {'conv1': 16.4087, 'res2': 35.7142, 'res3': 47.6353, 'res4': 58.7209, 'res5': 55.4605}}
INFO 2022-05-23 14:39:51,429 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 14:39:51,432 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 14:39:51,433 log_hooks.py: 425: [phase: 12] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 14:39:52,697 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase12.torch
INFO 2022-05-23 14:39:52,697 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 14:39:52,700 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 14:39:52,700 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 25, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 14:40:30,811 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 14:40:30,811 state_update_hooks.py: 115: Starting phase 25 [test]
INFO 2022-05-23 14:45:04,571 trainer_main.py: 214: Meters synced
INFO 2022-05-23 14:45:04,575 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1396
INFO 2022-05-23 14:45:04,576 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.42, 'res2': 23.744, 'res3': 33.134, 'res4': 41.766, 'res5': 36.092}, 'top_5': {'conv1': 21.302, 'res2': 42.312, 'res3': 54.504, 'res4': 64.302, 'res5': 58.672000000000004}}
INFO 2022-05-23 14:45:04,576 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 14:45:04,578 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 14:45:04,579 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 26, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 14:45:46,068 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 14:45:46,069 state_update_hooks.py: 115: Starting phase 26 [train]
INFO 2022-05-23 14:48:34,199 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 65200; lr: 0.001; loss: 20.20934; btime(ms): 1318; eta: 1 day, 3:26:44; peak_mem(M): 6616;
INFO 2022-05-23 14:52:41,157 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 65400; lr: 0.001; loss: 21.95901; btime(ms): 1317; eta: 1 day, 3:21:03; peak_mem(M): 6616;
INFO 2022-05-23 14:56:47,756 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 65600; lr: 0.001; loss: 20.93303; btime(ms): 1316; eta: 1 day, 3:15:22; peak_mem(M): 6616;
INFO 2022-05-23 15:00:53,076 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 65800; lr: 0.001; loss: 20.87144; btime(ms): 1315; eta: 1 day, 3:09:38; peak_mem(M): 6616;
INFO 2022-05-23 15:05:01,711 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 66000; lr: 0.001; loss: 20.75391; btime(ms): 1314; eta: 1 day, 3:04:10; peak_mem(M): 6616;
INFO 2022-05-23 15:09:07,405 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 66200; lr: 0.001; loss: 21.32476; btime(ms): 1313; eta: 1 day, 2:58:33; peak_mem(M): 6616;
INFO 2022-05-23 15:13:17,747 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 66400; lr: 0.001; loss: 20.5923; btime(ms): 1312; eta: 1 day, 2:53:13; peak_mem(M): 6616;
INFO 2022-05-23 15:17:27,939 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 66600; lr: 0.001; loss: 20.26771; btime(ms): 1311; eta: 1 day, 2:48:02; peak_mem(M): 6616;
INFO 2022-05-23 15:21:38,233 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 66800; lr: 0.001; loss: 20.49357; btime(ms): 1311; eta: 1 day, 2:42:49; peak_mem(M): 6616;
INFO 2022-05-23 15:25:44,076 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 67000; lr: 0.001; loss: 22.47698; btime(ms): 1310; eta: 1 day, 2:37:18; peak_mem(M): 6616;
INFO 2022-05-23 15:29:54,283 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 67200; lr: 0.001; loss: 21.95146; btime(ms): 1309; eta: 1 day, 2:31:58; peak_mem(M): 6616;
INFO 2022-05-23 15:34:03,602 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 67400; lr: 0.001; loss: 20.99034; btime(ms): 1309; eta: 1 day, 2:26:56; peak_mem(M): 6616;
INFO 2022-05-23 15:38:10,262 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 67600; lr: 0.001; loss: 20.52825; btime(ms): 1308; eta: 1 day, 2:21:31; peak_mem(M): 6616;
INFO 2022-05-23 15:42:13,366 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 67800; lr: 0.001; loss: 19.70008; btime(ms): 1307; eta: 1 day, 2:15:53; peak_mem(M): 6616;
INFO 2022-05-23 15:46:30,825 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 68000; lr: 0.001; loss: 20.83978; btime(ms): 1306; eta: 1 day, 2:11:23; peak_mem(M): 6616;
INFO 2022-05-23 15:50:50,593 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 68200; lr: 0.001; loss: 20.86911; btime(ms): 1306; eta: 1 day, 2:06:57; peak_mem(M): 6616;
INFO 2022-05-23 15:55:12,064 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 68400; lr: 0.001; loss: 20.38143; btime(ms): 1306; eta: 1 day, 2:02:35; peak_mem(M): 6616;
INFO 2022-05-23 15:59:29,470 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 68600; lr: 0.001; loss: 21.68016; btime(ms): 1306; eta: 1 day, 1:57:59; peak_mem(M): 6616;
INFO 2022-05-23 16:03:48,704 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 68800; lr: 0.001; loss: 20.53883; btime(ms): 1306; eta: 1 day, 1:53:30; peak_mem(M): 6616;
INFO 2022-05-23 16:08:06,594 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 69000; lr: 0.001; loss: 20.23781; btime(ms): 1306; eta: 1 day, 1:48:55; peak_mem(M): 6616;
INFO 2022-05-23 16:12:22,446 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 69200; lr: 0.001; loss: 20.98658; btime(ms): 1306; eta: 1 day, 1:44:15; peak_mem(M): 6616;
INFO 2022-05-23 16:16:41,568 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 69400; lr: 0.001; loss: 20.76434; btime(ms): 1305; eta: 1 day, 1:39:40; peak_mem(M): 6616;
INFO 2022-05-23 16:21:03,309 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 69600; lr: 0.001; loss: 21.28016; btime(ms): 1305; eta: 1 day, 1:35:20; peak_mem(M): 6616;
INFO 2022-05-23 16:25:22,531 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 69800; lr: 0.001; loss: 21.62912; btime(ms): 1305; eta: 1 day, 1:30:58; peak_mem(M): 6616;
INFO 2022-05-23 16:29:34,798 log_hooks.py: 277: Rank: 0; [ep: 13] iter: 70000; lr: 0.001; loss: 20.99229; btime(ms): 1305; eta: 1 day, 1:25:59; peak_mem(M): 6616;
INFO 2022-05-23 16:30:55,623 trainer_main.py: 214: Meters synced
INFO 2022-05-23 16:30:55,627 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1260
INFO 2022-05-23 16:30:55,627 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  911.72 ms  909.61 ms
             forward:    9.99 ms  214.47 ms
        loss_compute:    1.09 ms    1.07 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  123.01 ms  123.11 ms
            backward:    3.28 ms    5.90 ms
      optimizer_step:    1.38 ms    3.66 ms
    train_step_total: 1260.47 ms 1260.67 ms
INFO 2022-05-23 16:30:55,628 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.862699999999999, 'res2': 19.1812, 'res3': 28.3711, 'res4': 37.9582, 'res5': 34.2791}, 'top_5': {'conv1': 16.4914, 'res2': 35.9201, 'res3': 47.8175, 'res4': 58.8958, 'res5': 55.60659999999999}}
INFO 2022-05-23 16:30:55,629 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 16:30:55,632 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 16:30:55,632 log_hooks.py: 425: [phase: 13] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 16:30:56,910 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase13.torch
INFO 2022-05-23 16:30:56,911 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 16:30:56,914 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 16:30:56,916 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 27, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 16:31:35,714 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 16:31:35,715 state_update_hooks.py: 115: Starting phase 27 [test]
INFO 2022-05-23 16:36:20,199 trainer_main.py: 214: Meters synced
INFO 2022-05-23 16:36:20,203 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1451
INFO 2022-05-23 16:36:20,203 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.546000000000001, 'res2': 23.576, 'res3': 33.28, 'res4': 41.824, 'res5': 36.196}, 'top_5': {'conv1': 21.458, 'res2': 42.514, 'res3': 54.657999999999994, 'res4': 64.36800000000001, 'res5': 58.550000000000004}}
INFO 2022-05-23 16:36:20,204 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 16:36:20,206 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 16:36:20,206 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 28, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 16:37:01,139 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 16:37:01,140 state_update_hooks.py: 115: Starting phase 28 [train]
INFO 2022-05-23 16:39:52,532 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 70200; lr: 0.001; loss: 19.84506; btime(ms): 1310; eta: 1 day, 1:27:21; peak_mem(M): 6616;
INFO 2022-05-23 16:44:14,976 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 70400; lr: 0.001; loss: 21.64218; btime(ms): 1310; eta: 1 day, 1:23:00; peak_mem(M): 6616;
INFO 2022-05-23 16:48:34,206 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 70600; lr: 0.001; loss: 20.95902; btime(ms): 1310; eta: 1 day, 1:18:29; peak_mem(M): 6616;
INFO 2022-05-23 16:52:55,401 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 70800; lr: 0.001; loss: 22.09306; btime(ms): 1310; eta: 1 day, 1:14:04; peak_mem(M): 6616;
INFO 2022-05-23 16:57:15,671 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 71000; lr: 0.001; loss: 20.2735; btime(ms): 1310; eta: 1 day, 1:09:37; peak_mem(M): 6616;
INFO 2022-05-23 17:01:37,292 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 71200; lr: 0.001; loss: 21.00973; btime(ms): 1310; eta: 1 day, 1:05:14; peak_mem(M): 6616;
INFO 2022-05-23 17:05:57,176 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 71400; lr: 0.001; loss: 20.02596; btime(ms): 1309; eta: 1 day, 1:00:45; peak_mem(M): 6616;
INFO 2022-05-23 17:10:17,142 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 71600; lr: 0.001; loss: 21.25709; btime(ms): 1309; eta: 1 day, 0:56:17; peak_mem(M): 6616;
INFO 2022-05-23 17:14:36,991 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 71800; lr: 0.001; loss: 21.27793; btime(ms): 1309; eta: 1 day, 0:51:49; peak_mem(M): 6616;
INFO 2022-05-23 17:18:56,481 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 72000; lr: 0.001; loss: 21.20393; btime(ms): 1309; eta: 1 day, 0:47:19; peak_mem(M): 6616;
INFO 2022-05-23 17:23:18,930 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 72200; lr: 0.001; loss: 20.75978; btime(ms): 1309; eta: 1 day, 0:42:59; peak_mem(M): 6616;
INFO 2022-05-23 17:27:40,435 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 72400; lr: 0.001; loss: 20.91511; btime(ms): 1309; eta: 1 day, 0:38:36; peak_mem(M): 6616;
INFO 2022-05-23 17:32:01,322 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 72600; lr: 0.001; loss: 20.40097; btime(ms): 1309; eta: 1 day, 0:34:11; peak_mem(M): 6616;
INFO 2022-05-23 17:36:20,654 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 72800; lr: 0.001; loss: 19.69868; btime(ms): 1309; eta: 1 day, 0:29:42; peak_mem(M): 6616;
INFO 2022-05-23 17:40:41,125 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 73000; lr: 0.001; loss: 21.51197; btime(ms): 1309; eta: 1 day, 0:25:15; peak_mem(M): 6616;
INFO 2022-05-23 17:45:02,543 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 73200; lr: 0.001; loss: 22.12488; btime(ms): 1309; eta: 1 day, 0:20:52; peak_mem(M): 6616;
INFO 2022-05-23 17:49:21,229 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 73400; lr: 0.001; loss: 20.90963; btime(ms): 1309; eta: 1 day, 0:16:22; peak_mem(M): 6616;
INFO 2022-05-23 17:53:43,182 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 73600; lr: 0.001; loss: 21.23518; btime(ms): 1309; eta: 1 day, 0:12:00; peak_mem(M): 6616;
INFO 2022-05-23 17:58:02,921 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 73800; lr: 0.001; loss: 19.94288; btime(ms): 1309; eta: 1 day, 0:07:32; peak_mem(M): 6616;
INFO 2022-05-23 18:02:19,175 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 74000; lr: 0.001; loss: 20.53943; btime(ms): 1308; eta: 1 day, 0:02:56; peak_mem(M): 6616;
INFO 2022-05-23 18:06:39,630 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 74200; lr: 0.001; loss: 20.91994; btime(ms): 1308; eta: 23:58:31; peak_mem(M): 6616;
INFO 2022-05-23 18:11:02,151 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 74400; lr: 0.001; loss: 20.35177; btime(ms): 1308; eta: 23:54:11; peak_mem(M): 6616;
INFO 2022-05-23 18:15:23,404 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 74600; lr: 0.001; loss: 20.45909; btime(ms): 1308; eta: 23:49:47; peak_mem(M): 6616;
INFO 2022-05-23 18:19:59,090 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 74800; lr: 0.001; loss: 20.80682; btime(ms): 1309; eta: 23:46:01; peak_mem(M): 6616;
INFO 2022-05-23 18:24:32,750 log_hooks.py: 277: Rank: 0; [ep: 14] iter: 75000; lr: 0.001; loss: 20.45195; btime(ms): 1309; eta: 23:42:09; peak_mem(M): 6616;
INFO 2022-05-23 18:26:09,924 trainer_main.py: 214: Meters synced
INFO 2022-05-23 18:26:09,926 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1308
INFO 2022-05-23 18:26:09,927 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  958.23 ms  956.54 ms
             forward:   10.56 ms  214.47 ms
        loss_compute:    1.11 ms    1.10 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  123.08 ms  123.19 ms
            backward:    3.32 ms    6.01 ms
      optimizer_step:    1.41 ms    3.73 ms
    train_step_total: 1308.26 ms 1308.47 ms
INFO 2022-05-23 18:26:09,928 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.9063, 'res2': 19.3542, 'res3': 28.5349, 'res4': 38.087199999999996, 'res5': 34.4082}, 'top_5': {'conv1': 16.5878, 'res2': 36.0856, 'res3': 47.9583, 'res4': 59.0277, 'res5': 55.74289999999999}}
INFO 2022-05-23 18:26:09,929 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 18:26:09,933 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 18:26:09,934 log_hooks.py: 425: [phase: 14] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 18:26:11,634 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase14.torch
INFO 2022-05-23 18:26:11,634 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 18:26:11,637 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 18:26:11,639 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 29, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 18:26:51,745 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 18:26:51,746 state_update_hooks.py: 115: Starting phase 29 [test]
INFO 2022-05-23 18:31:52,230 trainer_main.py: 214: Meters synced
INFO 2022-05-23 18:31:52,237 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1533
INFO 2022-05-23 18:31:52,238 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.698, 'res2': 23.95, 'res3': 33.418, 'res4': 42.038, 'res5': 36.254}, 'top_5': {'conv1': 21.522, 'res2': 42.852000000000004, 'res3': 54.932, 'res4': 64.5, 'res5': 58.8}}
INFO 2022-05-23 18:31:52,238 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 18:31:52,241 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 18:31:52,242 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 30, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 18:32:36,405 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 18:32:36,406 state_update_hooks.py: 115: Starting phase 30 [train]
INFO 2022-05-23 18:35:27,235 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 75200; lr: 0.001; loss: 20.54103; btime(ms): 1315; eta: 23:43:22; peak_mem(M): 6616;
INFO 2022-05-23 18:39:57,784 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 75400; lr: 0.001; loss: 20.52784; btime(ms): 1315; eta: 23:39:17; peak_mem(M): 6616;
INFO 2022-05-23 18:44:30,674 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 75600; lr: 0.001; loss: 22.04143; btime(ms): 1315; eta: 23:35:18; peak_mem(M): 6616;
INFO 2022-05-23 18:48:56,960 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 75800; lr: 0.001; loss: 20.73674; btime(ms): 1315; eta: 23:31:02; peak_mem(M): 6616;
INFO 2022-05-23 18:53:19,793 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 76000; lr: 0.001; loss: 21.35561; btime(ms): 1315; eta: 23:26:29; peak_mem(M): 6616;
INFO 2022-05-23 18:58:19,198 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 76200; lr: 0.001; loss: 19.37316; btime(ms): 1317; eta: 23:23:29; peak_mem(M): 6616;
INFO 2022-05-23 19:03:12,770 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 76400; lr: 0.001; loss: 20.13641; btime(ms): 1318; eta: 23:20:15; peak_mem(M): 6616;
INFO 2022-05-23 19:08:03,700 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 76600; lr: 0.001; loss: 21.28711; btime(ms): 1319; eta: 23:17:05; peak_mem(M): 6616;
INFO 2022-05-23 19:12:58,986 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 76800; lr: 0.001; loss: 20.11096; btime(ms): 1320; eta: 23:13:52; peak_mem(M): 6616;
INFO 2022-05-23 19:17:52,728 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 77000; lr: 0.001; loss: 21.01817; btime(ms): 1321; eta: 23:10:35; peak_mem(M): 6616;
INFO 2022-05-23 19:22:46,439 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 77200; lr: 0.001; loss: 21.34462; btime(ms): 1322; eta: 23:07:16; peak_mem(M): 6616;
INFO 2022-05-23 19:27:02,830 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 77400; lr: 0.001; loss: 20.82371; btime(ms): 1322; eta: 23:02:33; peak_mem(M): 6616;
INFO 2022-05-23 19:31:19,137 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 77600; lr: 0.001; loss: 21.10683; btime(ms): 1321; eta: 22:57:51; peak_mem(M): 6616;
INFO 2022-05-23 19:35:40,300 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 77800; lr: 0.001; loss: 20.1234; btime(ms): 1321; eta: 22:53:20; peak_mem(M): 6616;
INFO 2022-05-23 19:40:00,958 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 78000; lr: 0.001; loss: 20.49409; btime(ms): 1321; eta: 22:48:48; peak_mem(M): 6616;
INFO 2022-05-23 19:44:20,983 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 78200; lr: 0.001; loss: 20.7866; btime(ms): 1321; eta: 22:44:14; peak_mem(M): 6616;
INFO 2022-05-23 19:48:40,622 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 78400; lr: 0.001; loss: 20.11398; btime(ms): 1321; eta: 22:39:40; peak_mem(M): 6616;
INFO 2022-05-23 19:53:00,275 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 78600; lr: 0.001; loss: 21.71306; btime(ms): 1321; eta: 22:35:06; peak_mem(M): 6616;
INFO 2022-05-23 19:57:21,140 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 78800; lr: 0.001; loss: 21.24658; btime(ms): 1321; eta: 22:30:35; peak_mem(M): 6616;
INFO 2022-05-23 20:01:43,054 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 79000; lr: 0.001; loss: 21.37704; btime(ms): 1321; eta: 22:26:06; peak_mem(M): 6616;
INFO 2022-05-23 20:06:02,135 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 79200; lr: 0.001; loss: 21.2176; btime(ms): 1320; eta: 22:21:32; peak_mem(M): 6616;
INFO 2022-05-23 20:10:19,444 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 79400; lr: 0.001; loss: 20.6713; btime(ms): 1320; eta: 22:16:54; peak_mem(M): 6616;
INFO 2022-05-23 20:14:40,155 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 79600; lr: 0.001; loss: 20.71339; btime(ms): 1320; eta: 22:12:23; peak_mem(M): 6616;
INFO 2022-05-23 20:18:59,417 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 79800; lr: 0.001; loss: 20.48332; btime(ms): 1320; eta: 22:07:50; peak_mem(M): 6616;
INFO 2022-05-23 20:23:17,957 log_hooks.py: 277: Rank: 0; [ep: 15] iter: 80000; lr: 0.001; loss: 20.0551; btime(ms): 1320; eta: 22:03:15; peak_mem(M): 6616;
INFO 2022-05-23 20:24:58,972 trainer_main.py: 214: Meters synced
INFO 2022-05-23 20:24:58,975 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1347
INFO 2022-05-23 20:24:58,976 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  989.52 ms  987.69 ms
             forward:   10.78 ms  214.49 ms
        loss_compute:    1.14 ms    1.12 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  130.93 ms  131.04 ms
            backward:    3.41 ms    6.03 ms
      optimizer_step:    1.40 ms    3.67 ms
    train_step_total: 1346.97 ms 1347.19 ms
INFO 2022-05-23 20:24:58,977 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 6.958, 'res2': 19.5026, 'res3': 28.6053, 'res4': 38.1992, 'res5': 34.4263}, 'top_5': {'conv1': 16.6779, 'res2': 36.2423, 'res3': 48.1019, 'res4': 59.215399999999995, 'res5': 55.846399999999996}}
INFO 2022-05-23 20:24:58,977 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 20:24:58,981 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 20:24:58,981 log_hooks.py: 425: [phase: 15] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 20:25:00,280 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase15.torch
INFO 2022-05-23 20:25:00,280 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 20:25:00,283 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 20:25:00,284 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 31, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 20:25:46,064 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 20:25:46,065 state_update_hooks.py: 115: Starting phase 31 [test]
INFO 2022-05-23 20:30:31,727 trainer_main.py: 214: Meters synced
INFO 2022-05-23 20:30:31,730 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1457
INFO 2022-05-23 20:30:31,731 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 9.718, 'res2': 24.188000000000002, 'res3': 33.489999999999995, 'res4': 42.211999999999996, 'res5': 36.266}, 'top_5': {'conv1': 21.712, 'res2': 42.992000000000004, 'res3': 54.97, 'res4': 64.482, 'res5': 58.833999999999996}}
INFO 2022-05-23 20:30:31,731 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 20:30:31,734 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 20:30:31,735 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 32, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 20:31:23,095 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 20:31:23,096 state_update_hooks.py: 115: Starting phase 32 [train]
INFO 2022-05-23 20:34:19,080 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 80200; lr: 0.0001; loss: 19.87049; btime(ms): 1324; eta: 22:03:14; peak_mem(M): 6616;
INFO 2022-05-23 20:39:13,739 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 80400; lr: 0.0001; loss: 19.65288; btime(ms): 1325; eta: 21:59:44; peak_mem(M): 6616;
INFO 2022-05-23 20:44:11,570 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 80600; lr: 0.0001; loss: 21.1678; btime(ms): 1326; eta: 21:56:21; peak_mem(M): 6616;
INFO 2022-05-23 20:49:08,340 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 80800; lr: 0.0001; loss: 20.31069; btime(ms): 1327; eta: 21:52:54; peak_mem(M): 6616;
INFO 2022-05-23 20:54:08,626 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 81000; lr: 0.0001; loss: 21.63659; btime(ms): 1328; eta: 21:49:24; peak_mem(M): 6616;
INFO 2022-05-23 20:59:10,358 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 81200; lr: 0.0001; loss: 20.36022; btime(ms): 1329; eta: 21:46:03; peak_mem(M): 6616;
INFO 2022-05-23 21:03:37,223 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 81400; lr: 0.0001; loss: 21.0296; btime(ms): 1329; eta: 21:41:40; peak_mem(M): 6616;
INFO 2022-05-23 21:07:59,629 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 81600; lr: 0.0001; loss: 19.5303; btime(ms): 1329; eta: 21:37:15; peak_mem(M): 6616;
INFO 2022-05-23 21:12:19,518 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 81800; lr: 0.0001; loss: 21.04428; btime(ms): 1329; eta: 21:32:38; peak_mem(M): 6616;
INFO 2022-05-23 21:16:44,466 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 82000; lr: 0.0001; loss: 20.02234; btime(ms): 1329; eta: 21:28:10; peak_mem(M): 6616;
INFO 2022-05-23 21:21:16,149 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 82200; lr: 0.0001; loss: 20.93702; btime(ms): 1329; eta: 21:23:48; peak_mem(M): 6616;
INFO 2022-05-23 21:25:45,458 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 82400; lr: 0.0001; loss: 20.87883; btime(ms): 1329; eta: 21:19:28; peak_mem(M): 6616;
INFO 2022-05-23 21:30:08,810 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 82600; lr: 0.0001; loss: 20.82335; btime(ms): 1329; eta: 21:15:04; peak_mem(M): 6616;
INFO 2022-05-23 21:34:34,370 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 82800; lr: 0.0001; loss: 20.2875; btime(ms): 1329; eta: 21:10:38; peak_mem(M): 6616;
INFO 2022-05-23 21:39:02,936 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 83000; lr: 0.0001; loss: 21.18464; btime(ms): 1329; eta: 21:06:11; peak_mem(M): 6616;
INFO 2022-05-23 21:43:32,078 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 83200; lr: 0.0001; loss: 21.62706; btime(ms): 1329; eta: 21:01:51; peak_mem(M): 6616;
INFO 2022-05-23 21:48:04,032 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 83400; lr: 0.0001; loss: 20.11188; btime(ms): 1329; eta: 20:57:34; peak_mem(M): 6616;
INFO 2022-05-23 21:52:32,863 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 83600; lr: 0.0001; loss: 20.92236; btime(ms): 1329; eta: 20:53:12; peak_mem(M): 6616;
INFO 2022-05-23 21:57:01,129 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 83800; lr: 0.0001; loss: 20.29779; btime(ms): 1329; eta: 20:48:49; peak_mem(M): 6616;
INFO 2022-05-23 22:01:28,164 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 84000; lr: 0.0001; loss: 19.89433; btime(ms): 1330; eta: 20:44:26; peak_mem(M): 6616;
INFO 2022-05-23 22:05:55,096 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 84200; lr: 0.0001; loss: 19.70791; btime(ms): 1330; eta: 20:40:01; peak_mem(M): 6616;
INFO 2022-05-23 22:10:26,339 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 84400; lr: 0.0001; loss: 21.04443; btime(ms): 1330; eta: 20:35:44; peak_mem(M): 6616;
INFO 2022-05-23 22:15:32,657 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 84600; lr: 0.0001; loss: 19.57692; btime(ms): 1331; eta: 20:32:18; peak_mem(M): 6616;
INFO 2022-05-23 22:20:09,121 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 84800; lr: 0.0001; loss: 21.02712; btime(ms): 1331; eta: 20:28:09; peak_mem(M): 6616;
INFO 2022-05-23 22:24:26,972 log_hooks.py: 277: Rank: 0; [ep: 16] iter: 85000; lr: 0.0001; loss: 20.66321; btime(ms): 1331; eta: 20:23:35; peak_mem(M): 6616;
INFO 2022-05-23 22:26:17,267 trainer_main.py: 214: Meters synced
INFO 2022-05-23 22:26:17,271 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1377
INFO 2022-05-23 22:26:17,271 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1017.70 ms 1015.74 ms
             forward:   10.99 ms  214.52 ms
        loss_compute:    1.17 ms    1.15 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  133.16 ms  133.27 ms
            backward:    3.49 ms    6.07 ms
      optimizer_step:    1.47 ms    3.68 ms
    train_step_total: 1377.25 ms 1377.48 ms
INFO 2022-05-23 22:26:17,272 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.2226, 'res2': 20.039, 'res3': 29.255300000000002, 'res4': 38.8604, 'res5': 35.0684}, 'top_5': {'conv1': 17.152, 'res2': 36.9437, 'res3': 48.7541, 'res4': 59.7515, 'res5': 56.4098}}
INFO 2022-05-23 22:26:17,273 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 22:26:17,277 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 22:26:17,278 log_hooks.py: 425: [phase: 16] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-23 22:26:18,602 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase16.torch
INFO 2022-05-23 22:26:18,603 checkpoint.py: 140: Creating symlink...
INFO 2022-05-23 22:26:18,605 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-23 22:26:18,605 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 33, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 22:26:57,555 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 22:26:57,556 state_update_hooks.py: 115: Starting phase 33 [test]
INFO 2022-05-23 22:31:57,389 trainer_main.py: 214: Meters synced
INFO 2022-05-23 22:31:57,393 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1529
INFO 2022-05-23 22:31:57,394 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.113999999999999, 'res2': 24.622, 'res3': 34.108, 'res4': 42.522, 'res5': 36.646}, 'top_5': {'conv1': 22.2, 'res2': 43.616, 'res3': 55.564, 'res4': 64.89399999999999, 'res5': 59.106}}
INFO 2022-05-23 22:31:57,395 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 22:31:57,397 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-23 22:31:57,398 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 34, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-23 22:32:38,675 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-23 22:32:38,676 state_update_hooks.py: 115: Starting phase 34 [train]
INFO 2022-05-23 22:35:14,103 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 85200; lr: 0.0001; loss: 20.05606; btime(ms): 1334; eta: 20:22:09; peak_mem(M): 6616;
INFO 2022-05-23 22:39:49,596 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 85400; lr: 0.0001; loss: 20.60492; btime(ms): 1334; eta: 20:17:54; peak_mem(M): 6616;
INFO 2022-05-23 22:44:26,093 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 85600; lr: 0.0001; loss: 20.01291; btime(ms): 1335; eta: 20:13:41; peak_mem(M): 6616;
INFO 2022-05-23 22:49:05,070 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 85800; lr: 0.0001; loss: 21.25518; btime(ms): 1335; eta: 20:09:32; peak_mem(M): 6616;
INFO 2022-05-23 22:53:40,762 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 86000; lr: 0.0001; loss: 20.65334; btime(ms): 1335; eta: 20:05:17; peak_mem(M): 6616;
INFO 2022-05-23 22:58:16,295 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 86200; lr: 0.0001; loss: 20.68888; btime(ms): 1335; eta: 20:01:02; peak_mem(M): 6616;
INFO 2022-05-23 23:02:46,354 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 86400; lr: 0.0001; loss: 20.92517; btime(ms): 1336; eta: 19:56:39; peak_mem(M): 6616;
INFO 2022-05-23 23:07:20,322 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 86600; lr: 0.0001; loss: 20.65287; btime(ms): 1336; eta: 19:52:21; peak_mem(M): 6616;
INFO 2022-05-23 23:11:52,823 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 86800; lr: 0.0001; loss: 19.51641; btime(ms): 1336; eta: 19:48:01; peak_mem(M): 6616;
INFO 2022-05-23 23:16:26,752 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 87000; lr: 0.0001; loss: 21.7337; btime(ms): 1336; eta: 19:43:43; peak_mem(M): 6616;
INFO 2022-05-23 23:20:56,671 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 87200; lr: 0.0001; loss: 21.04671; btime(ms): 1336; eta: 19:39:19; peak_mem(M): 6616;
INFO 2022-05-23 23:25:27,053 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 87400; lr: 0.0001; loss: 20.32686; btime(ms): 1336; eta: 19:34:56; peak_mem(M): 6616;
INFO 2022-05-23 23:29:59,120 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 87600; lr: 0.0001; loss: 20.44374; btime(ms): 1336; eta: 19:30:35; peak_mem(M): 6616;
INFO 2022-05-23 23:34:34,947 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 87800; lr: 0.0001; loss: 21.55697; btime(ms): 1337; eta: 19:26:19; peak_mem(M): 6616;
INFO 2022-05-23 23:39:06,434 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 88000; lr: 0.0001; loss: 19.49649; btime(ms): 1337; eta: 19:21:57; peak_mem(M): 6616;
INFO 2022-05-23 23:43:36,757 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 88200; lr: 0.0001; loss: 20.86885; btime(ms): 1337; eta: 19:17:33; peak_mem(M): 6616;
INFO 2022-05-23 23:48:07,959 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 88400; lr: 0.0001; loss: 19.87926; btime(ms): 1337; eta: 19:13:11; peak_mem(M): 6616;
INFO 2022-05-23 23:52:38,386 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 88600; lr: 0.0001; loss: 20.6603; btime(ms): 1337; eta: 19:08:47; peak_mem(M): 6616;
INFO 2022-05-23 23:57:11,140 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 88800; lr: 0.0001; loss: 20.96746; btime(ms): 1337; eta: 19:04:26; peak_mem(M): 6616;
INFO 2022-05-24 00:01:46,570 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 89000; lr: 0.0001; loss: 20.42079; btime(ms): 1337; eta: 19:00:09; peak_mem(M): 6616;
INFO 2022-05-24 00:06:16,076 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 89200; lr: 0.0001; loss: 20.59101; btime(ms): 1337; eta: 18:55:44; peak_mem(M): 6616;
INFO 2022-05-24 00:10:48,759 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 89400; lr: 0.0001; loss: 20.06223; btime(ms): 1337; eta: 18:51:17; peak_mem(M): 6616;
INFO 2022-05-24 00:15:39,244 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 89600; lr: 0.0001; loss: 20.13715; btime(ms): 1338; eta: 18:47:18; peak_mem(M): 6616;
INFO 2022-05-24 00:20:25,965 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 89800; lr: 0.0001; loss: 20.41229; btime(ms): 1338; eta: 18:43:14; peak_mem(M): 6616;
INFO 2022-05-24 00:25:13,493 log_hooks.py: 277: Rank: 0; [ep: 17] iter: 90000; lr: 0.0001; loss: 20.22792; btime(ms): 1339; eta: 18:39:10; peak_mem(M): 6616;
INFO 2022-05-24 00:27:16,922 trainer_main.py: 214: Meters synced
INFO 2022-05-24 00:27:16,926 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1374
INFO 2022-05-24 00:27:16,926 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1014.86 ms 1012.98 ms
             forward:   11.01 ms  214.55 ms
        loss_compute:    1.16 ms    1.15 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  132.67 ms  132.79 ms
            backward:    3.55 ms    6.15 ms
      optimizer_step:    1.45 ms    3.69 ms
    train_step_total: 1374.07 ms 1374.30 ms
INFO 2022-05-24 00:27:16,927 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.3069, 'res2': 20.180799999999998, 'res3': 29.442200000000003, 'res4': 39.0122, 'res5': 35.2457}, 'top_5': {'conv1': 17.3205, 'res2': 37.174, 'res3': 48.9899, 'res4': 59.9093, 'res5': 56.5662}}
INFO 2022-05-24 00:27:16,928 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 00:27:16,931 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 00:27:16,932 log_hooks.py: 425: [phase: 17] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 00:27:18,270 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase17.torch
INFO 2022-05-24 00:27:18,271 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 00:27:18,272 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 00:27:18,274 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 35, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 00:27:57,119 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 00:27:57,119 state_update_hooks.py: 115: Starting phase 35 [test]
INFO 2022-05-24 00:33:14,558 trainer_main.py: 214: Meters synced
INFO 2022-05-24 00:33:14,562 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1619
INFO 2022-05-24 00:33:14,563 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.12, 'res2': 24.686, 'res3': 34.188, 'res4': 42.577999999999996, 'res5': 36.708}, 'top_5': {'conv1': 22.228, 'res2': 43.678, 'res3': 55.704, 'res4': 65.036, 'res5': 59.19799999999999}}
INFO 2022-05-24 00:33:14,563 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 00:33:14,567 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 00:33:14,568 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 36, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 00:33:57,036 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 00:33:57,037 state_update_hooks.py: 115: Starting phase 36 [train]
INFO 2022-05-24 00:36:36,410 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 90200; lr: 0.0001; loss: 19.68955; btime(ms): 1342; eta: 18:37:49; peak_mem(M): 6616;
INFO 2022-05-24 00:41:27,264 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 90400; lr: 0.0001; loss: 21.61942; btime(ms): 1343; eta: 18:33:46; peak_mem(M): 6616;
INFO 2022-05-24 00:45:54,310 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 90600; lr: 0.0001; loss: 20.5091; btime(ms): 1343; eta: 18:29:16; peak_mem(M): 6616;
INFO 2022-05-24 00:50:28,512 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 90800; lr: 0.0001; loss: 20.33483; btime(ms): 1343; eta: 18:24:53; peak_mem(M): 6616;
INFO 2022-05-24 00:55:00,695 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 91000; lr: 0.0001; loss: 20.09023; btime(ms): 1343; eta: 18:20:29; peak_mem(M): 6616;
INFO 2022-05-24 00:59:35,191 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 91200; lr: 0.0001; loss: 21.03633; btime(ms): 1343; eta: 18:16:06; peak_mem(M): 6616;
INFO 2022-05-24 01:04:12,453 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 91400; lr: 0.0001; loss: 19.65993; btime(ms): 1344; eta: 18:11:47; peak_mem(M): 6616;
INFO 2022-05-24 01:08:44,229 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 91600; lr: 0.0001; loss: 21.8806; btime(ms): 1344; eta: 18:07:22; peak_mem(M): 6616;
INFO 2022-05-24 01:13:16,126 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 91800; lr: 0.0001; loss: 20.70983; btime(ms): 1344; eta: 18:02:56; peak_mem(M): 6616;
INFO 2022-05-24 01:17:47,404 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 92000; lr: 0.0001; loss: 21.28326; btime(ms): 1344; eta: 17:58:30; peak_mem(M): 6616;
INFO 2022-05-24 01:22:17,906 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 92200; lr: 0.0001; loss: 20.16238; btime(ms): 1344; eta: 17:54:03; peak_mem(M): 6616;
INFO 2022-05-24 01:26:51,039 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 92400; lr: 0.0001; loss: 19.56215; btime(ms): 1344; eta: 17:49:39; peak_mem(M): 6616;
INFO 2022-05-24 01:31:25,579 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 92600; lr: 0.0001; loss: 19.58499; btime(ms): 1344; eta: 17:45:16; peak_mem(M): 6616;
INFO 2022-05-24 01:35:56,868 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 92800; lr: 0.0001; loss: 20.82285; btime(ms): 1344; eta: 17:40:50; peak_mem(M): 6616;
INFO 2022-05-24 01:40:27,790 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 93000; lr: 0.0001; loss: 21.22427; btime(ms): 1344; eta: 17:36:23; peak_mem(M): 6616;
INFO 2022-05-24 01:45:00,081 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 93200; lr: 0.0001; loss: 20.62745; btime(ms): 1344; eta: 17:31:58; peak_mem(M): 6616;
INFO 2022-05-24 01:49:36,378 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 93400; lr: 0.0001; loss: 21.54748; btime(ms): 1344; eta: 17:27:36; peak_mem(M): 6616;
INFO 2022-05-24 01:54:09,377 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 93600; lr: 0.0001; loss: 21.13202; btime(ms): 1344; eta: 17:23:11; peak_mem(M): 6616;
INFO 2022-05-24 01:58:39,880 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 93800; lr: 0.0001; loss: 20.11711; btime(ms): 1344; eta: 17:18:44; peak_mem(M): 6616;
INFO 2022-05-24 02:03:12,984 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 94000; lr: 0.0001; loss: 21.28189; btime(ms): 1345; eta: 17:14:19; peak_mem(M): 6616;
INFO 2022-05-24 02:07:46,563 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 94200; lr: 0.0001; loss: 20.56134; btime(ms): 1345; eta: 17:09:55; peak_mem(M): 6616;
INFO 2022-05-24 02:12:23,488 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 94400; lr: 0.0001; loss: 20.59904; btime(ms): 1345; eta: 17:05:34; peak_mem(M): 6616;
INFO 2022-05-24 02:16:53,498 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 94600; lr: 0.0001; loss: 21.69065; btime(ms): 1345; eta: 17:01:06; peak_mem(M): 6616;
INFO 2022-05-24 02:21:23,232 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 94800; lr: 0.0001; loss: 20.17984; btime(ms): 1345; eta: 16:56:37; peak_mem(M): 6616;
INFO 2022-05-24 02:25:55,209 log_hooks.py: 277: Rank: 0; [ep: 18] iter: 95000; lr: 0.0001; loss: 21.39213; btime(ms): 1345; eta: 16:52:11; peak_mem(M): 6616;
INFO 2022-05-24 02:27:56,665 trainer_main.py: 214: Meters synced
INFO 2022-05-24 02:27:56,669 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1366
INFO 2022-05-24 02:27:56,670 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1008.85 ms 1006.97 ms
             forward:   11.03 ms  214.48 ms
        loss_compute:    1.16 ms    1.15 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  131.05 ms  131.18 ms
            backward:    3.42 ms    6.04 ms
      optimizer_step:    1.46 ms    3.71 ms
    train_step_total: 1366.36 ms 1366.58 ms
INFO 2022-05-24 02:27:56,671 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.3808, 'res2': 20.2877, 'res3': 29.487000000000002, 'res4': 39.0417, 'res5': 35.2669}, 'top_5': {'conv1': 17.3629, 'res2': 37.2044, 'res3': 49.0383, 'res4': 59.8935, 'res5': 56.5817}}
INFO 2022-05-24 02:27:56,672 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 02:27:56,675 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 02:27:56,675 log_hooks.py: 425: [phase: 18] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 02:27:58,040 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase18.torch
INFO 2022-05-24 02:27:58,041 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 02:27:58,044 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 02:27:58,045 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 37, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 02:28:37,176 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 02:28:37,177 state_update_hooks.py: 115: Starting phase 37 [test]
INFO 2022-05-24 02:33:38,333 trainer_main.py: 214: Meters synced
INFO 2022-05-24 02:33:38,337 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1536
INFO 2022-05-24 02:33:38,338 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.204, 'res2': 24.808, 'res3': 34.202, 'res4': 42.608000000000004, 'res5': 36.846000000000004}, 'top_5': {'conv1': 22.34, 'res2': 43.794, 'res3': 55.652, 'res4': 65.024, 'res5': 59.206}}
INFO 2022-05-24 02:33:38,339 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 02:33:38,341 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 02:33:38,342 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 38, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 02:34:20,410 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 02:34:20,411 state_update_hooks.py: 115: Starting phase 38 [train]
INFO 2022-05-24 02:36:44,833 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 95200; lr: 0.0001; loss: 20.56831; btime(ms): 1347; eta: 16:49:33; peak_mem(M): 6616;
INFO 2022-05-24 02:41:18,622 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 95400; lr: 0.0001; loss: 20.70229; btime(ms): 1347; eta: 16:45:08; peak_mem(M): 6616;
INFO 2022-05-24 02:45:49,763 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 95600; lr: 0.0001; loss: 19.70783; btime(ms): 1348; eta: 16:40:39; peak_mem(M): 6616;
INFO 2022-05-24 02:50:24,500 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 95800; lr: 0.0001; loss: 21.24093; btime(ms): 1348; eta: 16:36:15; peak_mem(M): 6616;
INFO 2022-05-24 02:54:56,570 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 96000; lr: 0.0001; loss: 21.23863; btime(ms): 1348; eta: 16:31:47; peak_mem(M): 6616;
INFO 2022-05-24 02:59:25,187 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 96200; lr: 0.0001; loss: 21.27394; btime(ms): 1348; eta: 16:27:17; peak_mem(M): 6616;
INFO 2022-05-24 03:03:51,847 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 96400; lr: 0.0001; loss: 20.28004; btime(ms): 1348; eta: 16:22:44; peak_mem(M): 6616;
INFO 2022-05-24 03:08:21,802 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 96600; lr: 0.0001; loss: 20.43745; btime(ms): 1348; eta: 16:18:15; peak_mem(M): 6616;
INFO 2022-05-24 03:12:48,772 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 96800; lr: 0.0001; loss: 20.83506; btime(ms): 1348; eta: 16:13:43; peak_mem(M): 6616;
INFO 2022-05-24 03:17:19,306 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 97000; lr: 0.0001; loss: 20.89308; btime(ms): 1348; eta: 16:09:14; peak_mem(M): 6616;
INFO 2022-05-24 03:21:46,160 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 97200; lr: 0.0001; loss: 20.73562; btime(ms): 1347; eta: 16:04:42; peak_mem(M): 6616;
INFO 2022-05-24 03:26:16,446 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 97400; lr: 0.0001; loss: 19.36458; btime(ms): 1348; eta: 16:00:13; peak_mem(M): 6616;
INFO 2022-05-24 03:30:44,265 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 97600; lr: 0.0001; loss: 19.99861; btime(ms): 1347; eta: 15:55:42; peak_mem(M): 6616;
INFO 2022-05-24 03:35:11,542 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 97800; lr: 0.0001; loss: 20.5333; btime(ms): 1347; eta: 15:51:08; peak_mem(M): 6616;
INFO 2022-05-24 03:39:39,140 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 98000; lr: 0.0001; loss: 20.60514; btime(ms): 1347; eta: 15:46:37; peak_mem(M): 6616;
INFO 2022-05-24 03:44:09,663 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 98200; lr: 0.0001; loss: 20.30949; btime(ms): 1347; eta: 15:42:07; peak_mem(M): 6616;
INFO 2022-05-24 03:48:41,324 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 98400; lr: 0.0001; loss: 21.05265; btime(ms): 1347; eta: 15:37:39; peak_mem(M): 6616;
INFO 2022-05-24 03:53:13,140 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 98600; lr: 0.0001; loss: 20.38691; btime(ms): 1347; eta: 15:33:11; peak_mem(M): 6616;
INFO 2022-05-24 03:57:53,434 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 98800; lr: 0.0001; loss: 20.81524; btime(ms): 1348; eta: 15:28:51; peak_mem(M): 6616;
INFO 2022-05-24 04:02:36,636 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 99000; lr: 0.0001; loss: 20.9322; btime(ms): 1348; eta: 15:24:32; peak_mem(M): 6616;
INFO 2022-05-24 04:07:25,215 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 99200; lr: 0.0001; loss: 21.02787; btime(ms): 1348; eta: 15:20:18; peak_mem(M): 6616;
INFO 2022-05-24 04:12:10,003 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 99400; lr: 0.0001; loss: 21.01042; btime(ms): 1349; eta: 15:16:00; peak_mem(M): 6616;
INFO 2022-05-24 04:16:36,119 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 99600; lr: 0.0001; loss: 20.99056; btime(ms): 1348; eta: 15:11:26; peak_mem(M): 6616;
INFO 2022-05-24 04:21:39,108 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 99800; lr: 0.0001; loss: 20.40904; btime(ms): 1349; eta: 15:07:23; peak_mem(M): 6616;
INFO 2022-05-24 04:26:39,473 log_hooks.py: 277: Rank: 0; [ep: 19] iter: 100000; lr: 0.0001; loss: 19.71343; btime(ms): 1350; eta: 15:03:16; peak_mem(M): 6616;
INFO 2022-05-24 04:29:01,091 trainer_main.py: 214: Meters synced
INFO 2022-05-24 04:29:01,093 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1374
INFO 2022-05-24 04:29:01,094 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1016.32 ms 1014.53 ms
             forward:   11.07 ms  214.53 ms
        loss_compute:    1.17 ms    1.16 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  131.56 ms  131.67 ms
            backward:    3.44 ms    6.06 ms
      optimizer_step:    1.47 ms    3.73 ms
    train_step_total: 1374.56 ms 1374.78 ms
INFO 2022-05-24 04:29:01,095 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.363599999999999, 'res2': 20.3514, 'res3': 29.5254, 'res4': 39.1116, 'res5': 35.2772}, 'top_5': {'conv1': 17.4165, 'res2': 37.302600000000005, 'res3': 49.071999999999996, 'res4': 59.9686, 'res5': 56.5875}}
INFO 2022-05-24 04:29:01,096 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 04:29:01,103 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 04:29:01,104 log_hooks.py: 425: [phase: 19] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 04:29:02,579 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase19.torch
INFO 2022-05-24 04:29:02,579 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 04:29:02,586 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 04:29:02,587 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 39, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 04:30:08,847 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 04:30:08,848 state_update_hooks.py: 115: Starting phase 39 [test]
INFO 2022-05-24 04:35:30,223 trainer_main.py: 214: Meters synced
INFO 2022-05-24 04:35:30,232 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1639
INFO 2022-05-24 04:35:30,234 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.181999999999999, 'res2': 24.796000000000003, 'res3': 34.254, 'res4': 42.61, 'res5': 36.83}, 'top_5': {'conv1': 22.306, 'res2': 43.742, 'res3': 55.618, 'res4': 64.946, 'res5': 59.221999999999994}}
INFO 2022-05-24 04:35:30,234 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 04:35:30,241 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 04:35:30,242 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 40, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 04:36:47,235 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 04:36:47,236 state_update_hooks.py: 115: Starting phase 40 [train]
INFO 2022-05-24 04:39:14,053 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 100200; lr: 0.0001; loss: 20.18343; btime(ms): 1354; eta: 15:01:37; peak_mem(M): 6616;
INFO 2022-05-24 04:44:08,515 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 100400; lr: 0.0001; loss: 21.00324; btime(ms): 1354; eta: 14:57:21; peak_mem(M): 6616;
INFO 2022-05-24 04:48:58,091 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 100600; lr: 0.0001; loss: 20.75418; btime(ms): 1355; eta: 14:53:05; peak_mem(M): 6616;
INFO 2022-05-24 04:53:49,887 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 100800; lr: 0.0001; loss: 20.51488; btime(ms): 1355; eta: 14:48:49; peak_mem(M): 6616;
INFO 2022-05-24 04:58:43,302 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 101000; lr: 0.0001; loss: 20.11089; btime(ms): 1356; eta: 14:44:34; peak_mem(M): 6616;
INFO 2022-05-24 05:03:36,379 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 101200; lr: 0.0001; loss: 20.07714; btime(ms): 1356; eta: 14:40:18; peak_mem(M): 6616;
INFO 2022-05-24 05:08:24,490 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 101400; lr: 0.0001; loss: 19.31704; btime(ms): 1356; eta: 14:36:00; peak_mem(M): 6616;
INFO 2022-05-24 05:13:13,503 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 101600; lr: 0.0001; loss: 20.49261; btime(ms): 1357; eta: 14:31:41; peak_mem(M): 6616;
INFO 2022-05-24 05:18:05,469 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 101800; lr: 0.0001; loss: 20.86316; btime(ms): 1357; eta: 14:27:25; peak_mem(M): 6616;
INFO 2022-05-24 05:22:56,208 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 102000; lr: 0.0001; loss: 21.44488; btime(ms): 1357; eta: 14:23:07; peak_mem(M): 6616;
INFO 2022-05-24 05:27:48,007 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 102200; lr: 0.0001; loss: 20.08269; btime(ms): 1358; eta: 14:18:49; peak_mem(M): 6616;
INFO 2022-05-24 05:32:34,966 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 102400; lr: 0.0001; loss: 20.86269; btime(ms): 1358; eta: 14:14:30; peak_mem(M): 6616;
INFO 2022-05-24 05:37:30,783 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 102600; lr: 0.0001; loss: 20.81178; btime(ms): 1358; eta: 14:10:13; peak_mem(M): 6616;
INFO 2022-05-24 05:42:23,345 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 102800; lr: 0.0001; loss: 20.21668; btime(ms): 1359; eta: 14:05:54; peak_mem(M): 6616;
INFO 2022-05-24 05:47:13,529 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 103000; lr: 0.0001; loss: 19.72697; btime(ms): 1359; eta: 14:01:35; peak_mem(M): 6616;
INFO 2022-05-24 05:52:04,223 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 103200; lr: 0.0001; loss: 20.87499; btime(ms): 1359; eta: 13:57:17; peak_mem(M): 6616;
INFO 2022-05-24 05:56:51,243 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 103400; lr: 0.0001; loss: 20.28716; btime(ms): 1360; eta: 13:52:56; peak_mem(M): 6616;
INFO 2022-05-24 06:01:41,600 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 103600; lr: 0.0001; loss: 21.04577; btime(ms): 1360; eta: 13:48:37; peak_mem(M): 6616;
INFO 2022-05-24 06:06:33,829 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 103800; lr: 0.0001; loss: 20.27979; btime(ms): 1360; eta: 13:44:17; peak_mem(M): 6616;
INFO 2022-05-24 06:11:26,236 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 104000; lr: 0.0001; loss: 20.93838; btime(ms): 1361; eta: 13:39:59; peak_mem(M): 6616;
INFO 2022-05-24 06:16:16,520 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 104200; lr: 0.0001; loss: 19.78029; btime(ms): 1361; eta: 13:35:38; peak_mem(M): 6616;
INFO 2022-05-24 06:21:09,044 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 104400; lr: 0.0001; loss: 20.97771; btime(ms): 1362; eta: 13:31:18; peak_mem(M): 6616;
INFO 2022-05-24 06:26:02,121 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 104600; lr: 0.0001; loss: 20.48959; btime(ms): 1362; eta: 13:26:59; peak_mem(M): 6616;
INFO 2022-05-24 06:30:53,472 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 104800; lr: 0.0001; loss: 21.24805; btime(ms): 1362; eta: 13:22:38; peak_mem(M): 6616;
INFO 2022-05-24 06:35:42,775 log_hooks.py: 277: Rank: 0; [ep: 20] iter: 105000; lr: 0.0001; loss: 19.37178; btime(ms): 1363; eta: 13:18:16; peak_mem(M): 6616;
INFO 2022-05-24 06:38:11,171 trainer_main.py: 214: Meters synced
INFO 2022-05-24 06:38:11,174 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1455
INFO 2022-05-24 06:38:11,175 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1074.37 ms 1072.47 ms
             forward:   11.69 ms  214.58 ms
        loss_compute:    1.22 ms    1.21 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:  153.42 ms  153.59 ms
            backward:    3.75 ms    6.32 ms
      optimizer_step:    1.52 ms    3.69 ms
    train_step_total: 1455.13 ms 1455.36 ms
INFO 2022-05-24 06:38:11,176 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.4343, 'res2': 20.372899999999998, 'res3': 29.5381, 'res4': 39.0659, 'res5': 35.2779}, 'top_5': {'conv1': 17.4847, 'res2': 37.3164, 'res3': 49.0801, 'res4': 59.993300000000005, 'res5': 56.6338}}
INFO 2022-05-24 06:38:11,177 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 06:38:11,185 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 06:38:11,186 log_hooks.py: 425: [phase: 20] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 06:38:12,580 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase20.torch
INFO 2022-05-24 06:38:12,580 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 06:38:12,589 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 06:38:12,591 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 41, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 06:39:27,389 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 06:39:27,390 state_update_hooks.py: 115: Starting phase 41 [test]
INFO 2022-05-24 06:44:47,341 trainer_main.py: 214: Meters synced
INFO 2022-05-24 06:44:47,346 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1632
INFO 2022-05-24 06:44:47,347 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.228, 'res2': 24.895999999999997, 'res3': 34.202, 'res4': 42.546, 'res5': 36.812}, 'top_5': {'conv1': 22.392, 'res2': 43.714, 'res3': 55.662, 'res4': 65.046, 'res5': 59.228}}
INFO 2022-05-24 06:44:47,348 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 06:44:47,353 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 06:44:47,354 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 42, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 06:46:04,550 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 06:46:04,550 state_update_hooks.py: 115: Starting phase 42 [train]
INFO 2022-05-24 06:48:23,500 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 105200; lr: 0.0001; loss: 20.61487; btime(ms): 1366; eta: 13:15:56; peak_mem(M): 6616;
INFO 2022-05-24 06:53:15,539 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 105400; lr: 0.0001; loss: 20.7028; btime(ms): 1367; eta: 13:11:33; peak_mem(M): 6616;
INFO 2022-05-24 06:58:06,022 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 105600; lr: 0.0001; loss: 20.60254; btime(ms): 1367; eta: 13:07:09; peak_mem(M): 6616;
INFO 2022-05-24 07:02:57,331 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 105800; lr: 0.0001; loss: 21.60553; btime(ms): 1367; eta: 13:02:46; peak_mem(M): 6616;
INFO 2022-05-24 07:07:46,445 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 106000; lr: 0.0001; loss: 21.10439; btime(ms): 1367; eta: 12:58:22; peak_mem(M): 6616;
INFO 2022-05-24 07:12:36,953 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 106200; lr: 0.0001; loss: 19.47812; btime(ms): 1368; eta: 12:53:58; peak_mem(M): 6616;
INFO 2022-05-24 07:17:27,915 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 106400; lr: 0.0001; loss: 20.23693; btime(ms): 1368; eta: 12:49:34; peak_mem(M): 6616;
INFO 2022-05-24 07:22:15,361 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 106600; lr: 0.0001; loss: 20.62428; btime(ms): 1368; eta: 12:45:09; peak_mem(M): 6616;
INFO 2022-05-24 07:27:06,105 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 106800; lr: 0.0001; loss: 20.54905; btime(ms): 1369; eta: 12:40:45; peak_mem(M): 6616;
INFO 2022-05-24 07:31:54,834 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 107000; lr: 0.0001; loss: 20.19031; btime(ms): 1369; eta: 12:36:20; peak_mem(M): 6616;
INFO 2022-05-24 07:36:43,568 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 107200; lr: 0.0001; loss: 20.45182; btime(ms): 1369; eta: 12:31:56; peak_mem(M): 6616;
INFO 2022-05-24 07:41:38,675 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 107400; lr: 0.0001; loss: 21.29376; btime(ms): 1370; eta: 12:27:34; peak_mem(M): 6616;
INFO 2022-05-24 07:46:31,612 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 107600; lr: 0.0001; loss: 19.40195; btime(ms): 1370; eta: 12:23:09; peak_mem(M): 6616;
INFO 2022-05-24 07:51:24,046 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 107800; lr: 0.0001; loss: 21.27014; btime(ms): 1370; eta: 12:18:46; peak_mem(M): 6616;
INFO 2022-05-24 07:56:21,282 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 108000; lr: 0.0001; loss: 20.54812; btime(ms): 1371; eta: 12:14:24; peak_mem(M): 6616;
INFO 2022-05-24 08:01:15,237 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 108200; lr: 0.0001; loss: 20.82805; btime(ms): 1371; eta: 12:10:00; peak_mem(M): 6616;
INFO 2022-05-24 08:06:07,503 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 108400; lr: 0.0001; loss: 20.52392; btime(ms): 1371; eta: 12:05:35; peak_mem(M): 6616;
INFO 2022-05-24 08:10:58,733 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 108600; lr: 0.0001; loss: 21.29725; btime(ms): 1371; eta: 12:01:10; peak_mem(M): 6616;
INFO 2022-05-24 08:15:50,465 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 108800; lr: 0.0001; loss: 22.08811; btime(ms): 1372; eta: 11:56:44; peak_mem(M): 6616;
INFO 2022-05-24 08:20:42,887 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 109000; lr: 0.0001; loss: 20.19672; btime(ms): 1372; eta: 11:52:19; peak_mem(M): 6616;
INFO 2022-05-24 08:25:15,205 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 109200; lr: 0.0001; loss: 20.33133; btime(ms): 1372; eta: 11:47:43; peak_mem(M): 6616;
INFO 2022-05-24 08:29:38,840 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 109400; lr: 0.0001; loss: 21.08003; btime(ms): 1372; eta: 11:43:03; peak_mem(M): 6616;
INFO 2022-05-24 08:33:53,602 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 109600; lr: 0.0001; loss: 21.81553; btime(ms): 1371; eta: 11:38:19; peak_mem(M): 6616;
INFO 2022-05-24 08:38:07,653 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 109800; lr: 0.0001; loss: 21.20283; btime(ms): 1371; eta: 11:33:35; peak_mem(M): 6616;
INFO 2022-05-24 08:42:23,196 log_hooks.py: 277: Rank: 0; [ep: 21] iter: 110000; lr: 0.0001; loss: 19.44774; btime(ms): 1371; eta: 11:28:52; peak_mem(M): 6616;
INFO 2022-05-24 08:44:38,856 trainer_main.py: 214: Meters synced
INFO 2022-05-24 08:44:38,859 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1421
INFO 2022-05-24 08:44:38,860 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample: 1048.41 ms 1046.68 ms
             forward:   11.41 ms  214.55 ms
        loss_compute:    1.20 ms    1.19 ms
     loss_all_reduce:    0.10 ms    0.11 ms
       meters_update:  145.74 ms  145.87 ms
            backward:    3.48 ms    6.08 ms
      optimizer_step:    1.50 ms    3.74 ms
    train_step_total: 1421.24 ms 1421.46 ms
INFO 2022-05-24 08:44:38,861 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.4215, 'res2': 20.438200000000002, 'res3': 29.6039, 'res4': 39.177499999999995, 'res5': 35.3258}, 'top_5': {'conv1': 17.5131, 'res2': 37.3838, 'res3': 49.134699999999995, 'res4': 60.0228, 'res5': 56.6995}}
INFO 2022-05-24 08:44:38,861 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 08:44:38,866 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 08:44:38,867 log_hooks.py: 425: [phase: 21] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 08:44:40,197 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase21.torch
INFO 2022-05-24 08:44:40,198 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 08:44:40,202 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 08:44:40,203 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 43, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 08:45:27,114 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 08:45:27,114 state_update_hooks.py: 115: Starting phase 43 [test]
INFO 2022-05-24 08:50:07,275 trainer_main.py: 214: Meters synced
INFO 2022-05-24 08:50:07,279 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1429
INFO 2022-05-24 08:50:07,279 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.252, 'res2': 24.86, 'res3': 34.39, 'res4': 42.68, 'res5': 36.903999999999996}, 'top_5': {'conv1': 22.386, 'res2': 43.846000000000004, 'res3': 55.716, 'res4': 65.12, 'res5': 59.238}}
INFO 2022-05-24 08:50:07,280 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 08:50:07,283 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 08:50:07,284 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 44, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 08:50:57,761 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 08:50:57,762 state_update_hooks.py: 115: Starting phase 44 [train]
INFO 2022-05-24 08:52:53,726 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 110200; lr: 0.0001; loss: 21.44338; btime(ms): 1372; eta: 11:24:59; peak_mem(M): 6616;
INFO 2022-05-24 12:55:57,049 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2022-05-24 12:55:57,049 env.py:  50: ARCH:	x86_64
INFO 2022-05-24 12:55:57,050 env.py:  50: BASH_ENV:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/init/bash
INFO 2022-05-24 12:55:57,050 env.py:  50: BASH_FUNC_ml%%:	() {  eval $($LMOD_DIR/ml_cmd "$@")
}
INFO 2022-05-24 12:55:57,050 env.py:  50: BASH_FUNC_module%%:	() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
INFO 2022-05-24 12:55:57,051 env.py:  50: CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64
INFO 2022-05-24 12:55:57,051 env.py:  50: CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0
INFO 2022-05-24 12:55:57,051 env.py:  50: COLUMNS:	214
INFO 2022-05-24 12:55:57,052 env.py:  50: CONDA_ACTIVATE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/etc/profile.d/conda.sh
INFO 2022-05-24 12:55:57,052 env.py:  50: CONDA_DEFAULT_ENV:	vissl_env
INFO 2022-05-24 12:55:57,052 env.py:  50: CONDA_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/conda
INFO 2022-05-24 12:55:57,052 env.py:  50: CONDA_PREFIX:	/home/mila/r/rajkuman/.conda/envs/vissl_env
INFO 2022-05-24 12:55:57,053 env.py:  50: CONDA_PROMPT_MODIFIER:	(vissl_env) 
INFO 2022-05-24 12:55:57,053 env.py:  50: CONDA_PYTHON_EXE:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin/python
INFO 2022-05-24 12:55:57,053 env.py:  50: CONDA_SHLVL:	1
INFO 2022-05-24 12:55:57,054 env.py:  50: CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include
INFO 2022-05-24 12:55:57,054 env.py:  50: CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3
INFO 2022-05-24 12:55:57,054 env.py:  50: CUDA_VISIBLE_DEVICES:	0
INFO 2022-05-24 12:55:57,054 env.py:  50: ENVIRONMENT:	BATCH
INFO 2022-05-24 12:55:57,055 env.py:  50: GPU_DEVICE_ORDINAL:	0
INFO 2022-05-24 12:55:57,055 env.py:  50: HOME:	/home/mila/r/rajkuman
INFO 2022-05-24 12:55:57,055 env.py:  50: HOSTNAME:	cn-b001
INFO 2022-05-24 12:55:57,056 env.py:  50: ID:	debian
INFO 2022-05-24 12:55:57,056 env.py:  50: JPY_API_TOKEN:	8c1c30b4d324453fb9311087ea0b0013
INFO 2022-05-24 12:55:57,056 env.py:  50: JUPYTERHUB_ACTIVITY_URL:	http://172.16.2.123:8081/hub/api/users/rajkuman/activity
INFO 2022-05-24 12:55:57,057 env.py:  50: JUPYTERHUB_API_TOKEN:	8c1c30b4d324453fb9311087ea0b0013
INFO 2022-05-24 12:55:57,057 env.py:  50: JUPYTERHUB_API_URL:	http://172.16.2.123:8081/hub/api
INFO 2022-05-24 12:55:57,057 env.py:  50: JUPYTERHUB_BASE_URL:	/
INFO 2022-05-24 12:55:57,058 env.py:  50: JUPYTERHUB_CLIENT_ID:	jupyterhub-user-rajkuman
INFO 2022-05-24 12:55:57,058 env.py:  50: JUPYTERHUB_HOST:	
INFO 2022-05-24 12:55:57,058 env.py:  50: JUPYTERHUB_OAUTH_CALLBACK_URL:	/user/rajkuman/oauth_callback
INFO 2022-05-24 12:55:57,058 env.py:  50: JUPYTERHUB_SERVER_NAME:	
INFO 2022-05-24 12:55:57,059 env.py:  50: JUPYTERHUB_SERVICE_PREFIX:	/user/rajkuman/
INFO 2022-05-24 12:55:57,059 env.py:  50: JUPYTERHUB_USER:	rajkuman
INFO 2022-05-24 12:55:57,059 env.py:  50: JUPYTER_SERVER_ROOT:	/home/mila/r/rajkuman
INFO 2022-05-24 12:55:57,060 env.py:  50: JUPYTER_SERVER_URL:	http://0.0.0.0:57809/user/rajkuman/
INFO 2022-05-24 12:55:57,060 env.py:  50: KERNEL_LAUNCH_TIMEOUT:	40
INFO 2022-05-24 12:55:57,060 env.py:  50: LANG:	en_US.UTF-8
INFO 2022-05-24 12:55:57,061 env.py:  50: LESSCLOSE:	/bin/lesspipe %s %s
INFO 2022-05-24 12:55:57,061 env.py:  50: LESSOPEN:	| /bin/lesspipe %s
INFO 2022-05-24 12:55:57,061 env.py:  50: LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib
INFO 2022-05-24 12:55:57,061 env.py:  50: LINES:	50
INFO 2022-05-24 12:55:57,062 env.py:  50: LMOD_CMD:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec/lmod
INFO 2022-05-24 12:55:57,062 env.py:  50: LMOD_DIR:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/libexec
INFO 2022-05-24 12:55:57,062 env.py:  50: LMOD_PACKAGE_PATH:	/cvmfs/config.mila.quebec/etc/lmod/
INFO 2022-05-24 12:55:57,063 env.py:  50: LMOD_PKG:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-24 12:55:57,063 env.py:  50: LMOD_ROOT:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod
INFO 2022-05-24 12:55:57,063 env.py:  50: LMOD_SETTARG_FULL_SUPPORT:	no
INFO 2022-05-24 12:55:57,064 env.py:  50: LMOD_SYSTEM_DEFAULT_MODULES:	Mila:gcc/7.4.0
INFO 2022-05-24 12:55:57,064 env.py:  50: LMOD_VERSION:	8.3.17
INFO 2022-05-24 12:55:57,064 env.py:  50: LMOD_sys:	Linux
INFO 2022-05-24 12:55:57,064 env.py:  50: LOADEDMODULES:	Mila:gcc/7.4.0:anaconda/3
INFO 2022-05-24 12:55:57,065 env.py:  50: LOCAL_RANK:	0
INFO 2022-05-24 12:55:57,065 env.py:  50: LOGNAME:	rajkuman
INFO 2022-05-24 12:55:57,065 env.py:  50: LS_COLORS:	rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
INFO 2022-05-24 12:55:57,066 env.py:  50: MAIL:	/var/mail/rajkuman
INFO 2022-05-24 12:55:57,066 env.py:  50: MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man::
INFO 2022-05-24 12:55:57,066 env.py:  50: MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:/cvmfs/config.mila.quebec/modules/Compiler:/cvmfs/config.mila.quebec/modules/Environments:/cvmfs/config.mila.quebec/modules/Cuda:/cvmfs/config.mila.quebec/modules/Pytorch:/cvmfs/config.mila.quebec/modules/Tensorflow
INFO 2022-05-24 12:55:57,066 env.py:  50: MODULEPATH_ROOT:	/cvmfs/config.mila.quebec/modules
INFO 2022-05-24 12:55:57,067 env.py:  50: MODULERCFILE:	/cvmfs/config.mila.quebec/etc/lmod/modulerc.lua
INFO 2022-05-24 12:55:57,067 env.py:  50: MODULESHOME:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod
INFO 2022-05-24 12:55:57,067 env.py:  50: OLDPWD:	/home/mila/r/rajkuman
INFO 2022-05-24 12:55:57,068 env.py:  50: PATH:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin:/home/mila/r/rajkuman/.local/bin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/condabin:/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:/opt/slurm/bin:/sbin:/bin:/usr/sbin:/usr/bin
INFO 2022-05-24 12:55:57,068 env.py:  50: PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig
INFO 2022-05-24 12:55:57,068 env.py:  50: PROCESSOR_ARCHITECTURE:	amd64
INFO 2022-05-24 12:55:57,069 env.py:  50: PWD:	/home/mila/r/rajkuman/mina/mphil-vissl
INFO 2022-05-24 12:55:57,069 env.py:  50: PYTHONNOUSERSITE:	True
INFO 2022-05-24 12:55:57,069 env.py:  50: PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7
INFO 2022-05-24 12:55:57,069 env.py:  50: PYXTERM_DIMENSIONS:	80x25
INFO 2022-05-24 12:55:57,070 env.py:  50: RANK:	0
INFO 2022-05-24 12:55:57,070 env.py:  50: ROCR_VISIBLE_DEVICES:	0
INFO 2022-05-24 12:55:57,070 env.py:  50: SACCT_FORMAT:	User,JobID,Jobname,partition,state,time,start,end,elapsed,nnodes,ncpus,reqmem,alloctres,nodelist,workdir
INFO 2022-05-24 12:55:57,070 env.py:  50: SCRATCH:	/network/scratch/r/rajkuman
INFO 2022-05-24 12:55:57,071 env.py:  50: SHELL:	/bin/bash
INFO 2022-05-24 12:55:57,071 env.py:  50: SHLVL:	3
INFO 2022-05-24 12:55:57,071 env.py:  50: SINFO_FORMAT:	%18N %.6D %.11T %.4c %.8z %.6m %.8d %.6w %.22f %80E
INFO 2022-05-24 12:55:57,072 env.py:  50: SLURMD_NODENAME:	cn-b001
INFO 2022-05-24 12:55:57,072 env.py:  50: SLURM_CLUSTER_NAME:	mila
INFO 2022-05-24 12:55:57,072 env.py:  50: SLURM_CONF:	/etc/slurm/slurm.conf
INFO 2022-05-24 12:55:57,072 env.py:  50: SLURM_CPUS_ON_NODE:	4
INFO 2022-05-24 12:55:57,073 env.py:  50: SLURM_CPUS_PER_TASK:	4
INFO 2022-05-24 12:55:57,073 env.py:  50: SLURM_EXPORT_ENV:	PATH,LANG,USER,HOME,SHELL,JUPYTERHUB_API_TOKEN,JPY_API_TOKEN,JUPYTERHUB_CLIENT_ID,JUPYTERHUB_HOST,JUPYTERHUB_OAUTH_CALLBACK_URL,JUPYTERHUB_USER,JUPYTERHUB_SERVER_NAME,JUPYTERHUB_API_URL,JUPYTERHUB_ACTIVITY_URL,JUPYTERHUB_BASE_URL,JUPYTERHUB_SERVICE_PREFIX
INFO 2022-05-24 12:55:57,073 env.py:  50: SLURM_GET_USER_ENV:	1
INFO 2022-05-24 12:55:57,073 env.py:  50: SLURM_GTIDS:	0
INFO 2022-05-24 12:55:57,074 env.py:  50: SLURM_JOBID:	1852577
INFO 2022-05-24 12:55:57,074 env.py:  50: SLURM_JOB_ACCOUNT:	mila
INFO 2022-05-24 12:55:57,074 env.py:  50: SLURM_JOB_CPUS_PER_NODE:	4
INFO 2022-05-24 12:55:57,075 env.py:  50: SLURM_JOB_GID:	1471600619
INFO 2022-05-24 12:55:57,075 env.py:  50: SLURM_JOB_GPUS:	6
INFO 2022-05-24 12:55:57,075 env.py:  50: SLURM_JOB_ID:	1852577
INFO 2022-05-24 12:55:57,075 env.py:  50: SLURM_JOB_NAME:	jupyterhub-rajkuman
INFO 2022-05-24 12:55:57,076 env.py:  50: SLURM_JOB_NODELIST:	cn-b001
INFO 2022-05-24 12:55:57,076 env.py:  50: SLURM_JOB_NUM_NODES:	1
INFO 2022-05-24 12:55:57,076 env.py:  50: SLURM_JOB_PARTITION:	unkillable
INFO 2022-05-24 12:55:57,076 env.py:  50: SLURM_JOB_QOS:	normal
INFO 2022-05-24 12:55:57,077 env.py:  50: SLURM_JOB_UID:	1471600619
INFO 2022-05-24 12:55:57,077 env.py:  50: SLURM_JOB_USER:	rajkuman
INFO 2022-05-24 12:55:57,077 env.py:  50: SLURM_LOCALID:	0
INFO 2022-05-24 12:55:57,078 env.py:  50: SLURM_MEM_PER_NODE:	24000
INFO 2022-05-24 12:55:57,078 env.py:  50: SLURM_NNODES:	1
INFO 2022-05-24 12:55:57,078 env.py:  50: SLURM_NODEID:	0
INFO 2022-05-24 12:55:57,078 env.py:  50: SLURM_NODELIST:	cn-b001
INFO 2022-05-24 12:55:57,079 env.py:  50: SLURM_NODE_ALIASES:	(null)
INFO 2022-05-24 12:55:57,079 env.py:  50: SLURM_NPROCS:	1
INFO 2022-05-24 12:55:57,079 env.py:  50: SLURM_NTASKS:	1
INFO 2022-05-24 12:55:57,080 env.py:  50: SLURM_PRIO_PROCESS:	0
INFO 2022-05-24 12:55:57,080 env.py:  50: SLURM_PROCID:	0
INFO 2022-05-24 12:55:57,080 env.py:  50: SLURM_SUBMIT_DIR:	/var/lib/jupyterhub
INFO 2022-05-24 12:55:57,080 env.py:  50: SLURM_SUBMIT_HOST:	jupyter
INFO 2022-05-24 12:55:57,081 env.py:  50: SLURM_TASKS_PER_NODE:	1
INFO 2022-05-24 12:55:57,081 env.py:  50: SLURM_TASK_PID:	31656
INFO 2022-05-24 12:55:57,081 env.py:  50: SLURM_TMPDIR:	/Tmp/slurm.1852577.0
INFO 2022-05-24 12:55:57,081 env.py:  50: SLURM_TOPOLOGY_ADDR:	cn-b001
INFO 2022-05-24 12:55:57,082 env.py:  50: SLURM_TOPOLOGY_ADDR_PATTERN:	node
INFO 2022-05-24 12:55:57,082 env.py:  50: SLURM_WORKING_CLUSTER:	mila:slurm:6817:9216:109
INFO 2022-05-24 12:55:57,082 env.py:  50: SQUEUE_FORMAT:	%.8i %.8u %.12P %.14j %.3t %16S %.10M %.5D %.4C %.10b %.7m %N (%r) %k
INFO 2022-05-24 12:55:57,083 env.py:  50: S_COLORS:	auto
INFO 2022-05-24 12:55:57,083 env.py:  50: TERM:	xterm
INFO 2022-05-24 12:55:57,083 env.py:  50: TMPDIR:	/tmp
INFO 2022-05-24 12:55:57,083 env.py:  50: USER:	rajkuman
INFO 2022-05-24 12:55:57,084 env.py:  50: WORLD_SIZE:	1
INFO 2022-05-24 12:55:57,084 env.py:  50: XDG_SESSION_ID:	c761
INFO 2022-05-24 12:55:57,084 env.py:  50: _:	/home/mila/r/rajkuman/.conda/envs/vissl_env/bin/python
INFO 2022-05-24 12:55:57,085 env.py:  50: _CE_CONDA:	
INFO 2022-05-24 12:55:57,085 env.py:  50: _CE_M:	
INFO 2022-05-24 12:55:57,085 env.py:  50: _LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua
INFO 2022-05-24 12:55:57,085 env.py:  50: _ModuleTable001_:	X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtNaWxhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL01pbGEubHVhIixbImZ1bGxOYW1lIl09Ik1pbGEiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17bG1vZD17WyJzdGlja3kiXT0xLH0sfSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJNaWxhIix9LGFuYWNvbmRhPXtbImZuIl09Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlL2FuYWNvbmRhLzMubHVhIixbImZ1bGxOYW1lIl09ImFuYWNvbmRh
INFO 2022-05-24 12:55:57,086 env.py:  50: _ModuleTable002_:	LzMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJhbmFjb25kYS8zIix9LGdjYz17WyJmbiJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZS9nY2MvNy40LjAubHVhIixbImZ1bGxOYW1lIl09ImdjYy83LjQuMCIsWyJsb2FkT3JkZXIiXT0yLHByb3BUPXtsbW9kPXtbInN0aWNreSJdPTEsfSx9LFsic3RhY2tEZXB0aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09ImdjYy83LjQuMCIsfSx9LG1wYXRoQT17Ii9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9Db3JlIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Nv
INFO 2022-05-24 12:55:57,086 env.py:  50: _ModuleTable003_:	bXBpbGVyIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50cyIsIi9jdm1mcy9jb25maWcubWlsYS5xdWViZWMvbW9kdWxlcy9DdWRhIiwiL2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL1B5dG9yY2giLCIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfSxbInN5c3RlbUJhc2VNUEFUSCJdPSIvY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29yZTovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ29tcGlsZXI6L2N2bWZzL2NvbmZpZy5taWxhLnF1ZWJlYy9tb2R1bGVzL0Vudmlyb25tZW50czovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvQ3VkYTovY3Zt
INFO 2022-05-24 12:55:57,086 env.py:  50: _ModuleTable004_:	ZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvUHl0b3JjaDovY3ZtZnMvY29uZmlnLm1pbGEucXVlYmVjL21vZHVsZXMvVGVuc29yZmxvdyIsfQ==
INFO 2022-05-24 12:55:57,087 env.py:  50: _ModuleTable_Sz_:	4
INFO 2022-05-24 12:55:57,087 env.py:  50: __Init_Default_Modules:	1
INFO 2022-05-24 12:55:57,087 env.py:  50: __LMOD_REF_COUNT_CMAKE_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1
INFO 2022-05-24 12:55:57,088 env.py:  50: __LMOD_REF_COUNT_CMAKE_PREFIX_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0:1
INFO 2022-05-24 12:55:57,088 env.py:  50: __LMOD_REF_COUNT_CPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/include:1
INFO 2022-05-24 12:55:57,088 env.py:  50: __LMOD_REF_COUNT_CSPYTHONPREFIXES:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3:1
INFO 2022-05-24 12:55:57,088 env.py:  50: __LMOD_REF_COUNT_LIBRARY_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib64:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/lib:1
INFO 2022-05-24 12:55:57,089 env.py:  50: __LMOD_REF_COUNT_LOADEDMODULES:	Mila:1;gcc/7.4.0:1;anaconda/3:1
INFO 2022-05-24 12:55:57,089 env.py:  50: __LMOD_REF_COUNT_MANPATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/gcc/7.4.0/share/man:1;/cvmfs/ai.mila.quebec/apps/x86_64/debian/lmod/lmod/share/man:1
INFO 2022-05-24 12:55:57,089 env.py:  50: __LMOD_REF_COUNT_MODULEPATH:	/cvmfs/config.mila.quebec/modules/Core:1;/cvmfs/config.mila.quebec/modules/Compiler:1;/cvmfs/config.mila.quebec/modules/Environments:1;/cvmfs/config.mila.quebec/modules/Cuda:1;/cvmfs/config.mila.quebec/modules/Pytorch:1;/cvmfs/config.mila.quebec/modules/Tensorflow:1
INFO 2022-05-24 12:55:57,090 env.py:  50: __LMOD_REF_COUNT_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/bin:1;/opt/slurm/bin:1;/sbin:1;/bin:1;/usr/sbin:1;/usr/bin:1
INFO 2022-05-24 12:55:57,090 env.py:  50: __LMOD_REF_COUNT_PKG_CONFIG_PATH:	/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/pkgconfig:1
INFO 2022-05-24 12:55:57,090 env.py:  50: __LMOD_REF_COUNT_PYTHONPATH:	/cvmfs/config.mila.quebec/etc/python.d/3.7:1
INFO 2022-05-24 12:55:57,090 env.py:  50: __LMOD_REF_COUNT__LMFILES_:	/cvmfs/config.mila.quebec/modules/Core/Mila.lua:1;/cvmfs/config.mila.quebec/modules/Core/gcc/7.4.0.lua:1;/cvmfs/config.mila.quebec/modules/Core/anaconda/3.lua:1
INFO 2022-05-24 12:55:57,091 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-24 12:55:57,091 train.py: 105: Setting seed....
INFO 2022-05-24 12:55:57,091 misc.py: 173: MACHINE SEED: 28
INFO 2022-05-24 12:55:57,109 hydra_config.py: 132: Training with config:
INFO 2022-05-24 12:55:57,121 hydra_config.py: 141: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': './checkpoints/after_poison/imagenet',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 4,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 256,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['imagenet1k_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 256,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['imagenet1k_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'CHECK_NAN': True,
           'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 200,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': ['conv1',
                                                    'res2',
                                                    'res3',
                                                    'res4',
                                                    'res5'],
                                    'num_meters': 5,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'model_output_mask': False,
            'name': 'accuracy_list_meter',
            'names': ['accuracy_list_meter'],
            'precision_at_k_list_meter': {'meter_names': [],
                                          'num_meters': 1,
                                          'topk_values': [1]},
            'recall_at_k_list_meter': {'meter_names': [],
                                       'num_meters': 1,
                                       'topk_values': [1]}},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'BASE_MODEL_NAME': 'multi_input_output_model',
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',
                                                                        ['AvgPool2d',
                                                                         [[10,
                                                                           10],
                                                                          10,
                                                                          4]]],
                                                                       ['res2',
                                                                        ['AvgPool2d',
                                                                         [[16,
                                                                           16],
                                                                          8,
                                                                          0]]],
                                                                       ['res3',
                                                                        ['AvgPool2d',
                                                                         [[13,
                                                                           13],
                                                                          5,
                                                                          0]]],
                                                                       ['res4',
                                                                        ['AvgPool2d',
                                                                         [[8,
                                                                           8],
                                                                          3,
                                                                          0]]],
                                                                       ['res5',
                                                                        ['AvgPool2d',
                                                                         [[6,
                                                                           6],
                                                                          1,
                                                                          0]]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 64}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 256}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 512}],
                               ['eval_mlp',
                                {'dims': [9216, 1000], 'in_channels': 1024}],
                               ['eval_mlp',
                                {'dims': [8192, 1000], 'in_channels': 2048}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,
                              'GROUP_SIZE': 8,
                              'SYNC_BN_TYPE': 'apex'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'BLOCK': 'Bottleneck',
                                 'CONV1_KERNEL': 7,
                                 'CONV1_PADDING': 3,
                                 'CONV1_STRIDE': 2,
                                 'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'MAXPOOL': True,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': './checkpoints/poisoned/model_final_checkpoint_phase99.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0005},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 28,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.01,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [8, 16, 24],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.01,
                                                      0.001,
                                                      0.0001,
                                                      1e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.01,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [8, 16, 24],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.01,
                                                           0.001,
                                                           0.0001,
                                                           1e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0005},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2022-05-24 12:55:59,278 train.py: 117: System config:
-------------------  ---------------------------------------------------------------------------------------------------------------
sys.platform         linux
Python               3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                1.19.5
Pillow               9.0.1
vissl                0.1.6 @/home/mila/r/rajkuman/mina/mphil-vissl/vissl
GPU available        True
GPU 0                Tesla V100-SXM2-32GB
CUDA_HOME            None
torchvision          0.9.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torchvision
hydra                1.0.7 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/hydra_core-1.0.7-py3.8.egg/hydra
classy_vision        0.7.0.dev @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/classy_vision
tensorboard          2.9.0
apex                 0.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/apex
PyTorch              1.8.1 @/home/mila/r/rajkuman/.conda/envs/vissl_env/lib/python3.8/site-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ----------------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               80
On-line CPU(s) list  0-79
Thread(s) per core   2
Core(s) per socket   20
Socket(s)            2
NUMA node(s)         2
Vendor ID            GenuineIntel
CPU family           6
Model                85
Model name           Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz
Stepping             7
CPU MHz              800.024
CPU max MHz          3900.0000
CPU min MHz          800.0000
BogoMIPS             4200.00
Virtualization       VT-x
L1d cache            32K
L1i cache            32K
L2 cache             1024K
L3 cache             28160K
NUMA node0 CPU(s)    0-19,40-59
NUMA node1 CPU(s)    20-39,60-79
-------------------  ----------------------------------------
INFO 2022-05-24 12:55:59,282 trainer_main.py: 112: Using Distributed init method: tcp://localhost:53891, world_size: 1, rank: 0
INFO 2022-05-24 12:55:59,287 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2022-05-24 12:55:59,288 trainer_main.py: 130: | initialized host cn-b001 as rank 0 (0)
INFO 2022-05-24 12:56:08,920 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2022-05-24 12:56:08,921 train_task.py: 455: Building model....
INFO 2022-05-24 12:56:08,922 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2022-05-24 12:56:08,922 resnext.py:  66: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2022-05-24 12:56:08,923 resnext.py:  93: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2022-05-24 12:56:09,443 feature_extractor.py:  50: Freezing model trunk...
INFO 2022-05-24 12:56:09,746 model_helpers.py: 178: Using SyncBN group size: 1
INFO 2022-05-24 12:56:09,746 model_helpers.py: 182: Converting BN layers to Apex SyncBN
INFO 2022-05-24 12:56:09,748 distributed_c10d.py: 187: Added key: store_based_barrier_key:2 to store for rank: 0
INFO 2022-05-24 12:56:09,755 train_task.py: 472: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2022-05-24 12:56:09,756 base_ssl_model.py: 195: Freezing model trunk...
INFO 2022-05-24 12:56:09,756 train_task.py: 656: Broadcast model BN buffers from primary on every forward pass
INFO 2022-05-24 12:56:09,757 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2022-05-24 12:56:09,854 optimizer_helper.py: 293: 
Trainable params: 20, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 0, 
Trunk Unregularized Parameters 0, 
Head Regularized Parameters: 10, 
Head Unregularized Parameters: 10 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2022-05-24 12:56:09,855 util.py: 276: Attempting to load checkpoint from ./checkpoints/after_poison/imagenet/model_phase21.torch
INFO 2022-05-24 12:56:10,720 util.py: 281: Loaded checkpoint from ./checkpoints/after_poison/imagenet/model_phase21.torch
INFO 2022-05-24 12:56:10,721 util.py: 240: Broadcasting checkpoint loaded from ./checkpoints/after_poison/imagenet/model_phase21.torch
INFO 2022-05-24 12:56:23,661 ssl_dataset.py: 156: Rank: 0 split: TEST Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-24 12:56:23,662 ssl_dataset.py: 159: Rank: 0 split: TEST Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/val']
INFO 2022-05-24 12:56:24,612 disk_dataset.py:  86: Loaded 50000 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/val
INFO 2022-05-24 12:56:24,613 ssl_dataset.py: 156: Rank: 0 split: TRAIN Data files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-24 12:56:24,613 ssl_dataset.py: 159: Rank: 0 split: TRAIN Label files:
['/network/datasets/imagenet.var/imagenet_torchvision/train']
INFO 2022-05-24 12:56:35,264 disk_dataset.py:  86: Loaded 1281167 samples from folder /network/datasets/imagenet.var/imagenet_torchvision/train
INFO 2022-05-24 12:56:35,265 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-24 12:56:35,265 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-24 12:56:35,266 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 12:56:35,267 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-24 12:56:35,268 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2022-05-24 12:56:35,269 __init__.py: 126: Created the Distributed Sampler....
INFO 2022-05-24 12:56:35,269 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 12:56:35,270 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2022-05-24 12:56:35,271 train_task.py: 384: Building loss...
INFO 2022-05-24 12:56:35,273 train_task.py: 759: ======Loaded loss state from checkpoint======
INFO 2022-05-24 12:56:35,274 train_task.py: 576: =======Updating classy state_dict from checkpoint=======
INFO 2022-05-24 12:56:35,274 base_ssl_model.py: 446: Rank 0: Loading Trunk state dict....
INFO 2022-05-24 12:56:35,340 base_ssl_model.py: 459: Rank 0: Loading Heads state dict....
INFO 2022-05-24 12:56:35,415 base_ssl_model.py: 474: Rank 0: Model state dict loaded!
INFO 2022-05-24 12:56:35,422 checkpoint.py: 672: Loaded: base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2022-05-24 12:56:35,423 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,423 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,423 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,424 checkpoint.py: 672: Loaded: base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,424 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,424 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,425 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,425 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,425 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,426 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,426 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,426 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,426 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,427 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,427 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,428 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,428 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,428 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,429 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,429 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,429 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,430 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,430 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,430 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,431 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,431 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,431 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,432 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,432 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2022-05-24 12:56:35,432 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,433 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,433 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,433 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,434 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,434 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,434 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,434 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,435 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,435 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,435 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,436 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,436 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,436 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,437 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,437 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,437 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,438 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,438 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,438 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,439 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,439 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,439 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,440 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,440 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,440 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,441 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,441 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,441 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,442 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,442 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,442 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,443 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,443 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,444 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,444 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,444 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,445 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,445 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,445 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,446 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,446 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,446 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,447 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,447 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,447 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,448 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,448 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,448 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,449 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,449 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,449 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,450 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,450 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,450 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,451 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,451 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,451 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,452 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,452 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2022-05-24 12:56:35,452 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,453 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,453 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,454 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,454 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,454 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,455 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,455 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,455 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,456 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,456 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,457 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,457 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,457 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,458 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,458 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,458 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,459 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,459 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,459 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,460 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,460 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,460 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,461 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,461 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,461 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,462 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,462 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,463 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,463 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,463 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,464 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,464 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,464 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,465 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,465 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,465 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,466 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,466 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,466 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,467 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,467 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,467 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,468 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,468 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,469 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,469 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2022-05-24 12:56:35,469 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,470 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,470 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,470 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,471 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,471 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,471 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,472 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,472 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,472 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,473 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,473 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,474 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,474 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,474 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,475 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,475 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,476 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,476 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,476 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,477 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,477 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,477 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,478 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,478 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,478 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,479 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,479 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,479 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,480 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,480 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2022-05-24 12:56:35,480 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,481 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,481 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,481 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,482 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,482 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,483 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,483 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,483 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,484 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,484 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,485 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,485 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,485 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,486 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,486 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,486 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,487 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,487 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,487 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,488 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,488 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,488 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,489 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,489 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,489 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,490 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,490 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,490 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,491 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,491 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,491 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,492 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,492 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,492 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,493 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,493 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,493 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,494 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,494 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,494 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,495 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,495 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,495 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,496 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,496 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,496 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,497 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,497 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,497 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,498 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,498 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,498 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,499 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,499 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,499 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,500 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,500 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,500 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,501 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,501 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,501 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,502 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,502 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,502 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,503 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,503 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,503 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,504 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,504 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,504 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,505 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,505 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,505 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,505 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,506 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,506 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,506 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,507 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,507 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,507 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,508 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,508 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,508 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,509 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,509 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,510 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,510 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,510 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,510 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,511 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,511 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,511 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,512 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,512 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,512 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,512 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,513 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,513 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,513 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,514 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,514 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,514 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,515 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,515 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,515 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,516 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,516 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,516 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,517 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,517 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,517 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,518 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,518 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2022-05-24 12:56:35,518 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,519 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,519 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,519 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,520 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,520 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,520 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,521 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,521 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,521 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,522 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,522 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,522 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,523 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,523 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,523 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,523 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,524 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,524 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,524 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,525 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,525 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,525 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,526 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2022-05-24 12:56:35,526 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2022-05-24 12:56:35,526 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,526 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,527 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,527 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,527 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2022-05-24 12:56:35,528 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2022-05-24 12:56:35,528 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,528 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,529 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,529 checkpoint.py: 672: Loaded: base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,529 checkpoint.py: 657: Ignored layer:	base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2022-05-24 12:56:35,530 checkpoint.py: 672: Loaded: 0.channel_bn.weight                                                  of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,530 checkpoint.py: 672: Loaded: 0.channel_bn.bias                                                    of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,530 checkpoint.py: 672: Loaded: 0.channel_bn.running_mean                                            of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,530 checkpoint.py: 672: Loaded: 0.channel_bn.running_var                                             of shape: torch.Size([64]) from checkpoint
INFO 2022-05-24 12:56:35,531 checkpoint.py: 657: Ignored layer:	0.channel_bn.num_batches_tracked
INFO 2022-05-24 12:56:35,531 checkpoint.py: 672: Loaded: 0.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-24 12:56:35,531 checkpoint.py: 672: Loaded: 0.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-24 12:56:35,532 checkpoint.py: 672: Loaded: 1.channel_bn.weight                                                  of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,532 checkpoint.py: 672: Loaded: 1.channel_bn.bias                                                    of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,532 checkpoint.py: 672: Loaded: 1.channel_bn.running_mean                                            of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,533 checkpoint.py: 672: Loaded: 1.channel_bn.running_var                                             of shape: torch.Size([256]) from checkpoint
INFO 2022-05-24 12:56:35,533 checkpoint.py: 657: Ignored layer:	1.channel_bn.num_batches_tracked
INFO 2022-05-24 12:56:35,533 checkpoint.py: 672: Loaded: 1.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-24 12:56:35,533 checkpoint.py: 672: Loaded: 1.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-24 12:56:35,534 checkpoint.py: 672: Loaded: 2.channel_bn.weight                                                  of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,534 checkpoint.py: 672: Loaded: 2.channel_bn.bias                                                    of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,534 checkpoint.py: 672: Loaded: 2.channel_bn.running_mean                                            of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,535 checkpoint.py: 672: Loaded: 2.channel_bn.running_var                                             of shape: torch.Size([512]) from checkpoint
INFO 2022-05-24 12:56:35,535 checkpoint.py: 657: Ignored layer:	2.channel_bn.num_batches_tracked
INFO 2022-05-24 12:56:35,535 checkpoint.py: 672: Loaded: 2.clf.clf.0.weight                                                   of shape: torch.Size([1000, 8192]) from checkpoint
INFO 2022-05-24 12:56:35,536 checkpoint.py: 672: Loaded: 2.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-24 12:56:35,536 checkpoint.py: 672: Loaded: 3.channel_bn.weight                                                  of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,536 checkpoint.py: 672: Loaded: 3.channel_bn.bias                                                    of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,537 checkpoint.py: 672: Loaded: 3.channel_bn.running_mean                                            of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,537 checkpoint.py: 672: Loaded: 3.channel_bn.running_var                                             of shape: torch.Size([1024]) from checkpoint
INFO 2022-05-24 12:56:35,537 checkpoint.py: 657: Ignored layer:	3.channel_bn.num_batches_tracked
INFO 2022-05-24 12:56:35,538 checkpoint.py: 672: Loaded: 3.clf.clf.0.weight                                                   of shape: torch.Size([1000, 9216]) from checkpoint
INFO 2022-05-24 12:56:35,538 checkpoint.py: 672: Loaded: 3.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-24 12:56:35,539 checkpoint.py: 672: Loaded: 4.channel_bn.weight                                                  of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,539 checkpoint.py: 672: Loaded: 4.channel_bn.bias                                                    of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,539 checkpoint.py: 672: Loaded: 4.channel_bn.running_mean                                            of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,540 checkpoint.py: 672: Loaded: 4.channel_bn.running_var                                             of shape: torch.Size([2048]) from checkpoint
INFO 2022-05-24 12:56:35,540 checkpoint.py: 657: Ignored layer:	4.channel_bn.num_batches_tracked
INFO 2022-05-24 12:56:35,541 checkpoint.py: 672: Loaded: 4.clf.clf.0.weight                                                   of shape: torch.Size([1000, 8192]) from checkpoint
INFO 2022-05-24 12:56:35,541 checkpoint.py: 672: Loaded: 4.clf.clf.0.bias                                                     of shape: torch.Size([1000]) from checkpoint
INFO 2022-05-24 12:56:35,541 checkpoint.py: 685: Extra layers not loaded from checkpoint: []
INFO 2022-05-24 12:56:35,728 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 43, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 12:57:15,588 trainer_main.py: 268: Training 28 epochs
INFO 2022-05-24 12:57:15,588 trainer_main.py: 269: One epoch = 5005 iterations.
INFO 2022-05-24 12:57:15,591 trainer_main.py: 270: Total 1281167 samples in one epoch
INFO 2022-05-24 12:57:15,592 trainer_main.py: 276: Total 140140 iterations for training
INFO 2022-05-24 12:57:15,860 logger.py:  84: Tue May 24 12:57:15 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |
| N/A   33C    P0    55W / 300W |   1760MiB / 32510MiB |      8%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     63263      C   python                           1757MiB |
+-----------------------------------------------------------------------------+

INFO 2022-05-24 12:57:15,863 trainer_main.py: 173: Model is:
 Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)
              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)
      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)
      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)
      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)
      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)
    )
  )
  (heads): ModuleList(
    (0): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (1): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (2): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
    (3): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=9216, out_features=1000, bias=True)
        )
      )
    )
    (4): LinearEvalMLP(
      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (clf): MLP(
        (clf): Sequential(
          (0): Linear(in_features=8192, out_features=1000, bias=True)
        )
      )
    )
  )
)
INFO 2022-05-24 12:57:15,864 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2022-05-24 12:57:15,865 trainer_main.py: 175: Starting training....
INFO 2022-05-24 12:57:15,865 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 43, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 12:57:48,566 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 12:57:48,567 state_update_hooks.py: 115: Starting phase 43 [test]
INFO 2022-05-24 13:02:16,112 trainer_main.py: 214: Meters synced
INFO 2022-05-24 13:02:16,116 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1365
INFO 2022-05-24 13:02:16,117 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.252, 'res2': 24.86, 'res3': 34.39, 'res4': 42.68, 'res5': 36.903999999999996}, 'top_5': {'conv1': 22.386, 'res2': 43.846000000000004, 'res3': 55.716, 'res4': 65.12, 'res5': 59.238}}
INFO 2022-05-24 13:02:16,117 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 13:02:16,120 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 13:02:16,121 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 44, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 13:02:55,865 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 13:02:55,865 state_update_hooks.py: 115: Starting phase 44 [train]
INFO 2022-05-24 13:04:45,066 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 110200; lr: 0.0001; loss: 21.51574; btime(ms): 1570; eta: 13:03:45; peak_mem(M): 6616;
INFO 2022-05-24 13:08:47,523 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 110400; lr: 0.0001; loss: 19.56699; btime(ms): 1423; eta: 11:45:24; peak_mem(M): 6616;
INFO 2022-05-24 13:12:53,758 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 110600; lr: 0.0001; loss: 20.15758; btime(ms): 1365; eta: 11:12:18; peak_mem(M): 6616;
INFO 2022-05-24 13:17:04,316 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 110800; lr: 0.0001; loss: 19.65745; btime(ms): 1337; eta: 10:54:03; peak_mem(M): 6616;
INFO 2022-05-24 13:21:09,979 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 111000; lr: 0.0001; loss: 19.75625; btime(ms): 1317; eta: 10:39:50; peak_mem(M): 6616;
INFO 2022-05-24 13:25:14,692 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 111200; lr: 0.0001; loss: 21.44474; btime(ms): 1302; eta: 10:28:16; peak_mem(M): 6616;
INFO 2022-05-24 13:29:21,468 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 111400; lr: 0.0001; loss: 21.19603; btime(ms): 1293; eta: 10:19:41; peak_mem(M): 6616;
INFO 2022-05-24 13:33:26,985 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 111600; lr: 0.0001; loss: 19.63671; btime(ms): 1285; eta: 10:11:39; peak_mem(M): 6616;
INFO 2022-05-24 13:37:28,307 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 111800; lr: 0.0001; loss: 20.96675; btime(ms): 1278; eta: 10:04:00; peak_mem(M): 6616;
INFO 2022-05-24 13:41:29,126 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 112000; lr: 0.0001; loss: 20.66631; btime(ms): 1271; eta: 9:56:31; peak_mem(M): 6616;
INFO 2022-05-24 13:45:28,919 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 112200; lr: 0.0001; loss: 20.12624; btime(ms): 1265; eta: 9:49:18; peak_mem(M): 6616;
INFO 2022-05-24 13:49:29,918 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 112400; lr: 0.0001; loss: 20.79272; btime(ms): 1260; eta: 9:42:51; peak_mem(M): 6616;
INFO 2022-05-24 13:53:31,700 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 112600; lr: 0.0001; loss: 20.50847; btime(ms): 1256; eta: 9:36:52; peak_mem(M): 6616;
INFO 2022-05-24 13:57:36,118 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 112800; lr: 0.0001; loss: 22.12326; btime(ms): 1254; eta: 9:31:35; peak_mem(M): 6616;
INFO 2022-05-24 14:01:38,227 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 113000; lr: 0.0001; loss: 20.99642; btime(ms): 1251; eta: 9:26:07; peak_mem(M): 6616;
INFO 2022-05-24 14:05:43,215 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 113200; lr: 0.0001; loss: 20.29443; btime(ms): 1249; eta: 9:21:13; peak_mem(M): 6616;
INFO 2022-05-24 14:09:50,229 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 113400; lr: 0.0001; loss: 21.66359; btime(ms): 1248; eta: 9:16:15; peak_mem(M): 6616;
INFO 2022-05-24 14:13:56,140 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 113600; lr: 0.0001; loss: 20.09082; btime(ms): 1247; eta: 9:11:35; peak_mem(M): 6616;
INFO 2022-05-24 14:18:01,067 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 113800; lr: 0.0001; loss: 21.87109; btime(ms): 1245; eta: 9:06:58; peak_mem(M): 6616;
INFO 2022-05-24 14:22:04,660 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 114000; lr: 0.0001; loss: 20.19793; btime(ms): 1244; eta: 9:02:12; peak_mem(M): 6616;
INFO 2022-05-24 14:26:06,217 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 114200; lr: 0.0001; loss: 21.01231; btime(ms): 1243; eta: 8:57:28; peak_mem(M): 6616;
INFO 2022-05-24 14:30:12,458 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 114400; lr: 0.0001; loss: 21.56815; btime(ms): 1242; eta: 8:52:53; peak_mem(M): 6616;
INFO 2022-05-24 14:34:17,580 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 114600; lr: 0.0001; loss: 19.79366; btime(ms): 1241; eta: 8:48:30; peak_mem(M): 6616;
INFO 2022-05-24 14:38:21,849 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 114800; lr: 0.0001; loss: 19.51464; btime(ms): 1240; eta: 8:44:02; peak_mem(M): 6616;
INFO 2022-05-24 14:42:24,475 log_hooks.py: 277: Rank: 0; [ep: 22] iter: 115000; lr: 0.0001; loss: 20.62924; btime(ms): 1239; eta: 8:39:27; peak_mem(M): 6616;
INFO 2022-05-24 14:44:39,355 trainer_main.py: 214: Meters synced
INFO 2022-05-24 14:44:39,359 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1219
INFO 2022-05-24 14:44:39,360 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  880.44 ms  878.62 ms
             forward:   10.02 ms  214.49 ms
        loss_compute:    1.06 ms    1.04 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  112.50 ms  112.60 ms
            backward:    3.18 ms    5.92 ms
      optimizer_step:    1.34 ms    3.68 ms
    train_step_total: 1219.31 ms 1219.48 ms
INFO 2022-05-24 14:44:39,361 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.4308, 'res2': 20.441200000000002, 'res3': 29.636499999999998, 'res4': 39.1598, 'res5': 35.2819}, 'top_5': {'conv1': 17.5304, 'res2': 37.4185, 'res3': 49.204100000000004, 'res4': 60.067400000000006, 'res5': 56.6747}}
INFO 2022-05-24 14:44:39,361 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 14:44:39,364 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 14:44:39,364 log_hooks.py: 425: [phase: 22] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 14:44:40,643 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase22.torch
INFO 2022-05-24 14:44:40,644 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 14:44:40,647 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 14:44:40,648 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 45, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 14:45:19,377 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 14:45:19,378 state_update_hooks.py: 115: Starting phase 45 [test]
INFO 2022-05-24 14:49:43,395 trainer_main.py: 214: Meters synced
INFO 2022-05-24 14:49:43,398 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1347
INFO 2022-05-24 14:49:43,399 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.241999999999999, 'res2': 24.962, 'res3': 34.296, 'res4': 42.67, 'res5': 36.842000000000006}, 'top_5': {'conv1': 22.442, 'res2': 43.884, 'res3': 55.742000000000004, 'res4': 65.036, 'res5': 59.228}}
INFO 2022-05-24 14:49:43,399 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 14:49:43,402 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 14:49:43,403 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 46, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 14:50:23,535 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 14:50:23,536 state_update_hooks.py: 115: Starting phase 46 [train]
INFO 2022-05-24 14:52:08,283 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 115200; lr: 0.0001; loss: 20.56312; btime(ms): 1256; eta: 8:42:27; peak_mem(M): 6616;
INFO 2022-05-24 14:56:09,478 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 115400; lr: 0.0001; loss: 21.44551; btime(ms): 1255; eta: 8:37:39; peak_mem(M): 6616;
INFO 2022-05-24 15:00:13,998 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 115600; lr: 0.0001; loss: 20.41409; btime(ms): 1254; eta: 8:33:02; peak_mem(M): 6616;
INFO 2022-05-24 15:04:20,746 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 115800; lr: 0.0001; loss: 20.26088; btime(ms): 1253; eta: 8:28:24; peak_mem(M): 6616;
INFO 2022-05-24 15:08:23,059 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 116000; lr: 0.0001; loss: 21.44954; btime(ms): 1251; eta: 8:23:36; peak_mem(M): 6616;
INFO 2022-05-24 15:12:28,928 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 116200; lr: 0.0001; loss: 19.97136; btime(ms): 1251; eta: 8:19:12; peak_mem(M): 6616;
INFO 2022-05-24 15:16:30,302 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 116400; lr: 0.0001; loss: 21.25406; btime(ms): 1249; eta: 8:14:33; peak_mem(M): 6616;
INFO 2022-05-24 15:20:32,950 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 116600; lr: 0.0001; loss: 21.01095; btime(ms): 1249; eta: 8:10:04; peak_mem(M): 6616;
INFO 2022-05-24 15:24:39,291 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 116800; lr: 0.0001; loss: 21.15632; btime(ms): 1248; eta: 8:05:44; peak_mem(M): 6616;
INFO 2022-05-24 15:28:38,736 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 117000; lr: 0.0001; loss: 21.26608; btime(ms): 1247; eta: 8:01:02; peak_mem(M): 6616;
INFO 2022-05-24 15:32:45,381 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 117200; lr: 0.0001; loss: 20.59102; btime(ms): 1246; eta: 7:56:40; peak_mem(M): 6616;
INFO 2022-05-24 15:36:53,177 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 117400; lr: 0.0001; loss: 19.632; btime(ms): 1246; eta: 7:52:20; peak_mem(M): 6616;
INFO 2022-05-24 15:40:57,378 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 117600; lr: 0.0001; loss: 21.08492; btime(ms): 1245; eta: 7:47:58; peak_mem(M): 6616;
INFO 2022-05-24 15:45:02,287 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 117800; lr: 0.0001; loss: 19.83475; btime(ms): 1245; eta: 7:43:33; peak_mem(M): 6616;
INFO 2022-05-24 15:49:04,639 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 118000; lr: 0.0001; loss: 20.75943; btime(ms): 1244; eta: 7:39:08; peak_mem(M): 6616;
INFO 2022-05-24 15:53:06,782 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 118200; lr: 0.0001; loss: 20.06927; btime(ms): 1243; eta: 7:34:45; peak_mem(M): 6616;
INFO 2022-05-24 15:57:13,524 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 118400; lr: 0.0001; loss: 20.62707; btime(ms): 1243; eta: 7:30:27; peak_mem(M): 6616;
INFO 2022-05-24 16:01:13,018 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 118600; lr: 0.0001; loss: 20.71037; btime(ms): 1242; eta: 7:26:02; peak_mem(M): 6616;
INFO 2022-05-24 16:05:15,250 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 118800; lr: 0.0001; loss: 19.7453; btime(ms): 1241; eta: 7:21:42; peak_mem(M): 6616;
INFO 2022-05-24 16:09:17,136 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 119000; lr: 0.0001; loss: 20.72602; btime(ms): 1241; eta: 7:17:19; peak_mem(M): 6616;
INFO 2022-05-24 16:13:21,729 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 119200; lr: 0.0001; loss: 21.298; btime(ms): 1240; eta: 7:13:03; peak_mem(M): 6616;
INFO 2022-05-24 16:17:23,491 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 119400; lr: 0.0001; loss: 20.6303; btime(ms): 1240; eta: 7:08:41; peak_mem(M): 6616;
INFO 2022-05-24 16:21:21,321 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 119600; lr: 0.0001; loss: 20.67722; btime(ms): 1239; eta: 7:04:12; peak_mem(M): 6616;
INFO 2022-05-24 16:25:22,280 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 119800; lr: 0.0001; loss: 19.93523; btime(ms): 1238; eta: 6:59:50; peak_mem(M): 6616;
INFO 2022-05-24 16:29:22,070 log_hooks.py: 277: Rank: 0; [ep: 23] iter: 120000; lr: 0.0001; loss: 20.35437; btime(ms): 1237; eta: 6:55:23; peak_mem(M): 6616;
INFO 2022-05-24 16:31:41,983 trainer_main.py: 214: Meters synced
INFO 2022-05-24 16:31:41,986 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1214
INFO 2022-05-24 16:31:41,987 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  874.00 ms  872.01 ms
             forward:    9.71 ms  214.34 ms
        loss_compute:    1.06 ms    1.04 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  114.50 ms  114.60 ms
            backward:    3.16 ms    5.88 ms
      optimizer_step:    1.33 ms    3.66 ms
    train_step_total: 1214.31 ms 1214.47 ms
INFO 2022-05-24 16:31:41,988 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.4557, 'res2': 20.4572, 'res3': 29.6437, 'res4': 39.2742, 'res5': 35.349199999999996}, 'top_5': {'conv1': 17.5525, 'res2': 37.4375, 'res3': 49.2282, 'res4': 60.123599999999996, 'res5': 56.671800000000005}}
INFO 2022-05-24 16:31:41,988 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 16:31:41,991 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 16:31:41,991 log_hooks.py: 425: [phase: 23] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 16:31:43,273 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase23.torch
INFO 2022-05-24 16:31:43,273 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 16:31:43,275 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 16:31:43,276 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 47, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 16:32:18,005 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 16:32:18,006 state_update_hooks.py: 115: Starting phase 47 [test]
INFO 2022-05-24 16:36:47,285 trainer_main.py: 214: Meters synced
INFO 2022-05-24 16:36:47,288 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1373
INFO 2022-05-24 16:36:47,289 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.282, 'res2': 24.92, 'res3': 34.406, 'res4': 42.686, 'res5': 36.778}, 'top_5': {'conv1': 22.49, 'res2': 43.96, 'res3': 55.818, 'res4': 65.012, 'res5': 59.321999999999996}}
INFO 2022-05-24 16:36:47,290 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 16:36:47,292 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 16:36:47,292 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 48, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 16:37:25,030 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 16:37:25,031 state_update_hooks.py: 115: Starting phase 48 [train]
INFO 2022-05-24 16:39:03,469 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 120200; lr: 1e-05; loss: 20.56553; btime(ms): 1246; eta: 6:54:10; peak_mem(M): 6616;
INFO 2022-05-24 16:43:13,783 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 120400; lr: 1e-05; loss: 20.42292; btime(ms): 1246; eta: 6:50:02; peak_mem(M): 6616;
INFO 2022-05-24 16:47:20,431 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 120600; lr: 1e-05; loss: 20.80934; btime(ms): 1246; eta: 6:45:49; peak_mem(M): 6616;
INFO 2022-05-24 16:51:25,425 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 120800; lr: 1e-05; loss: 21.29621; btime(ms): 1245; eta: 6:41:27; peak_mem(M): 6616;
INFO 2022-05-24 16:55:31,431 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 121000; lr: 1e-05; loss: 19.73654; btime(ms): 1245; eta: 6:37:12; peak_mem(M): 6616;
INFO 2022-05-24 16:59:33,400 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 121200; lr: 1e-05; loss: 20.50007; btime(ms): 1244; eta: 6:32:57; peak_mem(M): 6616;
INFO 2022-05-24 17:03:40,963 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 121400; lr: 1e-05; loss: 21.6176; btime(ms): 1244; eta: 6:28:46; peak_mem(M): 6616;
INFO 2022-05-24 17:07:48,737 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 121600; lr: 1e-05; loss: 19.54012; btime(ms): 1244; eta: 6:24:29; peak_mem(M): 6616;
INFO 2022-05-24 17:11:56,327 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 121800; lr: 1e-05; loss: 19.34252; btime(ms): 1244; eta: 6:20:19; peak_mem(M): 6616;
INFO 2022-05-24 17:15:58,617 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 122000; lr: 1e-05; loss: 19.93423; btime(ms): 1243; eta: 6:16:01; peak_mem(M): 6616;
INFO 2022-05-24 17:20:03,316 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 122200; lr: 1e-05; loss: 20.41829; btime(ms): 1243; eta: 6:11:46; peak_mem(M): 6616;
INFO 2022-05-24 17:24:11,256 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 122400; lr: 1e-05; loss: 19.8047; btime(ms): 1243; eta: 6:07:41; peak_mem(M): 6616;
INFO 2022-05-24 17:28:18,615 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 122600; lr: 1e-05; loss: 21.10864; btime(ms): 1243; eta: 6:03:31; peak_mem(M): 6616;
INFO 2022-05-24 17:32:29,358 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 122800; lr: 1e-05; loss: 20.30801; btime(ms): 1243; eta: 5:59:25; peak_mem(M): 6616;
INFO 2022-05-24 17:36:46,624 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 123000; lr: 1e-05; loss: 18.98678; btime(ms): 1244; eta: 5:55:27; peak_mem(M): 6616;
INFO 2022-05-24 17:41:11,567 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 123200; lr: 1e-05; loss: 19.86734; btime(ms): 1245; eta: 5:51:38; peak_mem(M): 6616;
INFO 2022-05-24 17:45:34,683 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 123400; lr: 1e-05; loss: 19.83524; btime(ms): 1246; eta: 5:47:46; peak_mem(M): 6616;
INFO 2022-05-24 17:49:58,501 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 123600; lr: 1e-05; loss: 21.09675; btime(ms): 1247; eta: 5:43:53; peak_mem(M): 6616;
INFO 2022-05-24 17:54:22,661 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 123800; lr: 1e-05; loss: 20.35459; btime(ms): 1248; eta: 5:40:01; peak_mem(M): 6616;
INFO 2022-05-24 17:58:46,543 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 124000; lr: 1e-05; loss: 21.90121; btime(ms): 1249; eta: 5:36:07; peak_mem(M): 6616;
INFO 2022-05-24 18:03:09,935 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 124200; lr: 1e-05; loss: 21.1691; btime(ms): 1250; eta: 5:32:11; peak_mem(M): 6616;
INFO 2022-05-24 18:07:31,707 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 124400; lr: 1e-05; loss: 20.55929; btime(ms): 1251; eta: 5:28:11; peak_mem(M): 6616;
INFO 2022-05-24 18:11:56,729 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 124600; lr: 1e-05; loss: 19.72609; btime(ms): 1251; eta: 5:24:14; peak_mem(M): 6616;
INFO 2022-05-24 18:16:15,990 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 124800; lr: 1e-05; loss: 20.78663; btime(ms): 1252; eta: 5:20:13; peak_mem(M): 6616;
INFO 2022-05-24 18:20:35,554 log_hooks.py: 277: Rank: 0; [ep: 24] iter: 125000; lr: 1e-05; loss: 20.92354; btime(ms): 1253; eta: 5:16:12; peak_mem(M): 6616;
INFO 2022-05-24 18:23:11,695 trainer_main.py: 214: Meters synced
INFO 2022-05-24 18:23:11,699 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1268
INFO 2022-05-24 18:23:11,700 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  916.40 ms  914.47 ms
             forward:   10.17 ms  214.41 ms
        loss_compute:    1.10 ms    1.09 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  125.31 ms  125.42 ms
            backward:    3.37 ms    6.04 ms
      optimizer_step:    1.37 ms    3.67 ms
    train_step_total: 1267.88 ms 1268.06 ms
INFO 2022-05-24 18:23:11,701 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.502000000000001, 'res2': 20.551, 'res3': 29.7221, 'res4': 39.2802, 'res5': 35.3444}, 'top_5': {'conv1': 17.5843, 'res2': 37.5246, 'res3': 49.2799, 'res4': 60.15200000000001, 'res5': 56.706999999999994}}
INFO 2022-05-24 18:23:11,701 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 18:23:11,706 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 18:23:11,706 log_hooks.py: 425: [phase: 24] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 18:23:13,019 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase24.torch
INFO 2022-05-24 18:23:13,020 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 18:23:13,022 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 18:23:13,023 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 49, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 18:23:54,061 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 18:23:54,062 state_update_hooks.py: 115: Starting phase 49 [test]
INFO 2022-05-24 18:28:32,267 trainer_main.py: 214: Meters synced
INFO 2022-05-24 18:28:32,272 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1419
INFO 2022-05-24 18:28:32,273 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.344000000000001, 'res2': 25.024, 'res3': 34.4, 'res4': 42.681999999999995, 'res5': 36.906}, 'top_5': {'conv1': 22.503999999999998, 'res2': 43.93, 'res3': 55.730000000000004, 'res4': 65.072, 'res5': 59.258}}
INFO 2022-05-24 18:28:32,273 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 18:28:32,276 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 18:28:32,277 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 50, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 18:29:15,967 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 18:29:15,967 state_update_hooks.py: 115: Starting phase 50 [train]
INFO 2022-05-24 18:30:54,198 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 125200; lr: 1e-05; loss: 19.94967; btime(ms): 1260; eta: 5:13:56; peak_mem(M): 6616;
INFO 2022-05-24 18:35:09,007 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 125400; lr: 1e-05; loss: 20.22537; btime(ms): 1260; eta: 5:09:46; peak_mem(M): 6616;
INFO 2022-05-24 18:39:20,390 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 125600; lr: 1e-05; loss: 19.97406; btime(ms): 1260; eta: 5:05:34; peak_mem(M): 6616;
INFO 2022-05-24 18:43:35,097 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 125800; lr: 1e-05; loss: 20.4657; btime(ms): 1261; eta: 5:01:24; peak_mem(M): 6616;
INFO 2022-05-24 18:47:47,403 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 126000; lr: 1e-05; loss: 21.3041; btime(ms): 1261; eta: 4:57:12; peak_mem(M): 6616;
INFO 2022-05-24 18:51:59,879 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 126200; lr: 1e-05; loss: 21.01892; btime(ms): 1261; eta: 4:53:01; peak_mem(M): 6616;
INFO 2022-05-24 18:56:14,143 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 126400; lr: 1e-05; loss: 19.60872; btime(ms): 1261; eta: 4:48:52; peak_mem(M): 6616;
INFO 2022-05-24 19:00:26,070 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 126600; lr: 1e-05; loss: 20.03053; btime(ms): 1261; eta: 4:44:39; peak_mem(M): 6616;
INFO 2022-05-24 19:04:41,765 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 126800; lr: 1e-05; loss: 21.65954; btime(ms): 1261; eta: 4:40:30; peak_mem(M): 6616;
INFO 2022-05-24 19:08:55,208 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 127000; lr: 1e-05; loss: 21.63523; btime(ms): 1261; eta: 4:36:18; peak_mem(M): 6616;
INFO 2022-05-24 19:13:10,730 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 127200; lr: 1e-05; loss: 20.77683; btime(ms): 1261; eta: 4:32:08; peak_mem(M): 6616;
INFO 2022-05-24 19:17:28,686 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 127400; lr: 1e-05; loss: 21.23029; btime(ms): 1262; eta: 4:28:00; peak_mem(M): 6616;
INFO 2022-05-24 19:21:48,384 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 127600; lr: 1e-05; loss: 19.91537; btime(ms): 1262; eta: 4:23:52; peak_mem(M): 6616;
INFO 2022-05-24 19:26:06,638 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 127800; lr: 1e-05; loss: 19.91038; btime(ms): 1262; eta: 4:19:44; peak_mem(M): 6616;
INFO 2022-05-24 19:30:21,559 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 128000; lr: 1e-05; loss: 20.4988; btime(ms): 1263; eta: 4:15:33; peak_mem(M): 6616;
INFO 2022-05-24 19:34:40,267 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 128200; lr: 1e-05; loss: 21.73524; btime(ms): 1263; eta: 4:11:24; peak_mem(M): 6616;
INFO 2022-05-24 19:38:58,650 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 128400; lr: 1e-05; loss: 20.46163; btime(ms): 1263; eta: 4:07:15; peak_mem(M): 6616;
INFO 2022-05-24 19:43:15,953 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 128600; lr: 1e-05; loss: 20.10102; btime(ms): 1263; eta: 4:03:05; peak_mem(M): 6616;
INFO 2022-05-24 19:47:33,716 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 128800; lr: 1e-05; loss: 20.03241; btime(ms): 1264; eta: 3:58:55; peak_mem(M): 6616;
INFO 2022-05-24 19:51:47,869 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 129000; lr: 1e-05; loss: 19.84957; btime(ms): 1264; eta: 3:54:43; peak_mem(M): 6616;
INFO 2022-05-24 19:56:02,243 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 129200; lr: 1e-05; loss: 21.77647; btime(ms): 1264; eta: 3:50:30; peak_mem(M): 6616;
INFO 2022-05-24 20:00:16,434 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 129400; lr: 1e-05; loss: 22.49665; btime(ms): 1264; eta: 3:46:18; peak_mem(M): 6616;
INFO 2022-05-24 20:04:31,256 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 129600; lr: 1e-05; loss: 19.78508; btime(ms): 1264; eta: 3:42:07; peak_mem(M): 6616;
INFO 2022-05-24 20:08:47,857 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 129800; lr: 1e-05; loss: 19.49206; btime(ms): 1264; eta: 3:37:56; peak_mem(M): 6616;
INFO 2022-05-24 20:13:00,362 log_hooks.py: 277: Rank: 0; [ep: 25] iter: 130000; lr: 1e-05; loss: 20.60171; btime(ms): 1264; eta: 3:33:43; peak_mem(M): 6616;
INFO 2022-05-24 20:15:39,068 trainer_main.py: 214: Meters synced
INFO 2022-05-24 20:15:39,072 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1275
INFO 2022-05-24 20:15:39,073 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  919.18 ms  917.34 ms
             forward:   10.54 ms  214.44 ms
        loss_compute:    1.10 ms    1.09 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  129.25 ms  129.38 ms
            backward:    3.37 ms    6.00 ms
      optimizer_step:    1.39 ms    3.71 ms
    train_step_total: 1275.15 ms 1275.34 ms
INFO 2022-05-24 20:15:39,074 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.533099999999999, 'res2': 20.4987, 'res3': 29.715700000000002, 'res4': 39.2701, 'res5': 35.410599999999995}, 'top_5': {'conv1': 17.6298, 'res2': 37.485, 'res3': 49.2798, 'res4': 60.0936, 'res5': 56.7265}}
INFO 2022-05-24 20:15:39,074 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 20:15:39,077 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 20:15:39,077 log_hooks.py: 425: [phase: 25] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 20:15:40,363 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase25.torch
INFO 2022-05-24 20:15:40,364 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 20:15:40,366 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 20:15:40,367 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 51, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 20:16:19,646 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 20:16:19,647 state_update_hooks.py: 115: Starting phase 51 [test]
INFO 2022-05-24 20:20:59,748 trainer_main.py: 214: Meters synced
INFO 2022-05-24 20:20:59,754 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1429
INFO 2022-05-24 20:20:59,755 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.328, 'res2': 25.019999999999996, 'res3': 34.486, 'res4': 42.69, 'res5': 36.878}, 'top_5': {'conv1': 22.561999999999998, 'res2': 43.966, 'res3': 55.833999999999996, 'res4': 65.116, 'res5': 59.34199999999999}}
INFO 2022-05-24 20:20:59,756 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 20:20:59,759 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 20:20:59,760 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 52, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 20:21:43,268 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 20:21:43,269 state_update_hooks.py: 115: Starting phase 52 [train]
INFO 2022-05-24 20:23:12,288 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 130200; lr: 1e-05; loss: 20.82385; btime(ms): 1269; eta: 3:30:21; peak_mem(M): 6616;
INFO 2022-05-24 20:27:29,603 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 130400; lr: 1e-05; loss: 20.34436; btime(ms): 1270; eta: 3:26:10; peak_mem(M): 6616;
INFO 2022-05-24 20:31:45,303 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 130600; lr: 1e-05; loss: 20.04622; btime(ms): 1269; eta: 3:21:55; peak_mem(M): 6616;
INFO 2022-05-24 20:36:01,404 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 130800; lr: 1e-05; loss: 20.19443; btime(ms): 1270; eta: 3:17:42; peak_mem(M): 6616;
INFO 2022-05-24 20:40:13,533 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 131000; lr: 1e-05; loss: 19.46927; btime(ms): 1270; eta: 3:13:28; peak_mem(M): 6616;
INFO 2022-05-24 20:44:26,864 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 131200; lr: 1e-05; loss: 20.15582; btime(ms): 1269; eta: 3:09:13; peak_mem(M): 6616;
INFO 2022-05-24 20:48:47,131 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 131400; lr: 1e-05; loss: 20.81999; btime(ms): 1270; eta: 3:05:02; peak_mem(M): 6616;
INFO 2022-05-24 20:53:03,939 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 131600; lr: 1e-05; loss: 20.54433; btime(ms): 1270; eta: 3:00:49; peak_mem(M): 6616;
INFO 2022-05-24 20:57:20,662 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 131800; lr: 1e-05; loss: 21.95084; btime(ms): 1270; eta: 2:56:36; peak_mem(M): 6616;
INFO 2022-05-24 21:01:38,351 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 132000; lr: 1e-05; loss: 20.9619; btime(ms): 1270; eta: 2:52:23; peak_mem(M): 6616;
INFO 2022-05-24 21:05:58,729 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 132200; lr: 1e-05; loss: 20.99478; btime(ms): 1271; eta: 2:48:12; peak_mem(M): 6616;
INFO 2022-05-24 21:10:18,421 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 132400; lr: 1e-05; loss: 19.6078; btime(ms): 1271; eta: 2:43:59; peak_mem(M): 6616;
INFO 2022-05-24 21:14:30,625 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 132600; lr: 1e-05; loss: 21.07207; btime(ms): 1271; eta: 2:39:44; peak_mem(M): 6616;
INFO 2022-05-24 21:18:50,763 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 132800; lr: 1e-05; loss: 20.62359; btime(ms): 1271; eta: 2:35:32; peak_mem(M): 6616;
INFO 2022-05-24 21:23:08,080 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 133000; lr: 1e-05; loss: 21.37845; btime(ms): 1271; eta: 2:31:18; peak_mem(M): 6616;
INFO 2022-05-24 21:27:24,893 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 133200; lr: 1e-05; loss: 20.28212; btime(ms): 1271; eta: 2:27:04; peak_mem(M): 6616;
INFO 2022-05-24 21:31:43,631 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 133400; lr: 1e-05; loss: 21.20359; btime(ms): 1271; eta: 2:22:51; peak_mem(M): 6616;
INFO 2022-05-24 21:36:01,873 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 133600; lr: 1e-05; loss: 20.98036; btime(ms): 1271; eta: 2:18:37; peak_mem(M): 6616;
INFO 2022-05-24 21:40:15,177 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 133800; lr: 1e-05; loss: 20.47281; btime(ms): 1271; eta: 2:14:23; peak_mem(M): 6616;
INFO 2022-05-24 21:44:32,935 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 134000; lr: 1e-05; loss: 19.85279; btime(ms): 1271; eta: 2:10:09; peak_mem(M): 6616;
INFO 2022-05-24 21:48:48,582 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 134200; lr: 1e-05; loss: 21.56279; btime(ms): 1271; eta: 2:05:55; peak_mem(M): 6616;
INFO 2022-05-24 21:53:02,123 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 134400; lr: 1e-05; loss: 20.12357; btime(ms): 1272; eta: 2:01:41; peak_mem(M): 6616;
INFO 2022-05-24 21:57:21,900 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 134600; lr: 1e-05; loss: 19.82409; btime(ms): 1272; eta: 1:57:27; peak_mem(M): 6616;
INFO 2022-05-24 22:01:38,510 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 134800; lr: 1e-05; loss: 19.55384; btime(ms): 1272; eta: 1:53:13; peak_mem(M): 6616;
INFO 2022-05-24 22:05:55,554 log_hooks.py: 277: Rank: 0; [ep: 26] iter: 135000; lr: 1e-05; loss: 20.00201; btime(ms): 1272; eta: 1:48:59; peak_mem(M): 6616;
INFO 2022-05-24 22:08:41,663 trainer_main.py: 214: Meters synced
INFO 2022-05-24 22:08:41,667 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1282
INFO 2022-05-24 22:08:41,668 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  926.09 ms  923.97 ms
             forward:   10.43 ms  214.43 ms
        loss_compute:    1.11 ms    1.10 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  130.15 ms  130.26 ms
            backward:    3.37 ms    6.00 ms
      optimizer_step:    1.38 ms    3.64 ms
    train_step_total: 1282.21 ms 1282.39 ms
INFO 2022-05-24 22:08:41,668 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.5048, 'res2': 20.5911, 'res3': 29.8348, 'res4': 39.3903, 'res5': 35.4742}, 'top_5': {'conv1': 17.6637, 'res2': 37.6131, 'res3': 49.3488, 'res4': 60.241, 'res5': 56.7905}}
INFO 2022-05-24 22:08:41,669 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 22:08:41,671 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 22:08:41,671 log_hooks.py: 425: [phase: 26] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-24 22:08:42,856 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_phase26.torch
INFO 2022-05-24 22:08:42,857 checkpoint.py: 140: Creating symlink...
INFO 2022-05-24 22:08:42,859 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-24 22:08:42,861 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 53, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 22:09:20,443 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 22:09:20,444 state_update_hooks.py: 115: Starting phase 53 [test]
INFO 2022-05-24 22:14:01,722 trainer_main.py: 214: Meters synced
INFO 2022-05-24 22:14:01,726 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1435
INFO 2022-05-24 22:14:01,727 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.346, 'res2': 24.959999999999997, 'res3': 34.424, 'res4': 42.693999999999996, 'res5': 36.802}, 'top_5': {'conv1': 22.518, 'res2': 43.918, 'res3': 55.803999999999995, 'res4': 65.078, 'res5': 59.384}}
INFO 2022-05-24 22:14:01,728 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 22:14:01,731 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-24 22:14:01,731 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 54, 'num_samples': 1281167, 'total_size': 1281167, 'shuffle': True, 'seed': 0}
INFO 2022-05-24 22:14:42,673 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-24 22:14:42,674 state_update_hooks.py: 115: Starting phase 54 [train]
INFO 2022-05-24 22:16:05,760 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 135200; lr: 1e-05; loss: 19.98579; btime(ms): 1276; eta: 1:45:06; peak_mem(M): 6616;
INFO 2022-05-24 22:20:24,674 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 135400; lr: 1e-05; loss: 20.5035; btime(ms): 1276; eta: 1:40:51; peak_mem(M): 6616;
INFO 2022-05-24 22:24:42,323 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 135600; lr: 1e-05; loss: 20.55416; btime(ms): 1276; eta: 1:36:36; peak_mem(M): 6616;
INFO 2022-05-24 22:29:01,874 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 135800; lr: 1e-05; loss: 21.25605; btime(ms): 1276; eta: 1:32:21; peak_mem(M): 6616;
INFO 2022-05-24 22:33:19,364 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 136000; lr: 1e-05; loss: 20.06359; btime(ms): 1277; eta: 1:28:06; peak_mem(M): 6616;
INFO 2022-05-24 22:37:38,446 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 136200; lr: 1e-05; loss: 19.58573; btime(ms): 1277; eta: 1:23:51; peak_mem(M): 6616;
INFO 2022-05-24 22:41:51,878 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 136400; lr: 1e-05; loss: 19.68564; btime(ms): 1277; eta: 1:19:36; peak_mem(M): 6616;
INFO 2022-05-24 22:46:09,933 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 136600; lr: 1e-05; loss: 20.28669; btime(ms): 1277; eta: 1:15:21; peak_mem(M): 6616;
INFO 2022-05-24 22:50:23,727 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 136800; lr: 1e-05; loss: 20.19662; btime(ms): 1277; eta: 1:11:05; peak_mem(M): 6616;
INFO 2022-05-24 22:54:43,117 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 137000; lr: 1e-05; loss: 20.72692; btime(ms): 1277; eta: 1:06:50; peak_mem(M): 6616;
INFO 2022-05-24 22:58:57,582 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 137200; lr: 1e-05; loss: 20.00365; btime(ms): 1277; eta: 1:02:34; peak_mem(M): 6616;
INFO 2022-05-24 23:03:13,318 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 137400; lr: 1e-05; loss: 19.52706; btime(ms): 1277; eta: 0:58:19; peak_mem(M): 6616;
INFO 2022-05-24 23:07:29,721 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 137600; lr: 1e-05; loss: 20.27454; btime(ms): 1277; eta: 0:54:04; peak_mem(M): 6616;
INFO 2022-05-24 23:11:46,847 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 137800; lr: 1e-05; loss: 20.45202; btime(ms): 1277; eta: 0:49:48; peak_mem(M): 6616;
INFO 2022-05-24 23:16:00,707 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 138000; lr: 1e-05; loss: 21.00393; btime(ms): 1277; eta: 0:45:33; peak_mem(M): 6616;
INFO 2022-05-24 23:20:18,811 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 138200; lr: 1e-05; loss: 20.59727; btime(ms): 1277; eta: 0:41:18; peak_mem(M): 6616;
INFO 2022-05-24 23:24:34,753 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 138400; lr: 1e-05; loss: 20.5769; btime(ms): 1277; eta: 0:37:02; peak_mem(M): 6616;
INFO 2022-05-24 23:28:46,594 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 138600; lr: 1e-05; loss: 19.90767; btime(ms): 1277; eta: 0:32:46; peak_mem(M): 6616;
INFO 2022-05-24 23:33:03,378 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 138800; lr: 1e-05; loss: 19.68585; btime(ms): 1277; eta: 0:28:31; peak_mem(M): 6616;
INFO 2022-05-24 23:37:18,452 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 139000; lr: 1e-05; loss: 21.15845; btime(ms): 1277; eta: 0:24:16; peak_mem(M): 6616;
INFO 2022-05-24 23:41:34,380 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 139200; lr: 1e-05; loss: 20.15882; btime(ms): 1277; eta: 0:20:00; peak_mem(M): 6616;
INFO 2022-05-24 23:45:51,967 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 139400; lr: 1e-05; loss: 21.02415; btime(ms): 1277; eta: 0:15:45; peak_mem(M): 6616;
INFO 2022-05-24 23:50:09,902 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 139600; lr: 1e-05; loss: 20.49786; btime(ms): 1277; eta: 0:11:29; peak_mem(M): 6616;
INFO 2022-05-24 23:54:29,247 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 139800; lr: 1e-05; loss: 20.33032; btime(ms): 1277; eta: 0:07:14; peak_mem(M): 6616;
INFO 2022-05-24 23:58:52,352 log_hooks.py: 277: Rank: 0; [ep: 27] iter: 140000; lr: 1e-05; loss: 20.99069; btime(ms): 1277; eta: 0:02:58; peak_mem(M): 6616;
INFO 2022-05-25 00:01:54,761 trainer_main.py: 214: Meters synced
INFO 2022-05-25 00:01:54,764 log_hooks.py: 568: Average train batch time (ms) for 5005 batches: 1285
INFO 2022-05-25 00:01:54,765 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:  930.93 ms  929.06 ms
             forward:   10.53 ms  214.44 ms
        loss_compute:    1.11 ms    1.10 ms
     loss_all_reduce:    0.09 ms    0.09 ms
       meters_update:  127.18 ms  127.29 ms
            backward:    3.44 ms    6.08 ms
      optimizer_step:    1.43 ms    3.73 ms
    train_step_total: 1284.94 ms 1285.13 ms
INFO 2022-05-25 00:01:54,766 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'conv1': 7.5254, 'res2': 20.5395, 'res3': 29.7259, 'res4': 39.3181, 'res5': 35.458099999999995}, 'top_5': {'conv1': 17.6421, 'res2': 37.5871, 'res3': 49.3365, 'res4': 60.179700000000004, 'res5': 56.793800000000005}}
INFO 2022-05-25 00:01:54,766 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-25 00:01:54,769 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-25 00:01:54,769 log_hooks.py: 425: [phase: 27] Saving checkpoint to ./checkpoints/after_poison/imagenet
INFO 2022-05-25 00:01:56,092 checkpoint.py: 131: Saved checkpoint: ./checkpoints/after_poison/imagenet/model_final_checkpoint_phase27.torch
INFO 2022-05-25 00:01:56,092 checkpoint.py: 140: Creating symlink...
INFO 2022-05-25 00:01:56,095 checkpoint.py: 144: Created symlink: ./checkpoints/after_poison/imagenet/checkpoint.torch
INFO 2022-05-25 00:01:56,096 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 55, 'num_samples': 50000, 'total_size': 50000, 'shuffle': True, 'seed': 0}
INFO 2022-05-25 00:02:37,218 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2022-05-25 00:02:37,219 state_update_hooks.py: 115: Starting phase 55 [test]
INFO 2022-05-25 00:07:14,869 trainer_main.py: 214: Meters synced
INFO 2022-05-25 00:07:14,874 log_hooks.py: 568: Average test batch time (ms) for 196 batches: 1416
INFO 2022-05-25 00:07:14,875 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'conv1': 10.35, 'res2': 24.986, 'res3': 34.432, 'res4': 42.662, 'res5': 36.846000000000004}, 'top_5': {'conv1': 22.498, 'res2': 44.019999999999996, 'res3': 55.82, 'res4': 65.06, 'res5': 59.309999999999995}}
INFO 2022-05-25 00:07:14,875 io.py:  63: Saving data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-25 00:07:14,878 io.py:  89: Saved data to file: ./checkpoints/after_poison/imagenet/metrics.json
INFO 2022-05-25 00:07:15,075 train.py: 131: All Done!
INFO 2022-05-25 00:07:15,076 logger.py:  73: Shutting down loggers...
INFO 2022-05-25 00:07:15,207 distributed_launcher.py: 168: All Done!
INFO 2022-05-25 00:07:15,207 logger.py:  73: Shutting down loggers...
